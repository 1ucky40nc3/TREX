{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TREX.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "a3SM312SP6v6",
        "e0AFeWgzwFgr",
        "kUMHIlD8Tj7g",
        "-uSXlrc5UXis",
        "8yY2gJS0hZWw",
        "oKuBPzcJWaOu",
        "k_Zo09hxv31Y",
        "12V9_IDkmwq-",
        "jnD_dmwAm8BI",
        "BKsJj9mKnd1G",
        "ZXF876tBJ6I8",
        "0DVfrA6NpQuo",
        "8fqGpEURp38G",
        "WAOU0Mf-qRJi",
        "xgUr4Q6TJ6JH",
        "hG8kX8OHvA-U",
        "pkJSj4o6TA86"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOCEjD9YMaHRpbDr5aSH9oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/TREX/blob/main/TREX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCNgpK3tZbZ",
        "cellView": "form",
        "outputId": "551c9f86-791f-4ddd-f96a-abbba5f80a5f"
      },
      "source": [
        "# @title Check if Runtime is connected with a GPU â“ ðŸ’ª \n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  1 15:31:41 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3SM312SP6v6"
      },
      "source": [
        "# ***Set up TREX*** ðŸ¦–ðŸ’¬\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78i3mCfXdyK1",
        "cellView": "form"
      },
      "source": [
        "# @title Utils for the entire Notebook\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "from IPython.utils.io import capture_output\n",
        "\n",
        "\n",
        "def execute(func, *args, verbose: bool = False, **kwargs):\n",
        "    if verbose:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})\n",
        "    \n",
        "    with capture_output() as captured:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0AFeWgzwFgr"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Natural Language Processing (NLP)*** ðŸ“°ðŸ¤¯\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RSVfnYbnkrXo"
      },
      "source": [
        "#@markdown ### Language selection during operation ðŸ³ï¸â€ðŸŒˆ/ðŸ´â€â˜ ï¸\n",
        "LANGUAGE = \"de\" #@param [\"en\", \"de\"]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUMHIlD8Tj7g"
      },
      "source": [
        "### Set up fot the ***Legacy NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC4zn53LYTw9",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Install Dependencies â‡©\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "    \n",
        "\n",
        "def install_nlp_dependencies(**kwargs):\n",
        "    !pip install sentencepiece\n",
        "    !pip install transformers\n",
        "    !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "    !pip install torch-geometric\n",
        "    !pip install torch-scatter==2.0.8 -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "\n",
        "execute(install_nlp_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1U9U9gdwKig",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Initialize the NLP Pipelines\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "\n",
        "def device(boolean: bool) -> int:\n",
        "    return 0 if boolean else -1\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Model selection for the NLP toolkit ðŸ¤–ðŸ“°\n",
        "ZERO_SHOT_MODEL = \"facebook/bart-large-mnli\" #@param [\"facebook/bart-large-mnli\", \"typeform/distilbert-base-uncased-mnli\", \"joeddav/xlm-roberta-large-xnli\", \"Narsil/deberta-large-mnli-zero-cls\"]\n",
        "TABLE_QA_MODEL = \"lysandre/tiny-tapas-random-wtq\" #@param [\"lysandre/tiny-tapas-random-wtq\", \"lysandre/tiny-tapas-random-sqa\", \"google/tapas-base-finetuned-wtq\", \"google/tapas-base-finetuned-sqa\", \"google/tapas-base-finetuned-wikisql-supervised\", \"google/tapas-large-finetuned-wtq\", \"google/tapas-large-finetuned-sqa\", \"google/tapas-large-finetuned-wikisql-supervised\"]\n",
        "SMALL_TALK_MODEL = \"facebook/blenderbot-90M\" #@param [\"facebook/blenderbot-90M\", \"facebook/blenderbot-400M-distill\", \"facebook/blenderbot-1B-distill\", \"facebook/blenderbot-3B\"]\n",
        "FEW_SHOT_MODEL = \"EleutherAI/gpt-neo-125M\" #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"EleutherAI/gpt-neo-125M\", \"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Model selection for translation between English and German\n",
        "GERMAN_TO_ENGLISH_MODEL = \"facebook/wmt19-de-en\" #@param [\"Helsinki-NLP/opus-mt-de-en\", \"facebook/wmt19-de-en\"]\n",
        "ENGLISH_TO_GERMAN_MODEL = \"facebook/wmt19-en-de\" #@param [\"Helsinki-NLP/opus-mt-en-de\", \"facebook/wmt19-en-de\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Select if the individual model shall be on GPU ðŸ’»ðŸ”¥\n",
        "USE_GPU_FOR_ZERO_SHOT = True # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_SMALL_TALK = False # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_FEW_SHOT = False # @param {type:\"boolean\"}\n",
        "\n",
        "USE_GPU_FOR_GERMAN_TO_ENGLISH = False # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_ENGLISH_TO_GERMAN = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "    \n",
        "\n",
        "def initialize_nlp_pipelines(**kwargs):\n",
        "    print(\"[DEBUG] Downloading Zero-Shot-Classification Components\")\n",
        "    ZERO_SHOT = transformers.pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=ZERO_SHOT_MODEL,\n",
        "        device=device(USE_GPU_FOR_ZERO_SHOT))\n",
        "    \n",
        "    print(\"[DEBUG] Downloading Table-QA Components\")\n",
        "    TABLE_QA = transformers.pipeline(\n",
        "        \"table-question-answering\", \n",
        "        model=TABLE_QA_MODEL)\n",
        "\n",
        "    print(\"[DEBUG] Downloading Small-Talk Components\")\n",
        "    SMALL_TALK = transformers.pipeline(\n",
        "        \"conversational\", \n",
        "        model=SMALL_TALK_MODEL, \n",
        "        device=device(USE_GPU_FOR_SMALL_TALK))\n",
        "\n",
        "    print(\"[DEBUG] Downloading Text-To-Text Components\")\n",
        "    FEW_SHOT = transformers.pipeline(\n",
        "        \"text-generation\", \n",
        "        model=FEW_SHOT_MODEL, \n",
        "        device=device(USE_GPU_FOR_FEW_SHOT))\n",
        "    FEW_SHOT_TOKENIZER = transformers.GPT2Tokenizer.from_pretrained(\n",
        "        FEW_SHOT_MODEL)\n",
        "    \n",
        "    if LANGUAGE == \"de\":\n",
        "        print(\"[DEBUG] Downloading German-To-English Translation Components\")\n",
        "        GERMAN_TO_ENGLISH_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_de_to_en\", \n",
        "            model=GERMAN_TO_ENGLISH_MODEL)\n",
        "        print(\"[DEBUG] Downloading English-To-German Translation Components\")\n",
        "        ENGLISH_TO_GERMAN_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_en_to_de\", \n",
        "            model=ENGLISH_TO_GERMAN_MODEL)\n",
        "    \n",
        "    return locals()\n",
        "\n",
        "PIPELINES = execute(initialize_nlp_pipelines, verbose=VERBOSE)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDT5V9m2w3sQ",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Legacy NLP Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from typing import Callable\n",
        "from typing import Optional\n",
        "\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Classification on a Zero-Shot basis.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def zero_shot_classification(input: str, \n",
        "                             labels: List[str], \n",
        "                             top_k: Optional[int] = 1,\n",
        "                             **kwargs) -> List[str]:\n",
        "    return PIPELINES[\"ZERO_SHOT\"](input, labels)[\"labels\"][:top_k]\n",
        "\n",
        "def skill_classification(input: str, \n",
        "                         skills: List[str], \n",
        "                         verbose: Optional[bool] = False,\n",
        "                         **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Skill Classification| skills: {skills}\")\n",
        "\n",
        "    skill = zero_shot_classification(input, skills, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| skill: {skill}\")\n",
        "    return skill\n",
        "\n",
        "def sentiment_classification(input: str,\n",
        "                             labels: List[str],\n",
        "                             verbose: Optional[bool] = False,\n",
        "                             **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Sentiment Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Sentiment Classification| labels: {labels}\")\n",
        "\n",
        "    label = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Sentiment Classification| label: {label}\")\n",
        "    return label\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~\n",
        "Section for Table QA.\n",
        "~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def table_question_answering(input: str, \n",
        "                             table: pd.DataFrame, \n",
        "                             verbose: Optional[bool] = False, \n",
        "                             **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| input: {input}\")\n",
        "        print(f\"[DEBUG] |Table Question Answering| table: \\n{table}\")\n",
        "    \n",
        "    print(type(input), type(table))\n",
        "    output = PIPELINES[\"TABLE_QA\"](table=table, query=input)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| output: \\n{output}\")\n",
        "    return output[\"answer\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Few-Shot Text Generation\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "\n",
        "def few_shot(query: str, \n",
        "             samples: str, \n",
        "             verbose: Optional[bool] = False, \n",
        "             **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "    \n",
        "    outputs = PIPELINES[\"FEW_SHOT\"](samples + query, **kwargs)\n",
        "    outputs = [sample[\"generated_text\"] for sample in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def travel_few_shot(query: str, \n",
        "                    samples: str, \n",
        "                    verbose: Optional[bool] = False, \n",
        "                    **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "\n",
        "    outputs = few_shot(query, \n",
        "                      samples, \n",
        "                      verbose, \n",
        "                      **kwargs)\n",
        "    \n",
        "    for i, sample in enumerate(outputs):\n",
        "        sample = sample[len(samples + query):]\n",
        "        print(sample)\n",
        "        sample = sample.split('\\n\\n')[0]\n",
        "        outputs[i] = sample\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Skill Functions\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def legacy_travel_skill(conversation: transformers.Conversation, \n",
        "                        associations: dict, \n",
        "                        verbose: Optional[bool] = False, \n",
        "                        **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Travel Skill| input conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |Legacy Travel Skill| associations: \\n{associations}\")\n",
        "\n",
        "    input = conversation.new_user_input\n",
        "    labels = list(associations.keys())\n",
        "\n",
        "    variant = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    data = associations[variant][\"data\"]()\n",
        "    time = associations[variant][\"time\"]()\n",
        "    location = associations[variant][\"location\"]()\n",
        "    samples = associations[variant][\"samples\"]\n",
        "    config = associations[variant][\"config\"]\n",
        "\n",
        "    cell = table_question_answering(input, data, verbose)\n",
        "    cell = cell.replace(\":00\", \"\")\n",
        "\n",
        "    input = f\"I am in {location}. It is {time}. {input}\"\n",
        "    query = f'Q: {input}\\nC: {cell}\\n'\n",
        "\n",
        "    outputs = travel_few_shot(\n",
        "        query, \n",
        "        samples, \n",
        "        verbose, \n",
        "        **{**config, **kwargs})\n",
        "    outputs = [output.replace(\"A: \", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Travel Skill| variant: {variant}\")\n",
        "        print(f\"[DEBUG] |Legacy Travel Skill| cell: {cell}\")\n",
        "        print(f\"[DEBUG] |Legacy Travel Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "def legacy_small_talk_skill(conversation: transformers.Conversation,\n",
        "                            associations: dict,\n",
        "                            verbose: Optional[bool] = False, \n",
        "                            **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| input conversation: \\n{conversation}\")\n",
        "\n",
        "    num_return_sequences = associations[\"num_return_sequences\"]\n",
        "    \n",
        "    conversations = [copy.deepcopy(conversation) for _ in range(num_return_sequences)]\n",
        "    conversations = PIPELINES[\"SMALL_TALK\"](conversations)\n",
        "    outputs = [conversation.generated_responses[-1] for conversation in conversations]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| num_return_sequences: {num_return_sequences}\")\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Personas and Warm Up\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def legacy_warm_up(conversation: transformers.Conversation, \n",
        "                   personas: List[str],\n",
        "                   verbose: bool = False,\n",
        "                   **kwargs) -> transformers.Conversation:\n",
        "    for persona in personas:\n",
        "        conversation.add_user_input(persona)\n",
        "        conversation = PIPELINES[\"SMALL_TALK\"](conversation)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Warm Up| personas: {personas}\")\n",
        "        print(f\"[DEBUG] |Legacy Warm Up| personas: {conversation}\")\n",
        "    return conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~\n",
        "Language Processors\n",
        "~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def legacy_german_to_english_translation(input: str,\n",
        "                                         verbose: Optional[bool] = False, \n",
        "                                         **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy German-To-English Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"GERMAN_TO_ENGLISH_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy German-To-English Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "def legacy_english_to_german_translation(input: str,\n",
        "                                         verbose: Optional[bool] = False, \n",
        "                                         **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy English-To-German Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"ENGLISH_TO_GERMAN_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy English-To-German Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section Few-Shot Samples and their utilities.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "legacy_travel_samples = \"\"\"Q: It is 12:30. Wich is the next train from Frankfurt to Leipzig?\n",
        "C: ICE 1655\n",
        "A: The next train to Leipzig is the ICE 1655.\n",
        "\n",
        "Q: It is 17:22. Wich is the next train from Frankfurt to Leipzig?\n",
        "C: ICE 594\n",
        "A: The next train to Leipzig is the ICE 594.\n",
        "\n",
        "Q: When will the ICE 594 from Frankfurt arrive in Leipzig.\n",
        "C: 21:10\n",
        "A: The ICE 594 will arrive at 21:10.\n",
        "\n",
        "Q: How long will the ICE 1655 need to get from Frankfurt to Leipzig?\n",
        "C: 03:03\n",
        "A: The ICE 1655 will need 3 hours and 3 minutes.\n",
        "\n",
        "Q: At wich track will the FLX 1354 from Berlin arrive?\n",
        "C: 5\n",
        "A: The FLX 1354 from Berlin will arrive at the track 5.\n",
        "\n",
        "Q: Which train is the fastest option from Berlin to Hamburg?\n",
        "C: ICE 806\n",
        "A: The ICE 806 is the fastest option.\n",
        "\n",
        "Q: Which is the fastest option from Berlin to Hamburg?\n",
        "C: ICE 806\n",
        "A: The ICE 806 is the fastest option.\n",
        "\n",
        "Q: Can I take a Flixtrain from Berlin to Hamburg?\n",
        "C: FLX 1354\n",
        "A: The Flixtrain FLX 1354 will travel to Hamburg.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def length(samples: str, model: str) -> int:\n",
        "    tokenizer = PIPELINES[\"FEW_SHOT_TOKENIZER\"]\n",
        "    input_ids = tokenizer(\n",
        "        samples, return_tensors=\"pt\").input_ids\n",
        "    return input_ids.shape[-1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uSXlrc5UXis"
      },
      "source": [
        "### Set up fot the ***AI21 NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSsofpCOUWeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8778ecb0-4140-497d-eea6-727fa959668e"
      },
      "source": [
        "# @title | NLP | Set up AI21 Studio API Key\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from getpass import getpass\n",
        "import requests\n",
        "import json\n",
        "\n",
        "AI21_API_KEY = getpass(\"\"\"\n",
        "    â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„â–„    â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ â–„â–„   â–„â–„ â–„â–„â–„â–„â–„â–„  â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ \n",
        "    â–ˆ       â–ˆ   â–ˆ       â–ˆ    â–ˆ  â–ˆ       â–ˆ       â–ˆ  â–ˆ â–ˆ  â–ˆ      â–ˆâ–ˆ   â–ˆ       â–ˆ\n",
        "    â–ˆ   â–„   â–ˆ   â–ˆâ–„â–„â–„â–„   â–ˆâ–ˆ   â–ˆ  â–ˆ  â–„â–„â–„â–„â–„â–ˆâ–„     â–„â–ˆ  â–ˆ â–ˆ  â–ˆ  â–„    â–ˆ   â–ˆ   â–„   â–ˆ\n",
        "    â–ˆ  â–ˆâ–„â–ˆ  â–ˆ   â–ˆâ–„â–„â–„â–„â–ˆ  â–ˆâ–ˆ   â–ˆ  â–ˆ â–ˆâ–„â–„â–„â–„â–„  â–ˆ   â–ˆ â–ˆ  â–ˆâ–„â–ˆ  â–ˆ â–ˆ â–ˆ   â–ˆ   â–ˆ  â–ˆ â–ˆ  â–ˆ\n",
        "    â–ˆ       â–ˆ   â–ˆ â–„â–„â–„â–„â–„â–„â–ˆâ–ˆ   â–ˆ  â–ˆâ–„â–„â–„â–„â–„  â–ˆ â–ˆ   â–ˆ â–ˆ       â–ˆ â–ˆâ–„â–ˆ   â–ˆ   â–ˆ  â–ˆâ–„â–ˆ  â–ˆ\n",
        "    â–ˆ   â–„   â–ˆ   â–ˆ â–ˆâ–„â–„â–„â–„â–„ â–ˆ   â–ˆ   â–„â–„â–„â–„â–„â–ˆ â–ˆ â–ˆ   â–ˆ â–ˆ       â–ˆ       â–ˆ   â–ˆ       â–ˆ\n",
        "    â–ˆâ–„â–„â–ˆ â–ˆâ–„â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆ  â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆ â–ˆâ–„â–„â–„â–ˆ â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆ\n",
        "\n",
        "    Note: If you DO NOT wish to use the AI21 toolkit simply press Enter.\n",
        "    Paste your AI21 Studio API key here: \"\"\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„â–„    â–„â–„â–„â–„â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ â–„â–„   â–„â–„ â–„â–„â–„â–„â–„â–„  â–„â–„â–„ â–„â–„â–„â–„â–„â–„â–„ \n",
            "    â–ˆ       â–ˆ   â–ˆ       â–ˆ    â–ˆ  â–ˆ       â–ˆ       â–ˆ  â–ˆ â–ˆ  â–ˆ      â–ˆâ–ˆ   â–ˆ       â–ˆ\n",
            "    â–ˆ   â–„   â–ˆ   â–ˆâ–„â–„â–„â–„   â–ˆâ–ˆ   â–ˆ  â–ˆ  â–„â–„â–„â–„â–„â–ˆâ–„     â–„â–ˆ  â–ˆ â–ˆ  â–ˆ  â–„    â–ˆ   â–ˆ   â–„   â–ˆ\n",
            "    â–ˆ  â–ˆâ–„â–ˆ  â–ˆ   â–ˆâ–„â–„â–„â–„â–ˆ  â–ˆâ–ˆ   â–ˆ  â–ˆ â–ˆâ–„â–„â–„â–„â–„  â–ˆ   â–ˆ â–ˆ  â–ˆâ–„â–ˆ  â–ˆ â–ˆ â–ˆ   â–ˆ   â–ˆ  â–ˆ â–ˆ  â–ˆ\n",
            "    â–ˆ       â–ˆ   â–ˆ â–„â–„â–„â–„â–„â–„â–ˆâ–ˆ   â–ˆ  â–ˆâ–„â–„â–„â–„â–„  â–ˆ â–ˆ   â–ˆ â–ˆ       â–ˆ â–ˆâ–„â–ˆ   â–ˆ   â–ˆ  â–ˆâ–„â–ˆ  â–ˆ\n",
            "    â–ˆ   â–„   â–ˆ   â–ˆ â–ˆâ–„â–„â–„â–„â–„ â–ˆ   â–ˆ   â–„â–„â–„â–„â–„â–ˆ â–ˆ â–ˆ   â–ˆ â–ˆ       â–ˆ       â–ˆ   â–ˆ       â–ˆ\n",
            "    â–ˆâ–„â–„â–ˆ â–ˆâ–„â–„â–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆ  â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆ â–ˆâ–„â–„â–„â–ˆ â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–ˆâ–ˆâ–„â–„â–„â–ˆâ–„â–„â–„â–„â–„â–„â–„â–ˆ\n",
            "\n",
            "    Note: If you DO NOT wish to use the AI21 toolkit simply press Enter.\n",
            "    Paste your AI21 Studio API key here: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5Seco5VfCS",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | AI21 NLP Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities.\n",
        "~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def ai21_pipeline(model: str,\n",
        "                  input: str,\n",
        "                  num_beams: int = 0,\n",
        "                  num_return_sequences: int = 1,\n",
        "                  max_length: int = 100,\n",
        "                  stop_sequences: List[str] = [],\n",
        "                  top_p: float = 0.98,\n",
        "                  top_k: int = 0,\n",
        "                  temperature: float = 0.0,\n",
        "                  verbose: bool = False,\n",
        "                  **kwargs) -> List[str]:\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| model: {model}\")\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| input: {input}\")\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| config: {locals()}\")\n",
        "        \n",
        "        if AI21_API_KEY == \"\":\n",
        "            raise Exception(\n",
        "                \"\"\"[Error] No valid AI21 Studio API key was entered!\n",
        "                Please rerun the \"| NLP | Set up AI21 Studio API Key\" Cell \n",
        "                and enter your valid API Key.\"\"\")\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"https://api.ai21.com/studio/v1/{model}/complete\",\n",
        "            headers={\"Authorization\": f\"Bearer {AI21_API_KEY}\"},\n",
        "            json={\n",
        "                \"prompt\": input, \n",
        "                \"numResults\": num_return_sequences, \n",
        "                \"maxTokens\": max_length, \n",
        "                \"stopSequences\": stop_sequences,\n",
        "                \"topP\": top_p,\n",
        "                \"topKReturn\": top_k,\n",
        "                \"temperature\": temperature,\n",
        "            })\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise Exception(\n",
        "                f\"\"\"[Error] The AI21 Studio request has returned a status code other than 200!\n",
        "                The request returned the following status code: {response.status}.\n",
        "                with the following request body:\\n{response.text}\"\"\")\n",
        "        \n",
        "        outputs = json.loads(response.text)[\"completions\"]\n",
        "        outputs = [output[\"data\"][\"text\"] for output in outputs]\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| outputs: \\n{outputs}\")\n",
        "        return outputs\n",
        "\n",
        "def ai21_preprocess_table(data: pd.DataFrame) -> str:\n",
        "    table = df_to_csv(data)\n",
        "    table = table.replace(\",\", \" | \")\n",
        "\n",
        "    split = table.split(\"\\n\")\n",
        "    del split[-1]\n",
        "\n",
        "    for i, line in enumerate(split):\n",
        "        split[i] = f\"| {line} |\"\n",
        "\n",
        "    table = \"\\n\".join(split)\n",
        "    return table\n",
        "\n",
        "def ai21_warm_up(conversation: transformers.Conversation,\n",
        "                 *args,\n",
        "                 verbose: bool = False,\n",
        "                 **kwargs) -> transformers.Conversation:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Warm Up| personas: {conversation}\")\n",
        "    return conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Skill Functions\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def ai21_travel_skill(conversation: transformers.Conversation, \n",
        "                      associations: dict, \n",
        "                      verbose: Optional[bool] = False, \n",
        "                      **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Travel Skill| input conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |AI21 Travel Skill| associations: \\n{associations}\")\n",
        "\n",
        "    input = conversation.new_user_input\n",
        "    labels = list(associations.keys())\n",
        "\n",
        "    variant = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    data = associations[variant][\"data\"]()\n",
        "    time = associations[variant][\"time\"]()\n",
        "    location = associations[variant][\"location\"]()\n",
        "    samples = associations[variant][\"samples\"]\n",
        "    config = associations[variant][\"config\"]\n",
        "    model = associations[variant][\"model\"]\n",
        "\n",
        "    table = ai21_preprocess_table(data)\n",
        "    query = f\"Q: I am in {location}. It is {time}. {input}\"\n",
        "    input = f\"{table}\\n\\n{samples}{query}\"\n",
        "\n",
        "    outputs = ai21_pipeline(\n",
        "        model,\n",
        "        input,\n",
        "        verbose=verbose,\n",
        "        **config)\n",
        "    outputs = [output.replace(\"\\nA: \", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Travel Skill| variant: {variant}\")\n",
        "        print(f\"[DEBUG] |AI21 Travel Skill| input: \\n{input}\")\n",
        "        print(f\"[DEBUG] |AI21 Travel Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "def ai21_small_talk_skill(conversation: transformers.Conversation, \n",
        "                          associations: dict,\n",
        "                          verbose: Optional[bool] = False, \n",
        "                          **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Small Talk Skill| input conversation: \\n{conversation}\")\n",
        "    \n",
        "    model = associations[\"model\"]\n",
        "    samples = associations[\"samples\"]\n",
        "    config = associations[\"config\"]\n",
        "    \n",
        "    input = str(conversation)\n",
        "    input = input.split(\"\\n\")[1:]\n",
        "    input = \"\\n\".join(input)\n",
        "    input = samples + input\n",
        "\n",
        "    outputs = ai21_pipeline(\n",
        "        model,\n",
        "        input,\n",
        "        verbose=verbose,\n",
        "        **config)\n",
        "    outputs = [output.replace(\"bot >> \", \"\").replace(\"\\n\", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Small Talk Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section Few-Shot Samples and their utilities.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "ai21_travel_samples = \"\"\"Q: It is 12:30. Wich is the next train from Frankfurt to Leipzig?\n",
        "A: The next train to Leipzig is ICE 1655 at 17:21 from track 9.\n",
        "\n",
        "Q: It is 17:22. Wich is the next train from Frankfurt to Leipzig?\n",
        "A: The next train to Leipzig is ICE 594 at 18:14 from track 9.\n",
        "\n",
        "Q: When will the ICE 594 from Frankfurt arrive in Leipzig.\n",
        "A: The ICE 594 will arrive at 21:10 on the track 13.\n",
        "\n",
        "Q: How long will the ICE 1655 need to get from Frankfurt to Leipzig?\n",
        "A: The  ICE 1655 will need 3 hours and 3 minutes.\n",
        "\n",
        "Q: At wich track will the FLX 1354 from Berlin arrive?\n",
        "A: The FLX 1354 from Berlin will arrive at the track 5 at 10:07.\n",
        "\n",
        "Q: Which train is the fastest option from Berlin to Hamburg?\n",
        "A: The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\n",
        "\n",
        "Q: Which is the fastest option from Berlin to Hamburg?\n",
        "A: The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\n",
        "\n",
        "Q: Can I take a Flixtrain from Berlin to Hamburg?\n",
        "A: The Flixtrain FLX 1354 will travel to Hamburg starting at 08:07 from track 8.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ai21_small_talk_samples = \"\"\"user >> what is your name\n",
        "bot >> My name is Mia. How can I help you? How are you doing?\n",
        "user >> what is your job\n",
        "bot >> I'm your assistant. Feel free to ask me about travel or keep the small talk going.\n",
        "user >> i m going away now bye\n",
        "bot >>  Good Bye. It was nice meeting you. See you soon.\n",
        "\n",
        "user >> how are you today\n",
        "bot >> I'm fine thanks! How are you? How can I help you?\n",
        "user >> i am good would you rather have a dragon or unicorn as a pet\n",
        "bot >> A unicorn! But both would be awesome pets! How about you?\n",
        "user >> i think i would take dragon they can fly so traveling should be a breeze\n",
        "bot >> That is a good point. Can I help you with anything else?\n",
        "user >> no i am fine good bye see you later\n",
        "bot >>  Good Bye. It was nice meeting you. See you soon.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yY2gJS0hZWw"
      },
      "source": [
        "### Set up fot the ***DeepL NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCyOn6dMhZXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "1cb536d5-bbbe-464e-9587-7acf57d83f4d"
      },
      "source": [
        "# @title | NLP | Set up DeepL API Key\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from getpass import getpass\n",
        "import requests\n",
        "import json\n",
        "\n",
        "DEEPL_API_KEY = getpass(\"\"\"\n",
        "    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—     \n",
        "    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     \n",
        "    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     \n",
        "    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     \n",
        "    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
        "    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•â•â•â•â•\n",
        "\n",
        "    Note: If you DO NOT wish to use the DeepL component simply press Enter.\n",
        "    Paste your DeepL API key here: \"\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—     \n",
            "    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     \n",
            "    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     \n",
            "    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• â–ˆâ–ˆâ•‘     \n",
            "    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     â•šâ•â•â•â•â•â•â•\n",
            "\n",
            "    Note: If you DO NOT wish to use the DeepL component simply press Enter.\n",
            "    Paste your DeepL API key here: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3djIDKr_hZXO",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | DeepL Translation Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~\n",
        "Language Processors\n",
        "~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def deepl_translation(text: str,\n",
        "                      target_lang: str=\"DE\",\n",
        "                      verbose: Optional[bool] = False,\n",
        "                      **kwargs) -> dict:\n",
        "    if DEEPL_API_KEY == \"\":\n",
        "        raise Exception(\n",
        "            \"\"\"[Error] No valid  DeepL API key was entered!\n",
        "            Please rerun the \"| NLP | Set up DeepL API Key\" Cell \n",
        "            and enter your valid API Key.\"\"\")\n",
        "    \n",
        "    url = \"https://api-free.deepl.com/v2/translate\"\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "    data = f\"auth_key={DEEPL_API_KEY}&text={text}&target_lang={target_lang}\"\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "    \n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            f\"\"\"[Error] The DeepL API request has returned a status code other than 200!\n",
        "            The request returned the following status code: {response.status}.\n",
        "            with the following request body:\\n{response.text}\"\"\")\n",
        "        \n",
        "    response = json.loads(response.text)\n",
        "    translation = response[\"translations\"][0]\n",
        "\n",
        "    return translation\n",
        "\n",
        "def deepl_german_to_english_translation(input: str,\n",
        "                                        verbose: Optional[bool] = False, \n",
        "                                        **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL German-To-English Translation| input: {input}\")\n",
        "\n",
        "    translation = deepl_translation(input, target_lang=\"EN\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL German-To-English Translation| translation: {translation}\")\n",
        "    return translation[\"text\"]\n",
        "\n",
        "def deepl_english_to_german_translation(input: str,\n",
        "                                        verbose: Optional[bool] = False, \n",
        "                                        **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL English-To-German Translation| input: {input}\")\n",
        "\n",
        "    translation = deepl_translation(input, target_lang=\"DE\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL English-To-German Translation| translation: \\n{translation}\")\n",
        "    return translation[\"text\"]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKuBPzcJWaOu"
      },
      "source": [
        "### Set up fot the ***NLP*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "N4aTN97_w5sH",
        "cellView": "form",
        "outputId": "7875a1dd-963d-4d80-8115-4f930044f6bb"
      },
      "source": [
        "# @title | NLP | Set up Services for Data\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "from typing import Any\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "import transformers\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities to create travel tables\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "DE_TRAVEL_TABLE = \"\"\"Location,Train,Start,Destination,Departure Time,Arrival Time,Departure Track,Arrival Track,Duration,Changeover Time,Delay\n",
        "MÃ¼nchen,ICE 1655,Frankfurt(Main) Hbf,Leipzig Hbf,17:21:00,20:24:00,9,14,03:03:00,0,0\n",
        "MÃ¼nchen,ICE 594,Frankfurt(Main) Hbf,Leipzig Hbf,18:14:00,21:10:00,9,13,02:56:00,0,0\n",
        "MÃ¼nchen,FLX 1354,Berlin Hbf (tief),Hamburg Hbf,08:07 ,10:07:00,8,5,02:00:00,0,0\n",
        "MÃ¼nchen,ICE 806,Berlin Hbf (tief),Hamburg Hbf,08:38:00,10:21:00,8,5,01:43:00,0,0\n",
        "MÃ¼nchen,ICE 598,Stuttgart Hbf,Mannheim Hbf,12:51:00,13:29:00,9,2,00:38:00,0,0\n",
        "MÃ¼nchen,ICE 576,Stuttgart Hbf,Mannheim Hbf,13:23:00,14:02:00,10,3,00:39:00,0,0\n",
        "MÃ¼nchen,ICE 1223,NÃ¼rnberg Hbf,MÃ¼nchen Hbf,14:07:00,15:12:00,9,22,01:05:00,0,0\n",
        "MÃ¼nchen,ICE 705,NÃ¼rnberg Hbf,MÃ¼nchen Hbf,14:55:00,16:07:00,8,21,01:12:00,0,0\"\"\"\n",
        "\n",
        "EN_TRAVEL_TABLE = \"\"\"Location,Train,Start,Destination,Departure Time,Arrival Time,Departure Track,Arrival Track,Duration,Changeover Time,Delay\n",
        "Munich,ICE 1655,Frankfurt(Main) Hbf,Leipzig Hbf,17:21:00,20:24:00,9,14,03:03:00,0,0\n",
        "Munich,ICE 594,Frankfurt(Main) Hbf,Leipzig Hbf,18:14:00,21:10:00,9,13,02:56:00,0,0\n",
        "Munich,FLX 1354,Berlin Hbf (low),Hamburg Hbf,08:07 ,10:07:00,8,5,02:00:00,0,0\n",
        "Munich,ICE 806,Berlin Hbf (low),Hamburg Hbf,08:38:00,10:21:00,8,5,01:43:00,0,0\n",
        "Munich,ICE 598,Stuttgart Hbf,Mannheim Hbf,12:51:00,13:29:00,9,2,00:38:00,0,0\n",
        "Munich,ICE 576,Stuttgart Hbf,Mannheim Hbf,13:23:00,14:02:00,10,3,00:39:00,0,0\n",
        "Munich,ICE 1223,Nuremberg Hbf,Munich Hbf,14:07:00,15:12:00,9,22,01:05:00,0,0\n",
        "Munich,ICE 705,Nuremberg Hbf,Munich Hbf,14:55:00,16:07:00,8,21,01:12:00,0,0\"\"\"\n",
        "\n",
        "TRAVEL_TABLE = DE_TRAVEL_TABLE if LANGUAGE == \"de\" else EN_TRAVEL_TABLE\n",
        "\n",
        "\n",
        "def set_dtype(df: pd.DataFrame, dtype: Any) -> pd.DataFrame:\n",
        "    return df.astype({column: dtype for column in df.columns.values})\n",
        " \n",
        "def travel_table() -> pd.DataFrame:\n",
        "    df = pd.read_csv(\n",
        "        io.StringIO(TRAVEL_TABLE))\n",
        "    df = set_dtype(df, str)\n",
        "\n",
        "    return df\n",
        "\n",
        "def df_to_csv(df) -> str:\n",
        "    csv = io.StringIO()\n",
        "    df.to_csv(csv, index=False)\n",
        "    return csv.getvalue()\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for general utilities\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "TRAVEL_TIME = \"7:00\" #@param {type: \"string\"}\n",
        "TRAVEL_LOCATION = \"Munich\" #@param {type: \"string\"}\n",
        "\n",
        "def travel_time() -> str:\n",
        "    return TRAVEL_TIME\n",
        "\n",
        "def travel_location() -> str:\n",
        "    return TRAVEL_LOCATION\n",
        "\n",
        "\n",
        "travel_table()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Train</th>\n",
              "      <th>Start</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Departure Time</th>\n",
              "      <th>Arrival Time</th>\n",
              "      <th>Departure Track</th>\n",
              "      <th>Arrival Track</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Changeover Time</th>\n",
              "      <th>Delay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 1655</td>\n",
              "      <td>Frankfurt(Main)Hbf</td>\n",
              "      <td>Leipzig Hbf</td>\n",
              "      <td>17:21:00</td>\n",
              "      <td>20:24:00</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>03:03:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 594</td>\n",
              "      <td>Frankfurt(Main)Hbf</td>\n",
              "      <td>Leipzig Hbf</td>\n",
              "      <td>18:14:00</td>\n",
              "      <td>21:10:00</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>02:56:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>FLX 1354</td>\n",
              "      <td>Berlin Hbf (tief)</td>\n",
              "      <td>Hamburg Hbf</td>\n",
              "      <td>08:07</td>\n",
              "      <td>10:07:00</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>02:00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 806</td>\n",
              "      <td>Berlin Hbf (tief)</td>\n",
              "      <td>Hamburg Hbf</td>\n",
              "      <td>08:38:00</td>\n",
              "      <td>10:21:00</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>01:43:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 598</td>\n",
              "      <td>Stuttgart Hbf</td>\n",
              "      <td>Mannheim Hbf</td>\n",
              "      <td>12:51:00</td>\n",
              "      <td>13:29:00</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>00:38:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 576</td>\n",
              "      <td>Stuttgart Hbf</td>\n",
              "      <td>Mannheim Hbf</td>\n",
              "      <td>13:23:00</td>\n",
              "      <td>14:02:00</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>00:39:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 1223</td>\n",
              "      <td>NÃ¼rnberg Hbf</td>\n",
              "      <td>MÃ¼nchen Hbf</td>\n",
              "      <td>14:07:00</td>\n",
              "      <td>15:12:00</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>01:05:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MÃ¼nchen</td>\n",
              "      <td>ICE 705</td>\n",
              "      <td>NÃ¼rnberg Hbf</td>\n",
              "      <td>MÃ¼nchen Hbf</td>\n",
              "      <td>14:55:00</td>\n",
              "      <td>16:07:00</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>01:12:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Location     Train               Start  ...  Duration Changeover Time Delay\n",
              "0  MÃ¼nchen  ICE 1655  Frankfurt(Main)Hbf  ...  03:03:00               0     0\n",
              "1  MÃ¼nchen   ICE 594  Frankfurt(Main)Hbf  ...  02:56:00               0     0\n",
              "2  MÃ¼nchen  FLX 1354   Berlin Hbf (tief)  ...  02:00:00               0     0\n",
              "3  MÃ¼nchen   ICE 806   Berlin Hbf (tief)  ...  01:43:00               0     0\n",
              "4  MÃ¼nchen   ICE 598       Stuttgart Hbf  ...  00:38:00               0     0\n",
              "5  MÃ¼nchen   ICE 576       Stuttgart Hbf  ...  00:39:00               0     0\n",
              "6  MÃ¼nchen  ICE 1223        NÃ¼rnberg Hbf  ...  01:05:00               0     0\n",
              "7  MÃ¼nchen   ICE 705        NÃ¼rnberg Hbf  ...  01:12:00               0     0\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jG4ljQCWS7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "d4a18133-a846-4784-8efc-cad53eecd983"
      },
      "source": [
        "# @title | NLP | Set up Module\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the Skill Versions ðŸ‘€ðŸ”€\n",
        "SMALL_TALK_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TRAVEL_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TIMETABLE_SKILL_VERSION = \"legacy\" #@param [\"legacy\", \"ai21\"]\n",
        "TRANSLATION_COMPONENT = \"deepl\" #@param [\"legacy\", \"deepl\"]\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~\n",
        "NLP Configuration\n",
        "~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": {\n",
        "        \"to_native\": lambda x: x,\n",
        "        \"to_source\": lambda x: x,\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"to_native\": legacy_german_to_english_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_german_to_english_translation,\n",
        "        \"to_source\": legacy_english_to_german_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_english_to_german_translation,\n",
        "    }\n",
        "}\n",
        "\n",
        "SENTIMENT = {\n",
        "    \"positive\": [\"non-toxic\"],\n",
        "    \"negative\": [\"toxic\"],\n",
        "}\n",
        "\n",
        "LEGACY_PERSONAS = {\n",
        "    \"warm_up\": legacy_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "LEGACY_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"num_return_sequences\": 2,\n",
        "    }, \n",
        "    \"function\": legacy_small_talk_skill\n",
        "}\n",
        "\n",
        "LEGACY_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"data\": travel_table,\n",
        "            \"time\": travel_time,\n",
        "            \"location\": travel_location,\n",
        "            \"samples\": legacy_travel_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_travel_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_travel_skill\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "AI21_PERSONAS = {\n",
        "    \"warm_up\": ai21_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "AI21_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"model\": \"j1-jumbo\",\n",
        "        \"samples\": ai21_small_talk_samples,\n",
        "        \"config\": {\n",
        "            \"num_results\": 10,\n",
        "            \"max_tokens\": 64,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.98,\n",
        "            \"stop_sequences\": [\"user >>\"],\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_small_talk_skill\n",
        "}\n",
        "\n",
        "AI21_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": travel_table,\n",
        "            \"time\": travel_time,\n",
        "            \"location\": travel_location,\n",
        "            \"samples\": ai21_travel_samples,\n",
        "            \"config\": {\n",
        "                \"max_tokens\": 100,\n",
        "                \"temperature\": 0.0,\n",
        "                \"top_p\": 1.0,\n",
        "                \"stop_sequences\": [\"\\n\\n\"],\n",
        "\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_travel_skill\n",
        "}\n",
        "\n",
        "PERSONAS = LEGACY_PERSONAS if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_PERSONAS\n",
        "\n",
        "SKILLS = {\n",
        "    \"travel\": {\n",
        "        \"labels\": [\"travel\", \"travel on time\", \"travel delayed\"],\n",
        "        \"pipeline\": LEGACY_TRAVEL_SKILL if TRAVEL_SKILL_VERSION == \"legacy\" else AI21_TRAVEL_SKILL\n",
        "    },\n",
        "    \"small talk\": {\n",
        "        \"labels\": [\"small talk\", \"other\"],\n",
        "        \"pipeline\": LEGACY_SMALL_TALK_SKILL if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_SMALL_TALK_SKILL\n",
        "    }\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"languages\": LANGUAGES,\n",
        "    \"sentiment\": SENTIMENT,\n",
        "    \"personas\": PERSONAS,\n",
        "    \"skills\": SKILLS,\n",
        "} \n",
        "\n",
        "\n",
        "class NLP:\n",
        "    def __init__(self,\n",
        "                 config: dict = CONFIG,\n",
        "                 verbose: bool = True,\n",
        "                 **kwargs):\n",
        "        self.config = config\n",
        "\n",
        "        language = config[\"languages\"][LANGUAGE]\n",
        "        self.to_native = language[\"to_native\"]\n",
        "        self.to_source = language[\"to_source\"]\n",
        "\n",
        "        self.sentiment_labels = []\n",
        "        for _, labels in self.config[\"sentiment\"].items():\n",
        "            self.sentiment_labels.extend(labels)\n",
        "\n",
        "        personas = config[\"personas\"]\n",
        "        self.conversation = personas[\"warm_up\"](\n",
        "            transformers.Conversation(), \n",
        "            personas=personas[\"personas\"],\n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "\n",
        "        self.skills = config[\"skills\"]\n",
        "\n",
        "        self.skill_labels = []\n",
        "        for _, skill in self.skills.items():\n",
        "            self.skill_labels.extend(skill[\"labels\"])\n",
        "        \n",
        "    def __call__(self, \n",
        "                 input: str, \n",
        "                 verbose: bool = False, \n",
        "                 **kwargs) -> str:\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP __call__ <START>|\" + \"~\"*20)\n",
        "            print(f\"[DEBUG] |NLP ATTR skills|: {self.skills}\")\n",
        "            print(f\"[DEBUG] |NLP ATTR conversation|: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP User input|: {input}\")\n",
        "        # Convert input from the source to native language.\n",
        "        input = self.to_native(input)\n",
        "\n",
        "        # Check if sentiment of the input is negative.\n",
        "        if self.is_sentiment(\"negative\", input):\n",
        "            raise Exception(\"[Warning] A negative input was captured and discarded.\")\n",
        "        self.conversation.add_user_input(input)\n",
        "\n",
        "        # Match a skill to the given input.\n",
        "        label = skill_classification(\n",
        "            input, \n",
        "            self.skill_labels,\n",
        "            verbose=verbose, \n",
        "            **kwargs)\n",
        "        \n",
        "        # Collect components to do further processing.\n",
        "        skill = self.skill_from_label(label)\n",
        "        pipeline = skill[\"pipeline\"]\n",
        "        function = pipeline[\"function\"]\n",
        "        associations = pipeline[\"associations\"]\n",
        "        \n",
        "        # Generate the skills outputs.\n",
        "        outputs = function(\n",
        "            self.conversation, \n",
        "            associations=associations, \n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "        \n",
        "        # Find the first output with a positive sentiment.\n",
        "        output = \"\"\n",
        "        for sample in outputs:\n",
        "            if self.is_sentiment(\"positive\", sample):\n",
        "                output = sample\n",
        "                break\n",
        "\n",
        "        self.conversation.mark_processed()\n",
        "        self.conversation.append_response(output)\n",
        "\n",
        "        # Issue a warning if no outputs where positive.\n",
        "        if output == \"\":\n",
        "            raise Exception(\"[Warning] All outputs where negative and discarded.\")\n",
        "        \n",
        "        # Convert input from the native to source language.\n",
        "        output = self.to_source(output)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP conversation |: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP outputs|: \\n{outputs}\")\n",
        "            print(f\"[DEBUG] |NLP output|: {output}\")\n",
        "            print(f\"[DEBUG] |NLP __call__ <END>|\" + \"~\"*20)\n",
        "        return output\n",
        "\n",
        "    def is_sentiment(self, name: str, input: str) -> bool:\n",
        "        \"\"\"Return if the input has a given sentiment.\"\"\"\n",
        "        label = sentiment_classification(\n",
        "            input, self.sentiment_labels)\n",
        "        labels = self.config[\"sentiment\"][name]\n",
        "        \n",
        "        return label in labels\n",
        "        \n",
        "    def skill_from_label(self, label: str) -> dict:\n",
        "        \"\"\"Return the first skill that has the label.\"\"\"\n",
        "        for _, skill in self.skills.items():\n",
        "            if label in skill[\"labels\"]:\n",
        "                return skill\n",
        "\n",
        "        raise Exception(\"The classified skill_label is not mapped to a skill.\")\n",
        "\n",
        "\n",
        "nlp = execute(NLP, verbose=VERBOSE, config=CONFIG)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] |AI21 Warm Up| personas: Conversation id: 3dcc5667-35ec-406f-898d-0ce1687c3cc8 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Zo09hxv31Y"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Speech Recognition (STT)*** ðŸŽ¤ðŸ’¬\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12V9_IDkmwq-"
      },
      "source": [
        "### Set up for ***Legacy Speech Recognition***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7WGmmWMbf4o",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Installation of Legacy Dependencies â‡©\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_legacy_sst_dependencies(**kwargs):\n",
        "    !pip install transformers\n",
        "    !pip install numpy==1.20\n",
        "    !pip install numba==0.48\n",
        "    !pip install ffmpeg-python\n",
        "    !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "execute(install_legacy_sst_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjsRML5VtFXY",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Legacy Wav2Vec2 Speech Recognition\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def speech_to_text_implementation(**kwargs):\n",
        "    from transformers import Wav2Vec2Tokenizer\n",
        "    from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "    STT_MODEL = \"facebook/wav2vec2-large-960h-lv60-self\" if LANGUAGE == \"en\" else \"facebook/wav2vec2-large-xlsr-53-german\"\n",
        "\n",
        "    # load model and tokenizer\n",
        "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(STT_MODEL)\n",
        "    wav2vec2 = Wav2Vec2ForCTC.from_pretrained(STT_MODEL)\n",
        "\n",
        "    def speech_to_text(audio: np.ndarray, \n",
        "                       **kwargs) -> List[str]:   \n",
        "        input_values = tokenizer(\n",
        "            [audio], \n",
        "            return_tensors=\"pt\", \n",
        "            padding=\"longest\"\n",
        "        ).input_values\n",
        "\n",
        "        logits = wav2vec2(input_values).logits\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        text = tokenizer.batch_decode(predicted_ids)\n",
        "        text = \" \".join(text)\n",
        "        return text\n",
        "\n",
        "    return speech_to_text\n",
        "\n",
        "legacy_stt = execute(speech_to_text_implementation, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnD_dmwAm8BI"
      },
      "source": [
        "### Set up for ***Google Cloud Speech Recognition***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fnEA0Okm69x",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Installation of Google Cloud Dependencies â‡©\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "def install_gcloud_sst_dependencies(**kwargs):\n",
        "    !pip install soundfile\n",
        "    !pip install --upgrade google-auth\n",
        "    !pip install --upgrade google-cloud-speech\n",
        "    !pip install numpy==1.20\n",
        "    !pip install numba==0.48\n",
        "    !pip install ffmpeg-python\n",
        "    !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "execute(install_gcloud_sst_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "1hwMiTG3nsvt"
      },
      "source": [
        "# @title | STT | Mount Google Drive to access Google Cloud credentials\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "GCLOUD_STT_CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
        "    '/content/gdrive/MyDrive/projects/TREX/STT/key.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMGSkzgn8rP",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Google Cloud Speech Recognition Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from google.cloud import speech\n",
        "\n",
        "\n",
        "def gcloud_stt(data: np.ndarray,\n",
        "               rate: int=16000,\n",
        "               language_code: str=\"en-US\",\n",
        "               speech_file: str=\"speech_file.flac\",\n",
        "               encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
        "               credentials=GCLOUD_STT_CREDENTIALS) -> str:\n",
        "    \"\"\"Transcribe audio data via the Google Cloud Speech-To-Text Service.\n",
        "    \n",
        "    Args:\n",
        "        data (np.ndarray): The audio data.\n",
        "    \n",
        "    Kwargs:\n",
        "        speech_file (str): A file in which the audio is stored.\n",
        "        rate (int): The sample rate of the audio.\n",
        "        encoding (enum): The encoding of the audio file.\n",
        "        language_code (str): The language of the speech.\n",
        "\n",
        "    Returns:\n",
        "        (str) The most likely transcript.\n",
        "\n",
        "    Note:\n",
        "        Transcription is limited to a 60 seconds audio file.\n",
        "        Use a GCS file for audio longer than 1 minute.\n",
        "    \"\"\"\n",
        "    sf.write(speech_file, data, rate)\n",
        "\n",
        "    client = speech.SpeechClient(credentials=credentials)\n",
        "\n",
        "    with io.open(speech_file, \"rb\") as audio_file:\n",
        "        content = audio_file.read()\n",
        "\n",
        "    audio = speech.RecognitionAudio(content=content)\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=encoding,\n",
        "        sample_rate_hertz=rate,\n",
        "        language_code=language_code)\n",
        "\n",
        "    operation = client.long_running_recognize(\n",
        "        config=config, \n",
        "        audio=audio)\n",
        "\n",
        "    print(\"Waiting for operation to complete...\")\n",
        "    response = operation.result(timeout=90)\n",
        "\n",
        "    # Each result is for a consecutive portion of the audio. Iterate through\n",
        "    # them to get the transcripts for the entire audio file.\n",
        "    for result in response.results:\n",
        "        # The first alternative is the most likely one for this portion.\n",
        "        transcript = result.alternatives[0].transcript\n",
        "        confidence = result.alternatives[0].confidence\n",
        "\n",
        "        print(u\"Transcript: {}\".format(transcript))\n",
        "        print(\"Confidence: {}\".format(confidence))\n",
        "        return transcript\n",
        "    return None"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKsJj9mKnd1G"
      },
      "source": [
        "### Set up audio recording utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PauhmEq8chkm",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Audio Recording Utils\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\"\"\"Utils for recording audio in a Google Colaboratory notebook.\n",
        "\n",
        "This code is adapted from:\n",
        "    https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/\n",
        "    https://colab.research.google.com/gist/ricardodeazambuja/03ac98c31e87caf284f7b06286ebf7fd/microphone-to-numpy-array-from-your-browser-in-colab.ipynb\n",
        "\"\"\"\n",
        "\n",
        "SILENT = \"&> /dev/null\"\n",
        "\n",
        "import io\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import write\n",
        "from dl_colab_notebooks.audio import audio_bytes_to_np\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "STYLES_HTML = \"\"\"\n",
        "<script>\n",
        "\n",
        "var styles = `\n",
        "\n",
        "button {\n",
        "    width: 300px;\n",
        "    height: 54px;\n",
        "\n",
        "    padding: 20px;\n",
        "    margin: 5px;\n",
        "\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    border-radius: 40px;\n",
        "    border: none;\n",
        "\n",
        "    text-align: center;\n",
        "    font-size: 28px;\n",
        "    \n",
        "    transition: all 0.5s;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "button span {\n",
        "    display: inline-block;\n",
        "    position: relative;\n",
        "\n",
        "    cursor: pointer;\n",
        "    transition: 0.5s;\n",
        "}\n",
        "\n",
        "button span:after {\n",
        "    content: 'ðŸ™';\n",
        "\n",
        "    position: absolute;\n",
        "    right: -20px;\n",
        "\n",
        "    opacity: 0;\n",
        "    transition: 0.5s;\n",
        "}\n",
        "\n",
        "button:hover span {\n",
        "    padding-right: 25px;\n",
        "}\n",
        "\n",
        "button:hover span:after {\n",
        "    right: 0;\n",
        "    opacity: 1;\n",
        "}\n",
        "`\n",
        "\n",
        "var styleSheet = document.createElement(\"style\")\n",
        "styleSheet.type = \"text/css\"\n",
        "styleSheet.innerText = styles\n",
        "document.head.appendChild(styleSheet);\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "\n",
        "var container = document.createElement(\"div\");\n",
        "var button = document.createElement(\"button\");\n",
        "var span = document.createElement(\"span\");\n",
        "\n",
        "button.appendChild(span);\n",
        "container.appendChild(button);\n",
        "document.body.appendChild(container);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader, recorder, gumStream;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "            mimeType : 'audio/webm;codecs=opus'\n",
        "    };            \n",
        "    recorder = new MediaRecorder(stream);\n",
        "    recorder.ondataavailable = function(e) {            \n",
        "        var url = URL.createObjectURL(e.data);\n",
        "        var preview = document.createElement('audio');\n",
        "\n",
        "        preview.controls = true;\n",
        "        preview.src = url;\n",
        "        container.appendChild(preview);\n",
        "\n",
        "        reader = new FileReader();\n",
        "        reader.readAsDataURL(e.data); \n",
        "        reader.onloadend = function() {\n",
        "            base64data = reader.result;\n",
        "        }\n",
        "    };\n",
        "    recorder.start();\n",
        "};\n",
        "\n",
        "span.innerText = \"â¸ï¸Ž\";\n",
        "button.style.verticalAlign = \"middle\";\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "        recorder.stop();\n",
        "        gumStream.getAudioTracks()[0].stop();\n",
        "        span.innerText = \"âœ…\"\n",
        "    }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "    button.onclick = () => {\n",
        "        toggleRecording()\n",
        "\n",
        "        sleep(2000).then(() => {\n",
        "            resolve(base64data.toString())\n",
        "        });\n",
        "    }\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def record(sample_rate: int = 16000) -> str:\n",
        "    display(HTML(STYLES_HTML + AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    \n",
        "    audio_bytes = b64decode(data.split(',')[1])\n",
        "    return audio_bytes_to_np(audio_bytes, sample_rate)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXF876tBJ6I8"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Text-To-Speech (TTS)*** ðŸ’­ðŸ“£\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DVfrA6NpQuo"
      },
      "source": [
        "### Set up for the ***Legacy Text-To-Speech*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UxGOjsiJ6JF",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | Installation of Legacy Dependencies â‡©\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_legacy_tts_dependencies(**kwargs):\n",
        "    !apt-get install -y espeak\n",
        "\n",
        "    if LANGUAGE == \"de\":\n",
        "        !gdown --id 1VG0EI7J6S1bk3h0q1VBc9ALExkdZdeVm -O tts_model.pth.tar\n",
        "        !gdown --id 1s1GcSihlj58KX0LeA-FPFvdMWGMkcxKI -O config.json\n",
        "        !gdown --id 1zYFHElvYW_oTeilvbZVLMLscColWRbck -O vocoder_model.pth.tar\n",
        "        !gdown --id 1ye9kVDbatAKMncRMui7watrLQ_5DaJ3e -O config_vocoder.json\n",
        "        !gdown --id 1QD40bU_M7CWrj9k0MEACNBRqwqVTSLDc -O scale_stats.npy\n",
        "        !sudo apt-get install espeak\n",
        "        !git clone https://github.com/coqui-ai/TTS\n",
        "\n",
        "        %cd TTS\n",
        "        !git checkout 540d811\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup.py install\n",
        "\n",
        "        # sometimes installation does not work\n",
        "        import os, sys\n",
        "        sys.path.append(os.getcwd())\n",
        "        %cd ..\n",
        "    else:\n",
        "        !git clone https://github.com/1ucky40nc3/TransformerTTS.git\n",
        "        %cd TransformerTTS\n",
        "        !git checkout package\n",
        "        !pip install torchaudio\n",
        "        !pip install -r /content/TransformerTTS/requirements.txt\n",
        "        !pip install -r /content/TransformerTTS/TransformerTTS/vocoding/extra_requirements.txt\n",
        "        !python setup.py develop\n",
        "\n",
        "        !wget https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/hifigan.zip\n",
        "        !unzip -q hifigan.zip\n",
        "        !rsync -avq hifigan/ /content/TransformerTTS/TransformerTTS/vocoding/hifigan/\n",
        "\n",
        "execute(install_legacy_tts_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDXVw9toJ6JG",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | TTS Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown #### â—â—â— ***If \"de\" is selected as language an error may accure.***\n",
        "# @markdown #### â© Just try to rerun this cell. ðŸ‘» \n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchaudio import functional as F\n",
        "\n",
        "def text_to_speech_implementation(**kwargs):\n",
        "    if LANGUAGE == \"de\":\n",
        "        import os\n",
        "        from TTS.utils.io import load_config\n",
        "        from TTS.utils.audio import AudioProcessor\n",
        "        from TTS.tts.utils.io import load_checkpoint\n",
        "        from TTS.tts.utils.synthesis import synthesis\n",
        "        from TTS.tts.utils.text.symbols import symbols\n",
        "        from TTS.tts.utils.generic_utils import setup_model\n",
        "        from TTS.vocoder.utils.generic_utils import setup_generator\n",
        "        from TTS.vocoder.utils.io import load_checkpoint as load_vocoder_checkpoint\n",
        "\n",
        "        TTS_MODEL = \"/content/tts_model.pth.tar\"\n",
        "        TTS_CONFIG = \"/content/config.json\"\n",
        "        VOCODER_MODEL = \"/content/vocoder_model.pth.tar\"\n",
        "        VOCODER_CONFIG = \"/content/config_vocoder.json\"\n",
        "\n",
        "        TTS_CONFIG = load_config(TTS_CONFIG)\n",
        "        TTS_CONFIG.audio[\"stats_path\"] = \"/content/scale_stats.npy\"\n",
        "\n",
        "        VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
        "\n",
        "        audio_processor = AudioProcessor(**TTS_CONFIG.audio)\n",
        "\n",
        "        model, _ = load_checkpoint(\n",
        "            setup_model(\n",
        "                num_chars=len(symbols), \n",
        "                num_speakers=0,\n",
        "                c=TTS_CONFIG),\n",
        "            checkpoint_path=TTS_MODEL)\n",
        "\n",
        "        vocoder, _ = load_vocoder_checkpoint(\n",
        "            setup_generator(VOCODER_CONFIG), \n",
        "            checkpoint_path=VOCODER_MODEL)\n",
        "        vocoder.remove_weight_norm()\n",
        "        vocoder.inference_padding = 0\n",
        "\n",
        "        if USE_GPU_4_GERMAN_TTS:\n",
        "            model.cuda()\n",
        "            vocoder.cuda()\n",
        "\n",
        "        model.eval()\n",
        "        vocoder.eval()\n",
        "\n",
        "        def text_to_speech(text: str, \n",
        "                           **kwargs) -> np.ndarray:\n",
        "            _, _, _, mel_postnet_spec, _, _ = synthesis(\n",
        "                model, \n",
        "                text, \n",
        "                TTS_CONFIG,\n",
        "                USE_GPU_4_GERMAN_TTS, \n",
        "                audio_processor)\n",
        "            \n",
        "            speech = vocoder.inference(\n",
        "                torch.FloatTensor(\n",
        "                    mel_postnet_spec.T,\n",
        "                ).unsqueeze(0))\n",
        "            speech = speech.flatten().cpu().numpy()\n",
        "\n",
        "            return speech\n",
        "        \n",
        "        return text_to_speech\n",
        "    \n",
        "    %cd /content/TransformerTTS\n",
        "\n",
        "    from TransformerTTS.model.factory import tts_ljspeech\n",
        "    from TransformerTTS.vocoding.predictors import HiFiGANPredictor\n",
        "\n",
        "\n",
        "    folder = \"/content/TransformerTTS/TransformerTTS/vocoding/hifigan/en\"\n",
        "\n",
        "\n",
        "    model, _ = tts_ljspeech()\n",
        "    vocoder = HiFiGANPredictor.from_folder(folder)\n",
        "\n",
        "    def text_to_speech(text: str, \n",
        "                       **kwargs) -> np.ndarray:\n",
        "        speech = model.predict(text)\n",
        "        speech = speech[\"mel\"].numpy().T\n",
        "        speech = vocoder([speech])[0]\n",
        "\n",
        "        return speech\n",
        "\n",
        "    %cd ..\n",
        "    return text_to_speech\n",
        "\n",
        "legacy_tts = execute(text_to_speech_implementation, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fqGpEURp38G"
      },
      "source": [
        "### Set up for the ***Google Cloud Text-To-Speech*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUdzmRd9p6tl",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | Installation of Google Cloud Dependencies â‡©\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_gcloud_tts_dependencies(**kwargs):\n",
        "    !pip install soundfile\n",
        "    !pip install --upgrade google-auth\n",
        "    !pip install --upgrade google-cloud-texttospeech\n",
        "\n",
        "execute(install_gcloud_tts_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uidDtKTCqojE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59342bc7-e127-479d-9436-a642ba6fe4bd"
      },
      "source": [
        "# @title | TTS | Mount Google Drive to access Google Cloud credentials\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "GCLOUD_TTS_CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
        "    '/content/gdrive/MyDrive/projects/TREX/TTS/key.json')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vddpburPqxOs"
      },
      "source": [
        "# @title | TTS | Google Cloud Text-To-Speech Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "import google.cloud.texttospeech as texttospeech\n",
        "import scipy\n",
        "\n",
        "\n",
        "def gcloud_tts(text: str, \n",
        "               voice_name: str=\"en-US-Wavenet-D\",\n",
        "               credentials=GCLOUD_TTS_CREDENTIALS) -> np.ndarray:\n",
        "    text_input = texttospeech.SynthesisInput(text=text)\n",
        "\n",
        "    language_code = \"-\".join(voice_name.split(\"-\")[:2])\n",
        "    voice_params = texttospeech.VoiceSelectionParams(\n",
        "        language_code=language_code, \n",
        "        name=voice_name)\n",
        "    \n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.LINEAR16)\n",
        "\n",
        "    client = texttospeech.TextToSpeechClient(\n",
        "        credentials=credentials)\n",
        "\n",
        "    response = client.synthesize_speech(\n",
        "        input=text_input, \n",
        "        voice=voice_params, \n",
        "        audio_config=audio_config)\n",
        "\n",
        "    filename = f\"{language_code}.wav\"\n",
        "    with open(filename, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "        print(f'Generated speech saved to \"{filename}\"')\n",
        "\n",
        "    rate, data = scipy.io.wavfile.read(filename)\n",
        "    return data"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAOU0Mf-qRJi"
      },
      "source": [
        "### Set up for audio processing utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2uJeHgl_pjHS"
      },
      "source": [
        "# @title | TTS | Audio Processing Utils\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchaudio import functional as F\n",
        "\n",
        "def postprocessing(wav: np.ndarray) -> np.ndarray:\n",
        "    wav = torch.from_numpy(wav)\n",
        "\n",
        "    wav = wav.unsqueeze(-1).T\n",
        "    wav = F.apply_codec(\n",
        "        waveform=wav, \n",
        "        sample_rate=22050,\n",
        "        format=\"wav\", \n",
        "        encoding=\"PCM_F\")\n",
        "    wav = F.resample(\n",
        "        waveform=wav, \n",
        "        orig_freq=22050, \n",
        "        new_freq=16000)\n",
        "\n",
        "    wav = wav.squeeze()\n",
        "    wav = wav.numpy()\n",
        "    \n",
        "    return wav"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgUr4Q6TJ6JH"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Avatar (PC-AVS)*** ðŸ¤—ðŸ¤–\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2pN_5QGY-G",
        "cellView": "form"
      },
      "source": [
        "# @title | PC-AVS | Install Dependencies â‡©\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_avatar_dependencies(**kwargs):\n",
        "    !git clone https://github.com/1ucky40nc3/Talking-Face_PC-AVS.git\n",
        "    %cd /content/Talking-Face_PC-AVS\n",
        "\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install lws\n",
        "    !pip install face-alignment\n",
        "    !pip install av\n",
        "    !pip install torchaudio\n",
        "\n",
        "    !unzip ./misc/Audio_Source.zip -d ./misc/\n",
        "    !unzip ./misc/Input.zip -d ./misc/\n",
        "    !unzip ./misc/Mouth_Source.zip -d ./misc/ \n",
        "    !unzip ./misc/Pose_Source.zip -d ./misc/\n",
        "\n",
        "    !gdown https://drive.google.com/u/0/uc?id=1Zehr3JLIpzdg2S5zZrhIbpYPKF-4gKU_&export=download\n",
        "    !mkdir checkpoints\n",
        "    !unzip demo.zip -d ./checkpoints/\n",
        "\n",
        "execute(install_avatar_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yeHLAfXGvNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "edab2973-f3fc-4b8d-d73d-01202e33f103"
      },
      "source": [
        "# @title | PC-AVS | PC-AVS Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "%cd /content/Talking-Face_PC-AVS\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.append('..')\n",
        "\n",
        "from data import create_dataloader\n",
        "from models import create_model\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "class Namespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "\n",
        "def pc_avs_inference(opt, \n",
        "                     path_label, \n",
        "                     model, \n",
        "                     wav) -> str:\n",
        "    opt.path_label = path_label\n",
        "    dataloader = create_dataloader(opt, wav=wav)\n",
        "\n",
        "    fake_image_driven_pose_as = []\n",
        "\n",
        "    for data_i in tqdm(dataloader):\n",
        "        _, fake_image_driven_pose_a = model.forward(\n",
        "            data_i, mode='inference')\n",
        "\n",
        "        fake_image_driven_pose_as.append(\n",
        "            fake_image_driven_pose_a)\n",
        "\n",
        "    filename = os.path.join(\n",
        "        dataloader.dataset.get_processed_file_savepath(), \n",
        "        \"G_Pose_Driven_.mp4\")\n",
        "\n",
        "    video_array = torch.cat(fake_image_driven_pose_as, dim=0)\n",
        "    video_array = video_array.cpu().transpose(1, 3)\n",
        "    video_array = video_array * 125.5 + 125.5 \n",
        "    video_array = video_array.type(torch.uint8)\n",
        "    video_array = torch.rot90(video_array, -1, [1, 2])\n",
        "\n",
        "    wav = torch.from_numpy(wav)\n",
        "    wav = torch.unsqueeze(wav, dim=0)\n",
        "    \n",
        "    torchvision.io.write_video(\n",
        "        filename=filename, \n",
        "        video_array=video_array,\n",
        "        fps=25,\n",
        "        video_codec=\"libx264\",\n",
        "        audio_array=wav,\n",
        "        audio_fps=16000,\n",
        "        audio_codec=\"aac\"\n",
        "    )    \n",
        "\n",
        "    del dataloader\n",
        "    return filename\n",
        "\n",
        "\n",
        "def avatar(opt,\n",
        "           path_label,\n",
        "           wav) -> str:\n",
        "    opt.isTrain = False\n",
        "\n",
        "    model = create_model(opt).cuda()\n",
        "    model.eval()\n",
        "\n",
        "    return pc_avs_inference(\n",
        "        opt, \n",
        "        path_label, \n",
        "        model, \n",
        "        wav)\n",
        "    \n",
        "\n",
        "opt = Namespace(\n",
        "    D_input='single', \n",
        "    VGGFace_pretrain_path='', \n",
        "    aspect_ratio=1.0, \n",
        "    audio_nc=256, \n",
        "    augment_target=False, \n",
        "    batchSize=16, \n",
        "    beta1=0.5, \n",
        "    beta2=0.999, \n",
        "    checkpoints_dir='./checkpoints', \n",
        "    clip_len=1, \n",
        "    crop=False, \n",
        "    crop_len=16, \n",
        "    crop_size=224, \n",
        "    data_path='/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv', \n",
        "    dataset_mode='voxtest', \n",
        "    defined_driven=False, \n",
        "    dis_feat_rec=False, \n",
        "    display_winsize=224, \n",
        "    driven_type='face', \n",
        "    driving_pose=True, \n",
        "    feature_encoded_dim=2560, \n",
        "    feature_fusion='concat', \n",
        "    filename_tmpl='{:06}.jpg', \n",
        "    fitting_iterations=10, \n",
        "    frame_interval=1, \n",
        "    frame_rate=25, \n",
        "    gan_mode='hinge', \n",
        "    gen_video=True, \n",
        "    generate_from_audio_only=True, \n",
        "    generate_interval=1, \n",
        "    gpu_ids=[0], \n",
        "    has_mask=False, \n",
        "    heatmap_size=3, \n",
        "    hop_size=160, \n",
        "    how_many=1000000, \n",
        "    init_type='xavier', \n",
        "    init_variance=0.02, \n",
        "    input_id_feature=True, \n",
        "    input_path='./checkpoints/results/input_path', \n",
        "    isTrain=False, \n",
        "    label_mask=False, \n",
        "    lambda_D=1, \n",
        "    lambda_contrastive=100, \n",
        "    lambda_crossmodal=1, \n",
        "    lambda_feat=10.0, \n",
        "    lambda_image=1.0, \n",
        "    lambda_rotate_D=0.1, \n",
        "    lambda_softmax=1000000, \n",
        "    lambda_vgg=10.0, \n",
        "    lambda_vggface=5.0, \n",
        "    landmark_align=False, \n",
        "    landmark_type='min', \n",
        "    list_end=1000000, \n",
        "    list_num=0, \n",
        "    list_start=0, \n",
        "    load_from_opt_file=False, \n",
        "    load_landmark=False, \n",
        "    lr=0.001, \n",
        "    lrw_data_path='/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv', \n",
        "    max_dataset_size=9223372036854775807, \n",
        "    meta_path_vox='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15/avatar.csv', \n",
        "    mode='cpu', \n",
        "    model='av', \n",
        "    multi_gpu=False, \n",
        "    nThreads=4, \n",
        "    n_mel_T=4, \n",
        "    name='demo', \n",
        "    ndf=64, \n",
        "    nef=16, \n",
        "    netA='resseaudio', \n",
        "    netA_sync='ressesync', \n",
        "    netD='multiscale', \n",
        "    netE='fan', \n",
        "    netG='modulate', \n",
        "    netV='resnext', \n",
        "    ngf=64, \n",
        "    no_TTUR=False, \n",
        "    no_flip=True, \n",
        "    no_ganFeat_loss=False, \n",
        "    no_gaussian_landmark=False, \n",
        "    no_id_loss=False, \n",
        "    no_instance=False, \n",
        "    no_pairing_check=False, \n",
        "    no_spectrogram=False, \n",
        "    no_vgg_loss=False, \n",
        "    noise_pose=True, \n",
        "    norm_A='spectralinstance', \n",
        "    norm_D='spectralinstance', \n",
        "    norm_E='spectralinstance', \n",
        "    norm_G='spectralinstance', \n",
        "    num_bins_per_frame=4, \n",
        "    num_classes=5830, \n",
        "    num_clips=1, \n",
        "    num_frames_per_clip=5, \n",
        "    num_inputs=1, \n",
        "    onnx=False, \n",
        "    optimizer='adam', \n",
        "    output_nc=3, \n",
        "    phase='test', \n",
        "    pose_dim=12, \n",
        "    positional_encode=False, \n",
        "    preprocess_mode='resize_and_crop', \n",
        "    results_dir='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15', \n",
        "    save_path='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15', \n",
        "    serial_batches=False, \n",
        "    start_ind=0, \n",
        "    style_dim=2560, \n",
        "    style_feature_loss=True, \n",
        "    target_crop_len=0, \n",
        "    train_dis_pose=False, \n",
        "    train_recognition=False, \n",
        "    train_sync=False, \n",
        "    train_word=False, \n",
        "    trainer='audio', \n",
        "    use_audio=1, \n",
        "    use_audio_id=0, \n",
        "    use_transformer=False, \n",
        "    verbose=False, \n",
        "    vgg_face=False, \n",
        "    which_epoch='latest', \n",
        "    word_loss=False\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Talking-Face_PC-AVS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG8kX8OHvA-U"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# ***T-REX*** ðŸ¦–ðŸ’¬\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXxUibBOvZWT",
        "cellView": "form"
      },
      "source": [
        "# @title | T-REX | Start new Conversation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the Skill Versions ðŸ‘€ðŸ”€\n",
        "SMALL_TALK_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TRAVEL_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TIMETABLE_SKILL_VERSION = \"legacy\" #@param [\"legacy\", \"ai21\"]\n",
        "TRANSLATION_COMPONENT = \"deepl\" #@param [\"legacy\", \"deepl\"]\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~\n",
        "NLP Configuration\n",
        "~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": {\n",
        "        \"to_native\": lambda x: x,\n",
        "        \"to_source\": lambda x: x,\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"to_native\": legacy_german_to_english_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_german_to_english_translation,\n",
        "        \"to_source\": legacy_english_to_german_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_english_to_german_translation,\n",
        "    }\n",
        "}\n",
        "\n",
        "SENTIMENT = {\n",
        "    \"positive\": [\"non-toxic\", \"travel\", \"small talk\"],\n",
        "    \"negative\": [\"toxic\", \"vulgar\"],\n",
        "}\n",
        "\n",
        "LEGACY_PERSONAS = {\n",
        "    \"warm_up\": legacy_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "LEGACY_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"num_return_sequences\": 2,\n",
        "    }, \n",
        "    \"function\": legacy_small_talk_skill\n",
        "}\n",
        "\n",
        "LEGACY_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"data\": travel_table,\n",
        "            \"time\": travel_time,\n",
        "            \"location\": travel_location,\n",
        "            \"samples\": legacy_travel_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_travel_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_travel_skill\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "AI21_PERSONAS = {\n",
        "    \"warm_up\": ai21_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "AI21_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"model\": \"j1-jumbo\",\n",
        "        \"samples\": ai21_small_talk_samples,\n",
        "        \"config\": {\n",
        "            \"num_results\": 10,\n",
        "            \"max_tokens\": 64,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.98,\n",
        "            \"stop_sequences\": [\"user >>\"],\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_small_talk_skill\n",
        "}\n",
        "\n",
        "AI21_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": travel_table,\n",
        "            \"time\": travel_time,\n",
        "            \"location\": travel_location,\n",
        "            \"samples\": ai21_travel_samples,\n",
        "            \"config\": {\n",
        "                \"max_tokens\": 100,\n",
        "                \"temperature\": 0.0,\n",
        "                \"top_p\": 1.0,\n",
        "                \"stop_sequences\": [\"\\n\\n\"],\n",
        "\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_travel_skill\n",
        "}\n",
        "\n",
        "PERSONAS = LEGACY_PERSONAS if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_PERSONAS\n",
        "\n",
        "SKILLS = {\n",
        "    \"travel\": {\n",
        "        \"labels\": [\"travel\", \"travel on time\", \"travel delayed\"],\n",
        "        \"pipeline\": LEGACY_TRAVEL_SKILL if TRAVEL_SKILL_VERSION == \"legacy\" else AI21_TRAVEL_SKILL\n",
        "    },\n",
        "    \"small talk\": {\n",
        "        \"labels\": [\"small talk\", \"other\"],\n",
        "        \"pipeline\": LEGACY_SMALL_TALK_SKILL if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_SMALL_TALK_SKILL\n",
        "    }\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"languages\": LANGUAGES,\n",
        "    \"sentiment\": SENTIMENT,\n",
        "    \"personas\": PERSONAS,\n",
        "    \"skills\": SKILLS,\n",
        "}\n",
        "\n",
        "#@markdown ---\n",
        "ACTIVATE_PERSONAS = False # @param {type:\"boolean\"}\n",
        "PERSONA_1 = \"I work in a travel agency\" # @param {type:\"string\"}\n",
        "PERSONA_1 = f\"your persona: {PERSONA_1}\"\n",
        "PERSONA_2 = \"My name is Mia\" # @param {type:\"string\"}\n",
        "PERSONA_2 = f\"your persona: {PERSONA_2}\"\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import copy\n",
        "import uuid\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "def trex_setup(**kwargs):\n",
        "    personas = copy.deepcopy(LEGACY_PERSONAS)\n",
        "    personas[\"personas\"] = [PERSONA_1, PERSONA_2] if ACTIVATE_PERSONAS else []\n",
        "\n",
        "    config = {\n",
        "        \"languages\": LANGUAGES,\n",
        "        \"personas\": personas,\n",
        "        \"skills\": SKILLS,\n",
        "        \"sentiment\": SENTIMENT,\n",
        "    }\n",
        "\n",
        "    nlp = NLP(config=config, **kwargs)\n",
        "\n",
        "    conversation_id = uuid.uuid4()\n",
        "    conversation_dir = f\"./conversations/{conversation_id}\"\n",
        "    !mkdir ./conversations/\n",
        "    !mkdir {conversation_dir}\n",
        "\n",
        "    interaction_counter = 0\n",
        "    f\"Current Conversation is logged at: {conversation_dir}\"\n",
        "\n",
        "    !rm -r /content/Talking-Face_PC-AVS/results/id_input_pose_00473_audio_tts_output\n",
        "\n",
        "    return nlp\n",
        "\n",
        "nlp = execute(trex_setup, verbose=VERBOSE)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWlnRnDoJ_gd",
        "cellView": "form"
      },
      "source": [
        "# @title # Interact with T-REX ðŸ¦–\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the STT & TTS Module Versions ðŸ‘€ðŸ”€\n",
        "STT_VERSION = \"gcloud\" #@param [\"legacy\", \"gcloud\"]\n",
        "TTS_VERSION = \"gcloud\" #@param [\"legacy\", \"gcloud\"]\n",
        "\n",
        "stt = legacy_stt if STT_VERSION == \"legacy\" else gcloud_stt\n",
        "tts = legacy_tts if TTS_VERSION == \"legacy\" else gcloud_tts\n",
        "\n",
        "LANGUAGE_CODE = \"de-DE\" if LANGUAGE == \"de\" else \"en-US\"\n",
        "\n",
        "#@markdown ### Selection Google Cloud TTS Voice ðŸ‘€ðŸ”€\n",
        "EN_TTS_VOICE_NAME = \"en-US-Wavenet-B\" #@param [\"en-US-Wavenet-A\", \"en-US-Wavenet-B\", \"en-US-Wavenet-C\", \"en-US-Wavenet-D\", \"en-US-Wavenet-E\", \"en-US-Wavenet-F\", \"en-US-Wavenet-G\", \"en-US-Wavenet-H\", \"en-US-Wavenet-I\", \"en-US-Wavenet-J\"]\n",
        "DE_TTS_VOICE_NAME = \"de-DE-Wavenet-A\" #@param [\"de-DE-Wavenet-A\", \"de-DE-Wavenet-B\", \"de-DE-Wavenet-C\", \"de-DE-Wavenet-D\", \"de-DE-Wavenet-E\", \"de-DE-Wavenet-F\"]\n",
        "\n",
        "VOICE_NAME = DE_TTS_VOICE_NAME if LANGUAGE == \"de\" else EN_TTS_VOICE_NAME\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Define the  Input\n",
        "USE_STT_AS_INPUT = True # @param {type:\"boolean\"}\n",
        "TEXT_INPUT = \"Wie geht es dir heute?\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "def trex(input: str=\"\", **kwargs) -> str:\n",
        "    print(f\"[DEBUG] |T-REX STT| STT Output: {input}\")\n",
        "\n",
        "    output = nlp(input, **kwargs)\n",
        "    print(f\"[DEBUG] |T-REX NLP| NLP Output: {output}\")\n",
        "\n",
        "    audio = tts(output, voice_name=VOICE_NAME)\n",
        "    audio = postprocessing(audio)\n",
        "\n",
        "    image_id = \"1\" if LANGUAGE == \"de\" else \"2\"\n",
        "    path_labels = f\"./misc/Input/input {image_id} ./misc/Pose_Source/00473 158 ./misc/Audio_Source/tts_output.mp3 None 0 None\"\n",
        "\n",
        "    video = avatar(\n",
        "        opt,\n",
        "        path_labels,\n",
        "        audio\n",
        "    )\n",
        "\n",
        "    return video\n",
        "\n",
        "input = stt(record(), language_code=LANGUAGE_CODE) if USE_STT_AS_INPUT else TEXT_INPUT\n",
        "video = execute(trex, input=input, verbose=VERBOSE)\n",
        "\n",
        "# Show the final output.\n",
        "mp4 = open(video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + base64.b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=700 controls autoplay>\n",
        "    <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJSj4o6TA86"
      },
      "source": [
        "---\n",
        "# ***Test*** TREX ðŸ¦–ðŸ’¬\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQKe2YbHZGG"
      },
      "source": [
        "## ***Test the NLP Module*** ðŸ“°ðŸ¤¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGNWpDXpStcm",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Utils for Testing\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from typing import Any\n",
        "from typing import Tuple\n",
        "from typing import List\n",
        "\n",
        "import io\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import transformers\n",
        "\n",
        "\n",
        "def get_nlp_models(\n",
        "    order: List[str] = [\n",
        "        \"SMALL_TALK\", \n",
        "        \"FEW_SHOT\", \n",
        "        \"TABLE_QA\", \n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\", \n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\"],\n",
        "    delimiter: str = \",\") -> str:\n",
        "    models = {\n",
        "        \"ZERO_SHOT\": ZERO_SHOT_MODEL,\n",
        "        \"SMALL_TALK\": SMALL_TALK_MODEL,\n",
        "        \"FEW_SHOT\": FEW_SHOT_MODEL,\n",
        "        \"TABLE_QA\": TABLE_QA_MODEL,\n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\": GERMAN_TO_ENGLISH_MODEL,\n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\": ENGLISH_TO_GERMAN_MODEL,\n",
        "    }\n",
        "    return delimiter.join([models[i] for i in order])\n",
        "\n",
        "def test(component: Any,\n",
        "         dataset: List[Tuple[Any]],\n",
        "         config: dict = {}) -> dict:\n",
        "    results = {**locals()}\n",
        "\n",
        "    predictions = []\n",
        "    for x, y in dataset:\n",
        "        predictions.append(\n",
        "            component(x, **config))\n",
        "    \n",
        "    results[\"predictions\"] = predictions\n",
        "    results[\"models\"] = get_nlp_models()\n",
        "    return results\n",
        "\n",
        "def upload_file(extension: str) -> bytes:\n",
        "    \"\"\"Upload files and return the content of the file with the extension.\"\"\"\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if extension in filename:\n",
        "            return uploaded[filename]\n",
        "    \n",
        "    raise Exception(\"No file with specified extension was found in the uploaded files!\\n\"\\\n",
        "                    \"Check the uploaded files and please retry the procedure!\")\n",
        "\n",
        "def dataframe_from_csv(content: bytes,\n",
        "                       **kwargs) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a csv file into a DataFrame.\"\"\"\n",
        "    return pd.read_csv(io.BytesIO(content))\n",
        "\n",
        "def dataframe_from_excel(content: bytes,\n",
        "                         sheet: str) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a excel sheet into a DataFrame.\"\"\"\n",
        "    return pd.read_excel(\n",
        "        io.BytesIO(content),\n",
        "        sheet_name=sheet)\n",
        "    \n",
        "def dataframe_from_type(type: str,\n",
        "                        content: bytes,\n",
        "                        sheet: str=None) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a file of the given type into a DataFrame.\"\"\"\n",
        "    function = {\n",
        "        \".xlsx\": dataframe_from_excel,\n",
        "        \".csv\": dataframe_from_csv,\n",
        "    }\n",
        "\n",
        "    return function[type](content, sheet=sheet)\n",
        "\n",
        "def preprocess_dataframe(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Convert a given DataFrame into testing format.\"\"\"\n",
        "    dataframe = dataframe.astype(\n",
        "        {column: str for column in dataframe.columns.values})\n",
        "    \n",
        "    return dataframe\n",
        "\n",
        "def parse_table_from_dataframe(dataframe: pd.DataFrame,\n",
        "                               excluded_headers: List[str],\n",
        "                               delimiter: str=\",\") -> str:\n",
        "    \"\"\"Convert the dataframe into a Table-QA table, excluding specified headers.\"\"\"\n",
        "    dataframe = dataframe.loc[:, ~dataframe.columns.isin(excluded_headers)]\n",
        "    \n",
        "    table = df_to_csv(dataframe)\n",
        "    table = table.replace(\",\", delimiter)\n",
        "    return table\n",
        "\n",
        "def parse_dict_from_dataframe(dataframe: pd.DataFrame,\n",
        "                              headers: list) -> dict:\n",
        "    \"\"\"Load a dataset as dict from a DataFrame restricting to the headers.\"\"\"\n",
        "    dataframe = dataframe.to_dict()\n",
        "    datafame = {key: value for key, value in dataframe.items()\n",
        "                    if key in headers}\n",
        "    return dataframe\n",
        "\n",
        "def dataset_from_dict(test: dict,\n",
        "                      header_x: str=\"x\",\n",
        "                      header_y: str=\"y\") -> List[Tuple[str]]:\n",
        "    \"\"\"Create a list of (x, y) tuples to execute a given test.\"\"\"\n",
        "    x, y = test[header_x], test[header_y]\n",
        "    \n",
        "    x = [x[i] for i in x.keys()]\n",
        "    y = [y[i] for i in y.keys()]\n",
        "\n",
        "    dataset = [(i, j) for i, j in zip(x, y)]\n",
        "    return dataset\n",
        "\n",
        "def preprocess_dataset(dataset: List[Tuple[str]]) -> List[Tuple[transformers.Conversation, str]]:\n",
        "    \"\"\"Prepare the dataset for testing.\"\"\"\n",
        "    def input_as_conversation(sample):\n",
        "        x, y = sample\n",
        "        return transformers.Conversation(x), y\n",
        "\n",
        "    dataset = list(map(input_as_conversation, dataset))\n",
        "    return dataset\n",
        "\n",
        "def save_test_results(results: dict, \n",
        "                      dictionary: dict,\n",
        "                      filename: str=\"test.xlsx\") -> str:\n",
        "    \"\"\"Save the results of the test as excel file and return the filename.\"\"\"\n",
        "    dictionary[\"Output\"] = {}\n",
        "\n",
        "    for i, prediction in enumerate(results[\"predictions\"]):\n",
        "        dictionary[\"Output\"][i] = prediction\n",
        "\n",
        "    dataframe = pd.DataFrame.from_dict(dictionary)\n",
        "    dataframe.to_excel(filename)\n",
        "\n",
        "    return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCk74Lnm7TXK",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Prepare Testing Data ðŸ“‹ ðŸ†’\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown Select a file type. The first file with the given extension will be loaded. ðŸ“—\n",
        "EXTENSION = \".xlsx\" #@param [\".xlsx\", \".csv\"]\n",
        "\n",
        "# @markdown Select a sheet if the file is an excel file. ðŸ“œ\t\n",
        "SHEET = \"Test1\" #@param {type: \"string\"}\n",
        "\n",
        "# @markdown Specify headers in the sheet that shall be included in the dataset. ðŸ“‹\n",
        "DATASET_HEADERS = \"Question, Answer\" #@param {type: \"string\"}\n",
        "DATASET_HEADERS = DATASET_HEADERS.split(\", \")\n",
        "\n",
        "assert len(DATASET_HEADERS) == 2, \"Warning! There can only be two dataset headers! Please refactor and retry!\"\n",
        "DATASET_HEADER_X, DATASET_HEADER_Y = DATASET_HEADERS\n",
        "\n",
        "# @markdown âœ¨ Note: The headers must be concatenated via the string \", \".\n",
        "\n",
        "\n",
        "uploaded_content = upload_file(EXTENSION)\n",
        "dataframe = dataframe_from_type(\n",
        "    EXTENSION, \n",
        "    uploaded_content, \n",
        "    SHEET)\n",
        "dataframe = preprocess_dataframe(dataframe)\n",
        "\n",
        "table = parse_table_from_dataframe(\n",
        "    dataframe,\n",
        "    EXCLUDED_HEADERS)\n",
        "\n",
        "dictionary = parse_dict_from_dataframe(\n",
        "    dataframe,\n",
        "    DATASET_HEADERS)\n",
        "dataset = dataset_from_dict(\n",
        "    dictionary,\n",
        "    DATASET_HEADER_X,\n",
        "    DATASET_HEADER_Y)\n",
        "dataset = preprocess_dataset(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4c0bUZm1DGT",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Display the Dataset ðŸ“‹ðŸŽ‰\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(\n",
        "    pd.DataFrame(\n",
        "        dataset_from_dict(\n",
        "            dictionary,\n",
        "            DATASET_HEADER_X,\n",
        "            DATASET_HEADER_Y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nztBbD3cJN2",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Test Component ðŸ‘»\n",
        "# @markdown ---\n",
        "\n",
        "import uuid\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta as td\n",
        "from datetime import timezone as tz\n",
        "\n",
        "\n",
        "FILENAME = f\"Test_NLP_%u_%t.xlsx\" #@param {type: \"string\"}\n",
        "# @markdown âš¡ Select if a UUID shall be substituted for the **%u** string.\n",
        "UUID = True # @param {type:\"boolean\"}\n",
        "# @markdown âœ¨ Note: **%t** in the filename will the replaced with the current timestamp.\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "uuid_ = f\"_{str(uuid.uuid4())}_\" if UUID else \"\"\n",
        "filename = FILENAME.replace(\"_%u_\", uuid_)\n",
        "\n",
        "timestamp = dt.now() + td(hours=2)\n",
        "timestamp = f\"{timestamp:%Y%m%d%H%M}\"\n",
        "filename = filename.replace(\"%t\", timestamp)\n",
        "\n",
        "nlp = NLP(config=CONFIG)\n",
        "\n",
        "results = test(\n",
        "    nlp,\n",
        "    dataset,\n",
        "    {\"verbose\": VERBOSE})\n",
        "\n",
        "save_test_results(\n",
        "    results,\n",
        "    dictionary,\n",
        "    filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TREX.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "e0AFeWgzwFgr",
        "QsG51nhh1Lkj",
        "kUMHIlD8Tj7g",
        "-uSXlrc5UXis",
        "8yY2gJS0hZWw",
        "oKuBPzcJWaOu",
        "k_Zo09hxv31Y",
        "12V9_IDkmwq-",
        "jnD_dmwAm8BI",
        "BKsJj9mKnd1G",
        "ZXF876tBJ6I8",
        "0DVfrA6NpQuo",
        "8fqGpEURp38G",
        "WAOU0Mf-qRJi",
        "xgUr4Q6TJ6JH",
        "hG8kX8OHvA-U",
        "pkJSj4o6TA86",
        "BMQKe2YbHZGG"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOUbqmSefmSHFdO2V1ddR0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/TREX/blob/main/TREX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCNgpK3tZbZ",
        "cellView": "form",
        "outputId": "88f0e006-21e4-43fe-9177-781eadf581f2"
      },
      "source": [
        "# @title Check if Runtime is connected with a GPU ❓ 💪 \n",
        "!nvidia-smi"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  3 08:41:51 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |   2780MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3SM312SP6v6"
      },
      "source": [
        "# ***Set up TREX*** 🦖💬\t\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78i3mCfXdyK1",
        "cellView": "form"
      },
      "source": [
        "# @title Utils for the entire Notebook\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "from IPython.utils.io import capture_output\n",
        "\n",
        "\n",
        "def execute(func, *args, verbose: bool = False, **kwargs):\n",
        "    if verbose:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})\n",
        "    \n",
        "    with capture_output() as captured:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0AFeWgzwFgr"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Natural Language Processing (NLP)*** 📰🤯\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "RSVfnYbnkrXo"
      },
      "source": [
        "#@markdown ### Language selection during operation 🏳️‍🌈/🏴‍☠️\n",
        "LANGUAGE = \"de\" #@param [\"en\", \"de\"]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mC4zn53LYTw9",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Install Dependencies ⇩\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "    \n",
        "\n",
        "def install_nlp_dependencies(**kwargs):\n",
        "    !pip install sentencepiece\n",
        "    !pip install transformers\n",
        "    !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "    !pip install torch-geometric\n",
        "    !pip install torch-scatter==2.0.8 -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "\n",
        "execute(install_nlp_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BCVsSIKb1LkH"
      },
      "source": [
        "# @title | NLP | Set up Services for Data\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "from typing import Any\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "import transformers\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for general utilities.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "DATE = \"2021-08-29\" #@param {type: \"string\"}\n",
        "TIME = \"7:00\" #@param {type: \"string\"}\n",
        "LOCATION = \"Munich\" #@param {type: \"string\"}\n",
        "\n",
        "def date() -> str:\n",
        "    return DATE\n",
        "\n",
        "def time() -> str:\n",
        "    return TIME\n",
        "\n",
        "def location() -> str:\n",
        "    return LOCATION\n",
        "\n",
        "def set_dtype(df: pd.DataFrame, dtype: Any) -> pd.DataFrame:\n",
        "    return df.astype({column: dtype for column in df.columns.values})\n",
        "\n",
        "def df_to_csv(df) -> str:\n",
        "    csv = io.StringIO()\n",
        "    df.to_csv(csv, index=False)\n",
        "    return csv.getvalue()\n",
        "\n",
        "def table(string: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(\n",
        "        io.StringIO(string))\n",
        "    df = set_dtype(df, str)\n",
        "\n",
        "    return df\n",
        " \n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities to create travel tables.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "DE_TRAVEL_TABLE = \"\"\"Location,Train,Start,Destination,Departure Time,Arrival Time,Departure Track,Arrival Track,Duration\n",
        "Rödermark,RB61,Rödermark,Frankfurt (Main) Hauptbahnhof,15:31,15:30,2,2,0:30\n",
        "Rödermark,RB61,Rödermark,Dieburg Bahnhof,15:47,15:46,1,1,0:16\n",
        "Rödermark,RB61,Rödermark,Frankfurt (Main) Südbahnhof,16:00,15:59,2,2,0:30\n",
        "Rödermark,RB61,Rödermark,Rödermark-Ober-Roden Bahnhof,16:17,16:16,1,1,0:03\n",
        "München,ICE 1655,Frankfurt(Main)Hbf,Leipzig Hbf,17:21,20:24,9,14,03:03\n",
        "München,ICE 594,Frankfurt(Main)Hbf,Leipzig Hbf,18:14,21:10,9,13,02:56\n",
        "München,FLX 1354,Berlin Hbf (tief),Hamburg Hbf,08:07,10:07,8,5,02:00\n",
        "München,ICE 806,Berlin Hbf (tief),Hamburg Hbf,08:38,10:21,8,5,01:43\n",
        "München,ICE 598,Stuttgart Hbf,Mannheim Hbf,12:51,13:29,9,2,00:38\n",
        "München,ICE 576,Stuttgart Hbf,Mannheim Hbf,13:23,14:02,10,3,00:39\n",
        "München,ICE 1223,Nürnberg Hbf,München Hbf,14:07,15:12,9,22,01:05\n",
        "München,ICE 705,Nürnberg Hbf,München Hbf,14:55,16:07,8,21,01:12\"\"\"\n",
        "\n",
        "EN_TRAVEL_TABLE = \"\"\"Location,Train,Start,Destination,Departure Time,Arrival Time,Departure Track,Arrival Track,Duration\n",
        "Rödermark,RB61,Rodermark,Frankfurt (Main) main station,15:31,15:30,2,2,0:30\n",
        "Rödermark,RB61,Rodermark,Dieburg train station,15:47,15:46,1,1,0:16\n",
        "Rödermark,RB61,Rodermark,Frankfurt (Main) Südbahnhof,16:00,15:59,2,2,0:30\n",
        "Rödermark,RB61,Rodermark,Rödermark-Ober-Roden station,16:17,16:16,1,1,0:03\n",
        "München,ICE 1655,Frankfurt(Main)Hbf,Leipzig Hbf,17:21,20:24,9,14,03:03\n",
        "München,ICE 594,Frankfurt(Main)Hbf,Leipzig Hbf,18:14,21:10,9,13,02:56\n",
        "Munich,FLX 1354,Berlin Hbf (low),Hamburg Hbf,08:07,10:07,8,5,02:00\n",
        "Munich,ICE 806,Berlin Hbf (low),Hamburg Hbf,08:38,10:21,8,5,01:43\n",
        "Munich,ICE 598,Stuttgart Hbf,Mannheim Hbf,12:51,13:29,9,2,00:38\n",
        "Munich,ICE 576,Stuttgart Hbf,Mannheim Hbf,13:23,14:02,10,3,00:39\n",
        "Munich,ICE 1223,Nuremberg Hbf,Munich Hbf,14:07,15:12,9,22,01:05\n",
        "Munich,ICE 705,Nuremberg Hbf,Munich Hbf,14:55,16:07,8,21,01:12\"\"\"\n",
        "\n",
        "def travel_table() -> pd.DataFrame:\n",
        "    string = DE_TRAVEL_TABLE if LANGUAGE == \"de\" else EN_TRAVEL_TABLE\n",
        "    return table(string)\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities to create event tables.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "EVENT_TABLE = \"\"\"Title,Date,Start,End,Description,Location\n",
        "Literary reading tour with Lou Heinrich,2021-09-17,18:30,19:30,Excerpts from the novel cycle \"Leute von Seldwyla\" will be presented,Bücherturm Ober-Roden Trinkbrunnenstr. 8 Raum Rothahasaal 63322 Rödermark\n",
        "Autumn-Winter-Bazaar,2021-09-18,14:00,16:00,Autumn-Winter-Bazaar of the Förderverein Kindergarten St. Gallus and Rejoice,Halle Urberach Am Schellbusch 2 63322 Rödermark\n",
        "Urban Priol \"In the river\" cabaret,2021-09-23,20:00,22:15,nan,Kulturhalle Rödermark\n",
        "Musical \"Ausgetickt?\",2021-09-26,15:00,17:00,Musical for children from 8-13 years with the Rejoice Kids & Teens.,KSV Halle Turngartenstraße 63322 Rödermark\n",
        "Info evening \"Well prepared for self-employment\",2021-09-29,19:00,21:00,This free info event \"Well prepared for self-employment\" will be held with the team of our cooperation partner \"gruenderberatungen.de\",Rathaus Ober-Roden Dieburger Straße 9-11 im Zehnthof 63322 Rödermark\"\"\"\n",
        "\n",
        "def event_table() -> pd.DataFrame:\n",
        "    return table(EVENT_TABLE)\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities to create restaurant tables.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "RESTAURANT_TABLE = \"\"\"Restaurant Name,Price Class,Average Rating,Distance,Category\n",
        "Wolfsschlucht Restaurant,3.0,4.0,14.4,German\n",
        "Reatuarant zagreb,3.0,4.5,1.1,Balkan\n",
        "Pizzeria Romana,2.0,4.5,2.1,Italian\n",
        "La Scala,2.0,4.0,0.6,Italian\n",
        "Ristaurante Tie-Break,2.0,4.5,2.2,Italian\n",
        "Cuervo,2.0,4.0,0.7,Mexican\"\"\"\n",
        "\n",
        "def restaurant_table() -> pd.DataFrame:\n",
        "    return table(RESTAURANT_TABLE)\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities to create restaurant tables.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "TIMETABLE_TABLE = \"\"\"Name,Day,Date,Start Time,End Time,Duration,Professor,Room,Virtual Room\n",
        "Current Affairs,Monday,2021-08-30,12:15,12:45,30.0,None,Assembly hall,None\n",
        "IT Law,Monday,2021-08-30,12:45,16:00,195.0,Leonardo da Vinci,Assembly hall,None\n",
        "Design and Implementation of Databases,Tuesday,2021-08-31,08:30,11:45,195.0,Alan Turing,Assembly hall,None\n",
        "Finance and Investment,Tuesday,2021-08-31,12:45,16:00,195.0,Henry Ford,Assembly hall,None\n",
        "Practice/Project groups,Wednesday,2021-09-01,08:30,16:00,450.0,None,None,None\n",
        "Practice/Project groups,Thursday,2021-09-02,08:30,16:00,450.0,None,None,None\n",
        "Servicemanagement und ERP,Friday,2021-09-03,08:30,11:45,195.0,Nikola Tesla,Assembly hall,None\"\"\"\n",
        "\n",
        "def timetable_table() -> pd.DataFrame:\n",
        "    return table(TIMETABLE_TABLE)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsG51nhh1Lkj"
      },
      "source": [
        "#### Display the Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "_iGDLzcE1Lkk",
        "outputId": "3b51b58a-f178-4a98-ff10-eb62da06fc6b"
      },
      "source": [
        "# @title Display the Travel Table\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(travel_table())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"R\\u00f6dermark\",\n\"RB61\",\n\"R\\u00f6dermark\",\n\"Frankfurt (Main) Hauptbahnhof\",\n\"15:31\",\n\"15:30\",\n\"2\",\n\"2\",\n\"0:30\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"R\\u00f6dermark\",\n\"RB61\",\n\"R\\u00f6dermark\",\n\"Dieburg Bahnhof\",\n\"15:47\",\n\"15:46\",\n\"1\",\n\"1\",\n\"0:16\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"R\\u00f6dermark\",\n\"RB61\",\n\"R\\u00f6dermark\",\n\"Frankfurt (Main) S\\u00fcdbahnhof\",\n\"16:00\",\n\"15:59\",\n\"2\",\n\"2\",\n\"0:30\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"R\\u00f6dermark\",\n\"RB61\",\n\"R\\u00f6dermark\",\n\"R\\u00f6dermark-Ober-Roden Bahnhof\",\n\"16:17\",\n\"16:16\",\n\"1\",\n\"1\",\n\"0:03\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 1655\",\n\"Frankfurt(Main)Hbf\",\n\"Leipzig Hbf\",\n\"17:21\",\n\"20:24\",\n\"9\",\n\"14\",\n\"03:03\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 594\",\n\"Frankfurt(Main)Hbf\",\n\"Leipzig Hbf\",\n\"18:14\",\n\"21:10\",\n\"9\",\n\"13\",\n\"02:56\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"M\\u00fcnchen\",\n\"FLX 1354\",\n\"Berlin Hbf (tief)\",\n\"Hamburg Hbf\",\n\"08:07\",\n\"10:07\",\n\"8\",\n\"5\",\n\"02:00\"],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 806\",\n\"Berlin Hbf (tief)\",\n\"Hamburg Hbf\",\n\"08:38\",\n\"10:21\",\n\"8\",\n\"5\",\n\"01:43\"],\n [{\n            'v': 8,\n            'f': \"8\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 598\",\n\"Stuttgart Hbf\",\n\"Mannheim Hbf\",\n\"12:51\",\n\"13:29\",\n\"9\",\n\"2\",\n\"00:38\"],\n [{\n            'v': 9,\n            'f': \"9\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 576\",\n\"Stuttgart Hbf\",\n\"Mannheim Hbf\",\n\"13:23\",\n\"14:02\",\n\"10\",\n\"3\",\n\"00:39\"],\n [{\n            'v': 10,\n            'f': \"10\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 1223\",\n\"N\\u00fcrnberg Hbf\",\n\"M\\u00fcnchen Hbf\",\n\"14:07\",\n\"15:12\",\n\"9\",\n\"22\",\n\"01:05\"],\n [{\n            'v': 11,\n            'f': \"11\",\n        },\n\"M\\u00fcnchen\",\n\"ICE 705\",\n\"N\\u00fcrnberg Hbf\",\n\"M\\u00fcnchen Hbf\",\n\"14:55\",\n\"16:07\",\n\"8\",\n\"21\",\n\"01:12\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Location\"], [\"string\", \"Train\"], [\"string\", \"Start\"], [\"string\", \"Destination\"], [\"string\", \"Departure Time\"], [\"string\", \"Arrival Time\"], [\"string\", \"Departure Track\"], [\"string\", \"Arrival Track\"], [\"string\", \"Duration\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Train</th>\n",
              "      <th>Start</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Departure Time</th>\n",
              "      <th>Arrival Time</th>\n",
              "      <th>Departure Track</th>\n",
              "      <th>Arrival Track</th>\n",
              "      <th>Duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rödermark</td>\n",
              "      <td>RB61</td>\n",
              "      <td>Rödermark</td>\n",
              "      <td>Frankfurt (Main) Hauptbahnhof</td>\n",
              "      <td>15:31</td>\n",
              "      <td>15:30</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rödermark</td>\n",
              "      <td>RB61</td>\n",
              "      <td>Rödermark</td>\n",
              "      <td>Dieburg Bahnhof</td>\n",
              "      <td>15:47</td>\n",
              "      <td>15:46</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rödermark</td>\n",
              "      <td>RB61</td>\n",
              "      <td>Rödermark</td>\n",
              "      <td>Frankfurt (Main) Südbahnhof</td>\n",
              "      <td>16:00</td>\n",
              "      <td>15:59</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0:30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rödermark</td>\n",
              "      <td>RB61</td>\n",
              "      <td>Rödermark</td>\n",
              "      <td>Rödermark-Ober-Roden Bahnhof</td>\n",
              "      <td>16:17</td>\n",
              "      <td>16:16</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 1655</td>\n",
              "      <td>Frankfurt(Main)Hbf</td>\n",
              "      <td>Leipzig Hbf</td>\n",
              "      <td>17:21</td>\n",
              "      <td>20:24</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>03:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 594</td>\n",
              "      <td>Frankfurt(Main)Hbf</td>\n",
              "      <td>Leipzig Hbf</td>\n",
              "      <td>18:14</td>\n",
              "      <td>21:10</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>02:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>München</td>\n",
              "      <td>FLX 1354</td>\n",
              "      <td>Berlin Hbf (tief)</td>\n",
              "      <td>Hamburg Hbf</td>\n",
              "      <td>08:07</td>\n",
              "      <td>10:07</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>02:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 806</td>\n",
              "      <td>Berlin Hbf (tief)</td>\n",
              "      <td>Hamburg Hbf</td>\n",
              "      <td>08:38</td>\n",
              "      <td>10:21</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 598</td>\n",
              "      <td>Stuttgart Hbf</td>\n",
              "      <td>Mannheim Hbf</td>\n",
              "      <td>12:51</td>\n",
              "      <td>13:29</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>00:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 576</td>\n",
              "      <td>Stuttgart Hbf</td>\n",
              "      <td>Mannheim Hbf</td>\n",
              "      <td>13:23</td>\n",
              "      <td>14:02</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 1223</td>\n",
              "      <td>Nürnberg Hbf</td>\n",
              "      <td>München Hbf</td>\n",
              "      <td>14:07</td>\n",
              "      <td>15:12</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>01:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>München</td>\n",
              "      <td>ICE 705</td>\n",
              "      <td>Nürnberg Hbf</td>\n",
              "      <td>München Hbf</td>\n",
              "      <td>14:55</td>\n",
              "      <td>16:07</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "7e03uyL01Lkk",
        "outputId": "ef08b3dd-9670-4da3-86c6-f37e998f60d7"
      },
      "source": [
        "# @title Display the Event Table\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(event_table())"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Literary reading tour with Lou Heinrich\",\n\"2021-09-17\",\n\"18:30\",\n\"19:30\",\n\"Excerpts from the novel cycle \\\"Leute von Seldwyla\\\" will be presented\",\n\"B\\u00fccherturm Ober-Roden Trinkbrunnenstr. 8 Raum Rothahasaal 63322 R\\u00f6dermark\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Autumn-Winter-Bazaar\",\n\"2021-09-18\",\n\"14:00\",\n\"16:00\",\n\"Autumn-Winter-Bazaar of the F\\u00f6rderverein Kindergarten St. Gallus and Rejoice\",\n\"Halle Urberach Am Schellbusch 2 63322 R\\u00f6dermark\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Urban Priol \\\"In the river\\\" cabaret\",\n\"2021-09-23\",\n\"20:00\",\n\"22:15\",\n\"nan\",\n\"Kulturhalle R\\u00f6dermark\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Musical \\\"Ausgetickt?\\\"\",\n\"2021-09-26\",\n\"15:00\",\n\"17:00\",\n\"Musical for children from 8-13 years with the Rejoice Kids & Teens.\",\n\"KSV Halle Turngartenstra\\u00dfe 63322 R\\u00f6dermark\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Info evening \\\"Well prepared for self-employment\\\"\",\n\"2021-09-29\",\n\"19:00\",\n\"21:00\",\n\"This free info event \\\"Well prepared for self-employment\\\" will be held with the team of our cooperation partner \\\"gruenderberatungen.de\\\"\",\n\"Rathaus Ober-Roden Dieburger Stra\\u00dfe 9-11 im Zehnthof 63322 R\\u00f6dermark\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Title\"], [\"string\", \"Date\"], [\"string\", \"Start\"], [\"string\", \"End\"], [\"string\", \"Description\"], [\"string\", \"Location\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Date</th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Description</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Literary reading tour with Lou Heinrich</td>\n",
              "      <td>2021-09-17</td>\n",
              "      <td>18:30</td>\n",
              "      <td>19:30</td>\n",
              "      <td>Excerpts from the novel cycle \"Leute von Seldw...</td>\n",
              "      <td>Bücherturm Ober-Roden Trinkbrunnenstr. 8 Raum ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Autumn-Winter-Bazaar</td>\n",
              "      <td>2021-09-18</td>\n",
              "      <td>14:00</td>\n",
              "      <td>16:00</td>\n",
              "      <td>Autumn-Winter-Bazaar of the Förderverein Kinde...</td>\n",
              "      <td>Halle Urberach Am Schellbusch 2 63322 Rödermark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Urban Priol \"In the river\" cabaret</td>\n",
              "      <td>2021-09-23</td>\n",
              "      <td>20:00</td>\n",
              "      <td>22:15</td>\n",
              "      <td>nan</td>\n",
              "      <td>Kulturhalle Rödermark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Musical \"Ausgetickt?\"</td>\n",
              "      <td>2021-09-26</td>\n",
              "      <td>15:00</td>\n",
              "      <td>17:00</td>\n",
              "      <td>Musical for children from 8-13 years with the ...</td>\n",
              "      <td>KSV Halle Turngartenstraße 63322 Rödermark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Info evening \"Well prepared for self-employment\"</td>\n",
              "      <td>2021-09-29</td>\n",
              "      <td>19:00</td>\n",
              "      <td>21:00</td>\n",
              "      <td>This free info event \"Well prepared for self-e...</td>\n",
              "      <td>Rathaus Ober-Roden Dieburger Straße 9-11 im Ze...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "cellView": "form",
        "id": "mKUvgshh1Lkk",
        "outputId": "35e9044a-d1c5-465b-e75c-589db00fb1b4"
      },
      "source": [
        "# @title Display the Restaurant Table\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(restaurant_table())"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Wolfsschlucht Restaurant\",\n\"3.0\",\n\"4.0\",\n\"14.4\",\n\"German\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Reatuarant zagreb\",\n\"3.0\",\n\"4.5\",\n\"1.1\",\n\"Balkan\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Pizzeria Romana\",\n\"2.0\",\n\"4.5\",\n\"2.1\",\n\"Italian\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"La Scala\",\n\"2.0\",\n\"4.0\",\n\"0.6\",\n\"Italian\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Ristaurante Tie-Break\",\n\"2.0\",\n\"4.5\",\n\"2.2\",\n\"Italian\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Cuervo\",\n\"2.0\",\n\"4.0\",\n\"0.7\",\n\"Mexican\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Restaurant Name\"], [\"string\", \"Price Class\"], [\"string\", \"Average Rating\"], [\"string\", \"Distance\"], [\"string\", \"Category\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Restaurant Name</th>\n",
              "      <th>Price Class</th>\n",
              "      <th>Average Rating</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wolfsschlucht Restaurant</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>German</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Reatuarant zagreb</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>Balkan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Pizzeria Romana</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>La Scala</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ristaurante Tie-Break</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>Italian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cuervo</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>Mexican</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "cellView": "form",
        "id": "3xZ7JbCT1Lkl",
        "outputId": "edeadbb0-8942-455c-b02c-c6488bee0258"
      },
      "source": [
        "# @title Display the Timetable Table\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(timetable_table())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"Current Affairs\",\n\"Monday\",\n\"2021-08-30\",\n\"12:15\",\n\"12:45\",\n\"30.0\",\n\"None\",\n\"Assembly hall\",\n\"None\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"IT Law\",\n\"Monday\",\n\"2021-08-30\",\n\"12:45\",\n\"16:00\",\n\"195.0\",\n\"Leonardo da Vinci\",\n\"Assembly hall\",\n\"None\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"Design and Implementation of Databases\",\n\"Tuesday\",\n\"2021-08-31\",\n\"08:30\",\n\"11:45\",\n\"195.0\",\n\"Alan Turing\",\n\"Assembly hall\",\n\"None\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"Finance and Investment\",\n\"Tuesday\",\n\"2021-08-31\",\n\"12:45\",\n\"16:00\",\n\"195.0\",\n\"Henry Ford\",\n\"Assembly hall\",\n\"None\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"Practice/Project groups\",\n\"Wednesday\",\n\"2021-09-01\",\n\"08:30\",\n\"16:00\",\n\"450.0\",\n\"None\",\n\"None\",\n\"None\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Practice/Project groups\",\n\"Thursday\",\n\"2021-09-02\",\n\"08:30\",\n\"16:00\",\n\"450.0\",\n\"None\",\n\"None\",\n\"None\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"Servicemanagement und ERP\",\n\"Friday\",\n\"2021-09-03\",\n\"08:30\",\n\"11:45\",\n\"195.0\",\n\"Nikola Tesla\",\n\"Assembly hall\",\n\"None\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Name\"], [\"string\", \"Day\"], [\"string\", \"Date\"], [\"string\", \"Start Time\"], [\"string\", \"End Time\"], [\"string\", \"Duration\"], [\"string\", \"Professor\"], [\"string\", \"Room\"], [\"string\", \"Virtual Room\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Day</th>\n",
              "      <th>Date</th>\n",
              "      <th>Start Time</th>\n",
              "      <th>End Time</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Professor</th>\n",
              "      <th>Room</th>\n",
              "      <th>Virtual Room</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Current Affairs</td>\n",
              "      <td>Monday</td>\n",
              "      <td>2021-08-30</td>\n",
              "      <td>12:15</td>\n",
              "      <td>12:45</td>\n",
              "      <td>30.0</td>\n",
              "      <td>None</td>\n",
              "      <td>Assembly hall</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IT Law</td>\n",
              "      <td>Monday</td>\n",
              "      <td>2021-08-30</td>\n",
              "      <td>12:45</td>\n",
              "      <td>16:00</td>\n",
              "      <td>195.0</td>\n",
              "      <td>Leonardo da Vinci</td>\n",
              "      <td>Assembly hall</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Design and Implementation of Databases</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>08:30</td>\n",
              "      <td>11:45</td>\n",
              "      <td>195.0</td>\n",
              "      <td>Alan Turing</td>\n",
              "      <td>Assembly hall</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finance and Investment</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>2021-08-31</td>\n",
              "      <td>12:45</td>\n",
              "      <td>16:00</td>\n",
              "      <td>195.0</td>\n",
              "      <td>Henry Ford</td>\n",
              "      <td>Assembly hall</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Practice/Project groups</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>2021-09-01</td>\n",
              "      <td>08:30</td>\n",
              "      <td>16:00</td>\n",
              "      <td>450.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Practice/Project groups</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>2021-09-02</td>\n",
              "      <td>08:30</td>\n",
              "      <td>16:00</td>\n",
              "      <td>450.0</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Servicemanagement und ERP</td>\n",
              "      <td>Friday</td>\n",
              "      <td>2021-09-03</td>\n",
              "      <td>08:30</td>\n",
              "      <td>11:45</td>\n",
              "      <td>195.0</td>\n",
              "      <td>Nikola Tesla</td>\n",
              "      <td>Assembly hall</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUMHIlD8Tj7g"
      },
      "source": [
        "### Set up fot the ***Legacy NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1U9U9gdwKig",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Initialize the NLP Pipelines\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "\n",
        "def device(boolean: bool) -> int:\n",
        "    return 0 if boolean else -1\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Model selection for the NLP toolkit 🤖📰\n",
        "ZERO_SHOT_MODEL = \"facebook/bart-large-mnli\" #@param [\"facebook/bart-large-mnli\", \"typeform/distilbert-base-uncased-mnli\", \"joeddav/xlm-roberta-large-xnli\", \"Narsil/deberta-large-mnli-zero-cls\"]\n",
        "TABLE_QA_MODEL = \"google/tapas-large-finetuned-wikisql-supervised\" #@param [\"lysandre/tiny-tapas-random-wtq\", \"lysandre/tiny-tapas-random-sqa\", \"google/tapas-base-finetuned-wtq\", \"google/tapas-base-finetuned-sqa\", \"google/tapas-base-finetuned-wikisql-supervised\", \"google/tapas-large-finetuned-wtq\", \"google/tapas-large-finetuned-sqa\", \"google/tapas-large-finetuned-wikisql-supervised\"]\n",
        "SMALL_TALK_MODEL = \"facebook/blenderbot-90M\" #@param [\"facebook/blenderbot-90M\", \"facebook/blenderbot-400M-distill\", \"facebook/blenderbot-1B-distill\", \"facebook/blenderbot-3B\"]\n",
        "FEW_SHOT_MODEL = \"EleutherAI/gpt-neo-125M\" #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"EleutherAI/gpt-neo-125M\", \"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Model selection for translation between English and German\n",
        "GERMAN_TO_ENGLISH_MODEL = \"Helsinki-NLP/opus-mt-de-en\" #@param [\"Helsinki-NLP/opus-mt-de-en\", \"facebook/wmt19-de-en\"]\n",
        "ENGLISH_TO_GERMAN_MODEL = \"Helsinki-NLP/opus-mt-en-de\" #@param [\"Helsinki-NLP/opus-mt-en-de\", \"facebook/wmt19-en-de\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Select if the individual model shall be on GPU 💻🔥\n",
        "USE_GPU_FOR_ZERO_SHOT = True # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_SMALL_TALK = False # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_FEW_SHOT = False # @param {type:\"boolean\"}\n",
        "\n",
        "USE_GPU_FOR_GERMAN_TO_ENGLISH = False # @param {type:\"boolean\"}\n",
        "USE_GPU_FOR_ENGLISH_TO_GERMAN = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "    \n",
        "\n",
        "def initialize_nlp_pipelines(**kwargs):\n",
        "    print(\"[DEBUG] Downloading Zero-Shot-Classification Components\")\n",
        "    ZERO_SHOT = transformers.pipeline(\n",
        "        \"zero-shot-classification\",\n",
        "        model=ZERO_SHOT_MODEL,\n",
        "        device=device(USE_GPU_FOR_ZERO_SHOT))\n",
        "    \n",
        "    print(\"[DEBUG] Downloading Table-QA Components\")\n",
        "    TABLE_QA = transformers.pipeline(\n",
        "        \"table-question-answering\", \n",
        "        model=TABLE_QA_MODEL)\n",
        "\n",
        "    print(\"[DEBUG] Downloading Small-Talk Components\")\n",
        "    SMALL_TALK = transformers.pipeline(\n",
        "        \"conversational\", \n",
        "        model=SMALL_TALK_MODEL, \n",
        "        device=device(USE_GPU_FOR_SMALL_TALK))\n",
        "\n",
        "    print(\"[DEBUG] Downloading Text-To-Text Components\")\n",
        "    FEW_SHOT = transformers.pipeline(\n",
        "        \"text-generation\", \n",
        "        model=FEW_SHOT_MODEL, \n",
        "        device=device(USE_GPU_FOR_FEW_SHOT))\n",
        "    FEW_SHOT_TOKENIZER = transformers.GPT2Tokenizer.from_pretrained(\n",
        "        FEW_SHOT_MODEL)\n",
        "    \n",
        "    if LANGUAGE == \"de\":\n",
        "        print(\"[DEBUG] Downloading German-To-English Translation Components\")\n",
        "        GERMAN_TO_ENGLISH_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_de_to_en\", \n",
        "            model=GERMAN_TO_ENGLISH_MODEL)\n",
        "        print(\"[DEBUG] Downloading English-To-German Translation Components\")\n",
        "        ENGLISH_TO_GERMAN_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_en_to_de\", \n",
        "            model=ENGLISH_TO_GERMAN_MODEL)\n",
        "    \n",
        "    return locals()\n",
        "\n",
        "PIPELINES = execute(initialize_nlp_pipelines, verbose=VERBOSE)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDT5V9m2w3sQ",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Legacy NLP Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from typing import Callable\n",
        "from typing import Optional\n",
        "\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Classification on a Zero-Shot basis.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def zero_shot_classification(input: str, \n",
        "                             labels: List[str], \n",
        "                             top_k: Optional[int] = 1,\n",
        "                             **kwargs) -> List[str]:\n",
        "    return PIPELINES[\"ZERO_SHOT\"](input, labels)[\"labels\"][:top_k]\n",
        "\n",
        "def skill_classification(input: str, \n",
        "                         skills: List[str], \n",
        "                         verbose: Optional[bool] = False,\n",
        "                         **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Skill Classification| skills: {skills}\")\n",
        "\n",
        "    skill = zero_shot_classification(input, skills, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| skill: {skill}\")\n",
        "    return skill\n",
        "\n",
        "def sentiment_classification(input: str,\n",
        "                             labels: List[str],\n",
        "                             verbose: Optional[bool] = False,\n",
        "                             **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Sentiment Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Sentiment Classification| labels: {labels}\")\n",
        "\n",
        "    label = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Sentiment Classification| label: {label}\")\n",
        "    return label\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~\n",
        "Section for Table QA.\n",
        "~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def table_question_answering(input: str, \n",
        "                             table: pd.DataFrame, \n",
        "                             verbose: Optional[bool] = False, \n",
        "                             **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| input: {input}\")\n",
        "        print(f\"[DEBUG] |Table Question Answering| table: \\n{table}\")\n",
        "    \n",
        "    output = PIPELINES[\"TABLE_QA\"](table=table, query=input)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| output: \\n{output}\")\n",
        "    return output[\"answer\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Few-Shot Text Generation\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "\n",
        "def few_shot(query: str, \n",
        "             samples: str, \n",
        "             verbose: Optional[bool] = False, \n",
        "             **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "    \n",
        "    outputs = PIPELINES[\"FEW_SHOT\"](samples + query, **kwargs)\n",
        "    outputs = [sample[\"generated_text\"] for sample in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "def table_qa_few_shot(query: str, \n",
        "                      samples: str, \n",
        "                      verbose: Optional[bool] = False, \n",
        "                      **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table QA Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Table QA Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "\n",
        "    outputs = few_shot(query, \n",
        "                      samples, \n",
        "                      verbose, \n",
        "                      **kwargs)\n",
        "    \n",
        "    for i, sample in enumerate(outputs):\n",
        "        sample = sample[len(samples + query):]\n",
        "        sample = sample.split('\\n\\n')[0]\n",
        "        outputs[i] = sample\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table QA Few-Shot Text Generation| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Skill Functions\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "\n",
        "def legacy_table_qa_skill(conversation: transformers.Conversation, \n",
        "                          associations: dict, \n",
        "                          verbose: Optional[bool] = False, \n",
        "                          **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Table QA Skill| input conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |Legacy Table QA Skill| associations: \\n{associations}\")\n",
        "\n",
        "    input = conversation.new_user_input\n",
        "    labels = list(associations.keys())\n",
        "\n",
        "    variant = zero_shot_classification(\n",
        "        input, labels, **kwargs)[0]\n",
        "\n",
        "    data = associations[variant][\"data\"]()\n",
        "    samples = associations[variant][\"samples\"]\n",
        "    config = associations[variant][\"config\"]\n",
        "\n",
        "    cell = table_question_answering(input, data, verbose)\n",
        "\n",
        "    query = f\"Q: I am in {location()}. It is {date()} at {time()}. {input}\"\n",
        "    query = f'Q: {input}\\nC: {cell}\\n'\n",
        "\n",
        "    outputs = travel_few_shot(\n",
        "        query, \n",
        "        samples, \n",
        "        verbose, \n",
        "        **{**config, **kwargs})\n",
        "    outputs = [output.replace(\"A: \", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Table QA Skill| variant: {variant}\")\n",
        "        print(f\"[DEBUG] |Legacy Table QA Skill| cell: {cell}\")\n",
        "        print(f\"[DEBUG] |Legacy Table QA Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "def legacy_small_talk_skill(conversation: transformers.Conversation,\n",
        "                            associations: dict,\n",
        "                            verbose: Optional[bool] = False, \n",
        "                            **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| input conversation: \\n{conversation}\")\n",
        "\n",
        "    num_return_sequences = associations[\"num_return_sequences\"]\n",
        "    \n",
        "    conversations = [copy.deepcopy(conversation) for _ in range(num_return_sequences)]\n",
        "    conversations = PIPELINES[\"SMALL_TALK\"](conversations)\n",
        "    outputs = [conversation.generated_responses[-1] for conversation in conversations]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| num_return_sequences: {num_return_sequences}\")\n",
        "        print(f\"[DEBUG] |Legacy Small Talk Skill| outputs: \\n{outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Personas and Warm Up\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def legacy_warm_up(conversation: transformers.Conversation, \n",
        "                   personas: List[str],\n",
        "                   verbose: bool = False,\n",
        "                   **kwargs) -> transformers.Conversation:\n",
        "    for persona in personas:\n",
        "        conversation.add_user_input(persona)\n",
        "        conversation = PIPELINES[\"SMALL_TALK\"](conversation)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy Warm Up| personas: {personas}\")\n",
        "        print(f\"[DEBUG] |Legacy Warm Up| personas: {conversation}\")\n",
        "    return conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~\n",
        "Language Processors\n",
        "~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def legacy_german_to_english_translation(input: str,\n",
        "                                         verbose: Optional[bool] = False, \n",
        "                                         **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy German-To-English Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"GERMAN_TO_ENGLISH_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy German-To-English Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "def legacy_english_to_german_translation(input: str,\n",
        "                                         verbose: Optional[bool] = False, \n",
        "                                         **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy English-To-German Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"ENGLISH_TO_GERMAN_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Legacy English-To-German Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section Few-Shot Samples and their utilities.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "legacy_travel_samples = \"\"\"Q: It is 12:30. Wich is the next train from Frankfurt to Leipzig?\n",
        "C: ICE 1655\n",
        "A: The next train to Leipzig is the ICE 1655.\n",
        "\n",
        "Q: It is 17:22. Wich is the next train from Frankfurt to Leipzig?\n",
        "C: ICE 594\n",
        "A: The next train to Leipzig is the ICE 594.\n",
        "\n",
        "Q: When will the ICE 594 from Frankfurt arrive in Leipzig.\n",
        "C: 21:10\n",
        "A: The ICE 594 will arrive at 21:10.\n",
        "\n",
        "Q: How long will the ICE 1655 need to get from Frankfurt to Leipzig?\n",
        "C: 03:03\n",
        "A: The ICE 1655 will need 3 hours and 3 minutes.\n",
        "\n",
        "Q: At wich track will the FLX 1354 from Berlin arrive?\n",
        "C: 5\n",
        "A: The FLX 1354 from Berlin will arrive at the track 5.\n",
        "\n",
        "Q: Which train is the fastest option from Berlin to Hamburg?\n",
        "C: ICE 806\n",
        "A: The ICE 806 is the fastest option.\n",
        "\n",
        "Q: Which is the fastest option from Berlin to Hamburg?\n",
        "C: ICE 806\n",
        "A: The ICE 806 is the fastest option.\n",
        "\n",
        "Q: Can I take a Flixtrain from Berlin to Hamburg?\n",
        "C: FLX 1354\n",
        "A: The Flixtrain FLX 1354 will travel to Hamburg.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "legacy_event_samples = \"\"\"Q: It is the 2021-09-16. When is the next event?\n",
        "C: 2021-09-16\n",
        "A: The next event will take place at the 16th September.\n",
        "\n",
        "Q: Wich event will take place the 18th November?\n",
        "C: Herbst-Winter-Basar\n",
        "A: The Herbst-Winter-Basar will take place at the 18th November.\n",
        "\n",
        "Q: When will the Musical Ausgetickt end?\n",
        "C: 17:00\n",
        "A: The Musical Ausgetickt will end 17:00.\n",
        "\n",
        "Q: What is the Info evening Well prepared for self-employment about?\n",
        "C: This free info event \"Well prepared for self-employment\" will be held with the team of our cooperation partner \"gruenderberatungen.de\"\n",
        "A: The info event will be about beeing well prepared for self-employment.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "legacy_timetable_samples = \"\"\"Q: Wich lectures are planned for the 30th of August?\n",
        "C: Current Affairs, IT Law\n",
        "A: The lectures Current Affairs and IT Law are planned for the 30th of August.\n",
        "\n",
        "Q: It is the 2021-08-31. How late will the lecture Design and Implementation of Databases end?\n",
        "C: 11:45\n",
        "A: The lecture Design and Implementation of Databases will end 11:45.\n",
        "\n",
        "Q: Which lecturer will give the lecture Finance and Investment?\n",
        "C: Henry Ford\n",
        "A: Henry Ford will give the lecture Finance and Investment.\n",
        "\n",
        "Q: In wich room will the lecture Servicemanagement und ERP be?\n",
        "C: Assembly hall\n",
        "A: The lecture will be given in the assembly hall.\n",
        "\n",
        "Q: It is the 2021-09-01. What is planned for tomorrow?\n",
        "C: Practice/Project groups\n",
        "A: Practice and Project groups is scheduled for tomorrow.\n",
        "\n",
        "Q: It is the 2021-09-01. When do I have my next lecture?\n",
        "C: 2021-09-03\n",
        "A: Your next lecture will be at the 3rd of September.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "legacy_restaurant_samples = \"\"\"Q: How far away is the nearest restaurant.\n",
        "C: 0.6 km\n",
        "A: The nearest restaurant is 0.6 km away.\n",
        "\n",
        "Q: What is the closest Italian restaurant?\n",
        "C: La Scala\n",
        "A: The nearest restaurant is La Scala.\n",
        "\n",
        "Q: What kind of food does the restaurant Cuervo serve?\n",
        "C: Mexican\n",
        "A: The restaurant Cuervo serves Mexican food.\n",
        "\n",
        "Q: Can you tell me the best rated restaurants you know?\n",
        "C: Reatuarant zagreb, Pizzeria Romana, Ristaurante Tie-Break\n",
        "A: The best rated restaurants i know are Reatuarant zagreb, Pizzeria Romana, Ristaurante Tie-Break.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def length(samples: str, model: str) -> int:\n",
        "    tokenizer = PIPELINES[\"FEW_SHOT_TOKENIZER\"]\n",
        "    input_ids = tokenizer(\n",
        "        samples, return_tensors=\"pt\").input_ids\n",
        "    return input_ids.shape[-1]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for the Legacy Skills configuration.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LEGACY_PERSONAS = {\n",
        "    \"warm_up\": legacy_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "LEGACY_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"num_return_sequences\": 2,\n",
        "    }, \n",
        "    \"function\": legacy_small_talk_skill\n",
        "}\n",
        "\n",
        "LEGACY_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"any\": {\n",
        "            \"data\": travel_table,\n",
        "            \"samples\": legacy_travel_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_travel_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_table_qa_skill\n",
        "}\n",
        "\n",
        "LEGACY_EVENT_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"any\": {\n",
        "            \"data\": event_table,\n",
        "            \"samples\": legacy_event_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_event_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_table_qa_skill\n",
        "}\n",
        "\n",
        "LEGACY_TIMETABLE_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"any\": {\n",
        "            \"data\": timetable_table,\n",
        "            \"samples\": legacy_timetable_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_timetable_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_table_qa_skill\n",
        "}\n",
        "\n",
        "LEGACY_RESTAURANT_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"any\": {\n",
        "            \"data\": restaurant_table,\n",
        "            \"samples\": legacy_restaurant_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_restaurant_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_table_qa_skill\n",
        "}"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uSXlrc5UXis"
      },
      "source": [
        "### Set up fot the ***AI21 NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSsofpCOUWeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "f36f37a3-3e40-48e2-ad43-21af07b5cb38"
      },
      "source": [
        "# @title | NLP | Set up AI21 Studio API Key\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from getpass import getpass\n",
        "import requests\n",
        "import json\n",
        "\n",
        "AI21_API_KEY = getpass(\"\"\"\n",
        "    ▄▄▄▄▄▄▄ ▄▄▄ ▄▄▄▄▄▄▄ ▄▄▄▄    ▄▄▄▄▄▄▄ ▄▄▄▄▄▄▄ ▄▄   ▄▄ ▄▄▄▄▄▄  ▄▄▄ ▄▄▄▄▄▄▄ \n",
        "    █       █   █       █    █  █       █       █  █ █  █      ██   █       █\n",
        "    █   ▄   █   █▄▄▄▄   ██   █  █  ▄▄▄▄▄█▄     ▄█  █ █  █  ▄    █   █   ▄   █\n",
        "    █  █▄█  █   █▄▄▄▄█  ██   █  █ █▄▄▄▄▄  █   █ █  █▄█  █ █ █   █   █  █ █  █\n",
        "    █       █   █ ▄▄▄▄▄▄██   █  █▄▄▄▄▄  █ █   █ █       █ █▄█   █   █  █▄█  █\n",
        "    █   ▄   █   █ █▄▄▄▄▄ █   █   ▄▄▄▄▄█ █ █   █ █       █       █   █       █\n",
        "    █▄▄█ █▄▄█▄▄▄█▄▄▄▄▄▄▄██▄▄▄█  █▄▄▄▄▄▄▄█ █▄▄▄█ █▄▄▄▄▄▄▄█▄▄▄▄▄▄██▄▄▄█▄▄▄▄▄▄▄█\n",
        "\n",
        "    Note: If you DO NOT wish to use the AI21 toolkit simply press Enter.\n",
        "    Paste your AI21 Studio API key here: \"\"\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    ▄▄▄▄▄▄▄ ▄▄▄ ▄▄▄▄▄▄▄ ▄▄▄▄    ▄▄▄▄▄▄▄ ▄▄▄▄▄▄▄ ▄▄   ▄▄ ▄▄▄▄▄▄  ▄▄▄ ▄▄▄▄▄▄▄ \n",
            "    █       █   █       █    █  █       █       █  █ █  █      ██   █       █\n",
            "    █   ▄   █   █▄▄▄▄   ██   █  █  ▄▄▄▄▄█▄     ▄█  █ █  █  ▄    █   █   ▄   █\n",
            "    █  █▄█  █   █▄▄▄▄█  ██   █  █ █▄▄▄▄▄  █   █ █  █▄█  █ █ █   █   █  █ █  █\n",
            "    █       █   █ ▄▄▄▄▄▄██   █  █▄▄▄▄▄  █ █   █ █       █ █▄█   █   █  █▄█  █\n",
            "    █   ▄   █   █ █▄▄▄▄▄ █   █   ▄▄▄▄▄█ █ █   █ █       █       █   █       █\n",
            "    █▄▄█ █▄▄█▄▄▄█▄▄▄▄▄▄▄██▄▄▄█  █▄▄▄▄▄▄▄█ █▄▄▄█ █▄▄▄▄▄▄▄█▄▄▄▄▄▄██▄▄▄█▄▄▄▄▄▄▄█\n",
            "\n",
            "    Note: If you DO NOT wish to use the AI21 toolkit simply press Enter.\n",
            "    Paste your AI21 Studio API key here: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5Seco5VfCS",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | AI21 NLP Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~\n",
        "Section for utilities.\n",
        "~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def ai21_pipeline(model: str,\n",
        "                  input: str,\n",
        "                  num_beams: int = 0,\n",
        "                  num_return_sequences: int = 1,\n",
        "                  max_length: int = 100,\n",
        "                  stop_sequences: List[str] = [],\n",
        "                  top_p: float = 0.98,\n",
        "                  top_k: int = 0,\n",
        "                  temperature: float = 0.0,\n",
        "                  verbose: bool = False,\n",
        "                  **kwargs) -> List[str]:\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| model: {model}\")\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| input: {input}\")\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| config: {locals()}\")\n",
        "        \n",
        "        if AI21_API_KEY == \"\":\n",
        "            raise Exception(\n",
        "                \"\"\"[Error] No valid AI21 Studio API key was entered!\n",
        "                Please rerun the \"| NLP | Set up AI21 Studio API Key\" Cell \n",
        "                and enter your valid API Key.\"\"\")\n",
        "\n",
        "        response = requests.post(\n",
        "            f\"https://api.ai21.com/studio/v1/{model}/complete\",\n",
        "            headers={\"Authorization\": f\"Bearer {AI21_API_KEY}\"},\n",
        "            json={\n",
        "                \"prompt\": input, \n",
        "                \"numResults\": num_return_sequences, \n",
        "                \"maxTokens\": max_length, \n",
        "                \"stopSequences\": stop_sequences,\n",
        "                \"topP\": top_p,\n",
        "                \"topKReturn\": top_k,\n",
        "                \"temperature\": temperature,\n",
        "            })\n",
        "        \n",
        "        if response.status_code != 200:\n",
        "            raise Exception(\n",
        "                f\"\"\"[Error] The AI21 Studio request has returned a status code other than 200!\n",
        "                The request returned the following status code: {response.status_code}.\n",
        "                with the following request body:\\n{response.text}\"\"\")\n",
        "        \n",
        "        outputs = json.loads(response.text)[\"completions\"]\n",
        "        outputs = [output[\"data\"][\"text\"] for output in outputs]\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |AI21 Studio Pipeline| outputs: \\n{outputs}\")\n",
        "        return outputs\n",
        "\n",
        "def ai21_preprocess_table(data: pd.DataFrame) -> str:\n",
        "    table = df_to_csv(data)\n",
        "    table = table.replace(\",\", \" | \")\n",
        "\n",
        "    split = table.split(\"\\n\")\n",
        "    del split[-1]\n",
        "\n",
        "    for i, line in enumerate(split):\n",
        "        split[i] = f\"| {line} |\"\n",
        "\n",
        "    table = \"\\n\".join(split)\n",
        "    return table\n",
        "\n",
        "def ai21_warm_up(conversation: transformers.Conversation,\n",
        "                 *args,\n",
        "                 verbose: bool = False,\n",
        "                 **kwargs) -> transformers.Conversation:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Warm Up| personas: {conversation}\")\n",
        "    return conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Skill Functions\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def ai21_table_qa_skill(conversation: transformers.Conversation, \n",
        "                        associations: dict, \n",
        "                        verbose: Optional[bool] = False, \n",
        "                        **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Table QA Skill| input conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |AI21 Table QA Skill| associations: \\n{associations}\")\n",
        "\n",
        "    input = conversation.new_user_input\n",
        "    labels = list(associations.keys())\n",
        "\n",
        "    variant = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    data = associations[variant][\"data\"]()\n",
        "    \n",
        "    samples = associations[variant][\"samples\"]\n",
        "    config = associations[variant][\"config\"]\n",
        "    model = associations[variant][\"model\"]\n",
        "\n",
        "    table = ai21_preprocess_table(data)\n",
        "    query = f\"Q: I am in {location()}. It is {date()} at {time()}. {input}\"\n",
        "    input = f\"{table}\\n\\n{samples}{query}\"\n",
        "\n",
        "    outputs = ai21_pipeline(\n",
        "        model,\n",
        "        input,\n",
        "        verbose=verbose,\n",
        "        **config)\n",
        "    outputs = [output.replace(\"\\nA: \", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Table QA Skill| variant: {variant}\")\n",
        "        print(f\"[DEBUG] |AI21 Table QA Skill| input: \\n{input}\")\n",
        "        print(f\"[DEBUG] |AI21 Table QA Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "def ai21_small_talk_skill(conversation: transformers.Conversation, \n",
        "                          associations: dict,\n",
        "                          verbose: Optional[bool] = False, \n",
        "                          **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Small Talk Skill| input conversation: \\n{conversation}\")\n",
        "    \n",
        "    model = associations[\"model\"]\n",
        "    samples = associations[\"samples\"]\n",
        "    config = associations[\"config\"]\n",
        "    \n",
        "    input = str(conversation)\n",
        "    input = input.split(\"\\n\")[1:]\n",
        "    input = \"\\n\".join(input)\n",
        "    input = samples + input\n",
        "\n",
        "    outputs = ai21_pipeline(\n",
        "        model,\n",
        "        input,\n",
        "        verbose=verbose,\n",
        "        **config)\n",
        "    outputs = [output.replace(\"bot >> \", \"\").replace(\"\\n\", \"\") for output in outputs]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |AI21 Small Talk Skill| outputs: {outputs}\")\n",
        "    return outputs\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section Few-Shot Samples and their utilities.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "ai21_travel_samples = \"\"\"Q: It is 12:30. Wich is the next train from Frankfurt to Leipzig?\n",
        "A: The next train to Leipzig is ICE 1655 at 17:21 from track 9.\n",
        "\n",
        "Q: It is 17:22. Wich is the next train from Frankfurt to Leipzig?\n",
        "A: The next train to Leipzig is ICE 594 at 18:14 from track 9.\n",
        "\n",
        "Q: When will the ICE 594 from Frankfurt arrive in Leipzig.\n",
        "A: The ICE 594 will arrive at 21:10 on the track 13.\n",
        "\n",
        "Q: How long will the ICE 1655 need to get from Frankfurt to Leipzig?\n",
        "A: The  ICE 1655 will need 3 hours and 3 minutes.\n",
        "\n",
        "Q: At wich track will the FLX 1354 from Berlin arrive?\n",
        "A: The FLX 1354 from Berlin will arrive at the track 5 at 10:07.\n",
        "\n",
        "Q: Which train is the fastest option from Berlin to Hamburg?\n",
        "A: The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\n",
        "\n",
        "Q: Which is the fastest option from Berlin to Hamburg?\n",
        "A: The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\n",
        "\n",
        "Q: Can I take a Flixtrain from Berlin to Hamburg?\n",
        "A: The Flixtrain FLX 1354 will travel to Hamburg starting at 08:07 from track 8.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ai21_event_samples = \"\"\"Q: It is the 2021-09-16. When is the next event?\n",
        "A: The next event will take place at the 16th September.\n",
        "\n",
        "Q: Wich event will take place the 18th November?\n",
        "A: The Herbst-Winter-Basar will take place at the 18th November.\n",
        "\n",
        "Q: When will the Musical Ausgetickt end?\n",
        "A: The Musical Ausgetickt will end 17:00.\n",
        "\n",
        "Q: What is the Info evening Well prepared for self-employment about?\n",
        "A: The info event will be about beeing well prepared for self-employment.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ai21_timetable_samples = \"\"\"Q: Wich lectures are planned for the 30th of August?\n",
        "A: The lectures Current Affairs and IT Law are planned for the 30th of August.\n",
        "\n",
        "Q: It is the 2021-08-31. When will the lecture Design and Implementation of Databases end?\n",
        "A: The lecture Design and Implementation of Databases will end 11:45.\n",
        "\n",
        "Q: Which lecturer will give the lecture Finance and Investment?\n",
        "A: Henry Ford will give the lecture Finance and Investment.\n",
        "\n",
        "Q: In wich room will the lecture Servicemanagement und ERP be?\n",
        "A: The lecture will be given in the assembly hall. It will start 12:45 and last 195 minutes.\n",
        "\n",
        "Q: It is the 2021-09-01. What is planned for tomorrow?\n",
        "A: Practice and Project groups is scheduled for tomorrow.\n",
        "\n",
        "Q: It is the 2021-09-01. When do I have my next lecture?\n",
        "A: Your next lecture will be at the 3rd of September.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ai21_restaurant_samples = \"\"\"Q: How far away is the nearest restaurant.\n",
        "A: The nearest restaurant is 0.6 km away.\n",
        "\n",
        "Q: What is the closest Italian restaurant?\n",
        "A: The nearest restaurant is La Scala. It is just 0.6 km away and servers Italian food.\n",
        "\n",
        "Q: What kind of food does the restaurant Cuervo serve?\n",
        "A: The restaurant Cuervo serves Mexican food. It has an average rating of 4 out of 5.\n",
        "\n",
        "Q: Can you tell me the best rated restaurants you know?\n",
        "A: The best rated restaurants i know are Reatuarant zagreb, Pizzeria Romana, Ristaurante Tie-Break they share an average rating of 4.5 out of 5.\n",
        "\n",
        "Q: What is the furthest restaurant?\n",
        "A: The furthest restaurant I know is the restaurant Wolfsschlucht. It is 14.4 km away and serves German food.\n",
        "\n",
        "Q: What is the closest restaurant?\n",
        "A: The nearest restaurant is La Scala. It is just 0.6 km away and servers Italian food.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ai21_small_talk_samples = \"\"\"user >> what is your name\n",
        "bot >> My name is Mia. How can I help you? How are you doing?\n",
        "user >> what is your job\n",
        "bot >> I'm your assistant. Feel free to ask me about travel or keep the small talk going.\n",
        "user >> i m going away now bye\n",
        "bot >>  Good Bye. It was nice meeting you. See you soon.\n",
        "\n",
        "user >> how are you today\n",
        "bot >> I'm fine thanks! How are you? How can I help you?\n",
        "user >> i am good would you rather have a dragon or unicorn as a pet\n",
        "bot >> A unicorn! But both would be awesome pets! How about you?\n",
        "user >> i think i would take dragon they can fly so traveling should be a breeze\n",
        "bot >> That is a good point. Can I help you with anything else?\n",
        "user >> no i am fine good bye see you later\n",
        "bot >>  Good Bye. It was nice meeting you. See you soon.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for the AI21 Skills configuration.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "AI21_PERSONAS = {\n",
        "    \"warm_up\": ai21_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "AI21_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"model\": \"j1-jumbo\",\n",
        "        \"samples\": ai21_small_talk_samples,\n",
        "        \"config\": {\n",
        "            \"num_results\": 10,\n",
        "            \"max_tokens\": 64,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.98,\n",
        "            \"stop_sequences\": [\"user >>\"],\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_small_talk_skill\n",
        "}\n",
        "\n",
        "AI21_TABLE_QA_CONFIG = {\n",
        "    \"max_tokens\": 100,\n",
        "    \"temperature\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"stop_sequences\": [\"\\n\\n\"],\n",
        "}\n",
        "\n",
        "AI21_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": travel_table,\n",
        "            \"samples\": ai21_travel_samples,\n",
        "            \"config\": AI21_TABLE_QA_CONFIG\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_table_qa_skill\n",
        "}\n",
        "\n",
        "AI21_EVENT_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": event_table,\n",
        "            \"samples\": ai21_event_samples,\n",
        "            \"config\": AI21_TABLE_QA_CONFIG\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_table_qa_skill\n",
        "}\n",
        "\n",
        "AI21_TIMETABLE_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": timetable_table,\n",
        "            \"samples\": ai21_timetable_samples,\n",
        "            \"config\": AI21_TABLE_QA_CONFIG\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_table_qa_skill\n",
        "}\n",
        "\n",
        "AI21_RESTAURANT_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": restaurant_table,\n",
        "            \"samples\": ai21_restaurant_samples,\n",
        "            \"config\": AI21_TABLE_QA_CONFIG\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_table_qa_skill\n",
        "}"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yY2gJS0hZWw"
      },
      "source": [
        "### Set up fot the ***DeepL NLP*** Components\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCyOn6dMhZXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "45cf6c94-1251-4142-fe16-ee4388d32b16"
      },
      "source": [
        "# @title | NLP | Set up DeepL API Key\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from getpass import getpass\n",
        "import requests\n",
        "\n",
        "DEEPL_API_KEY = getpass(\"\"\"\n",
        "    ██████╗ ███████╗███████╗██████╗ ██╗     \n",
        "    ██╔══██╗██╔════╝██╔════╝██╔══██╗██║     \n",
        "    ██║  ██║█████╗  █████╗  ██████╔╝██║     \n",
        "    ██║  ██║██╔══╝  ██╔══╝  ██╔═══╝ ██║     \n",
        "    ██████╔╝███████╗███████╗██║     ███████╗\n",
        "    ╚═════╝ ╚══════╝╚══════╝╚═╝     ╚══════╝\n",
        "\n",
        "    Note: If you DO NOT wish to use the DeepL component simply press Enter.\n",
        "    Paste your DeepL API key here: \"\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    ██████╗ ███████╗███████╗██████╗ ██╗     \n",
            "    ██╔══██╗██╔════╝██╔════╝██╔══██╗██║     \n",
            "    ██║  ██║█████╗  █████╗  ██████╔╝██║     \n",
            "    ██║  ██║██╔══╝  ██╔══╝  ██╔═══╝ ██║     \n",
            "    ██████╔╝███████╗███████╗██║     ███████╗\n",
            "    ╚═════╝ ╚══════╝╚══════╝╚═╝     ╚══════╝\n",
            "\n",
            "    Note: If you DO NOT wish to use the DeepL component simply press Enter.\n",
            "    Paste your DeepL API key here: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3djIDKr_hZXO",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | DeepL Translation Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~\n",
        "Language Processors\n",
        "~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def deepl_translation(text: str,\n",
        "                      target_lang: str=\"DE\",\n",
        "                      verbose: Optional[bool] = False,\n",
        "                      **kwargs) -> dict:\n",
        "    if DEEPL_API_KEY == \"\":\n",
        "        raise Exception(\n",
        "            \"\"\"[Error] No valid  DeepL API key was entered!\n",
        "            Please rerun the \"| NLP | Set up DeepL API Key\" Cell \n",
        "            and enter your valid API Key.\"\"\")\n",
        "    \n",
        "    url = \"https://api-free.deepl.com/v2/translate\"\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "    data = f\"auth_key={DEEPL_API_KEY}&text={text}&target_lang={target_lang}\"\n",
        "\n",
        "    response = requests.post(url, headers=headers, data=data)\n",
        "    \n",
        "    if response.status_code != 200:\n",
        "        raise Exception(\n",
        "            f\"\"\"[Error] The DeepL API request has returned a status code other than 200!\n",
        "            The request returned the following status code: {response.status_code}.\n",
        "            with the following request body:\\n{response.text}\"\"\")\n",
        "        \n",
        "    json = response.json()\n",
        "    translation = json[\"translations\"][0]\n",
        "\n",
        "    return translation\n",
        "\n",
        "def deepl_german_to_english_translation(input: str,\n",
        "                                        verbose: Optional[bool] = False, \n",
        "                                        **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL German-To-English Translation| input: {input}\")\n",
        "\n",
        "    translation = deepl_translation(input, target_lang=\"EN\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL German-To-English Translation| translation: {translation}\")\n",
        "    return translation[\"text\"]\n",
        "\n",
        "def deepl_english_to_german_translation(input: str,\n",
        "                                        verbose: Optional[bool] = False, \n",
        "                                        **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL English-To-German Translation| input: {input}\")\n",
        "\n",
        "    translation = deepl_translation(input, target_lang=\"DE\")\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |DeepL English-To-German Translation| translation: \\n{translation}\")\n",
        "    return translation[\"text\"]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKuBPzcJWaOu"
      },
      "source": [
        "### Set up fot the ***NLP*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jG4ljQCWS7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "acd24ff4-cec8-41b8-9ac3-50142bf254a2"
      },
      "source": [
        "# @title | NLP | Set up Module\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the Skill Versions 👀🔀\n",
        "SMALL_TALK_SKILL_VERSION = \"legacy\" #@param [\"legacy\", \"ai21\"]\n",
        "TRAVEL_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "EVENT_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TIMETABLE_SKILL_VERSION = \"legacy\" #@param [\"legacy\", \"ai21\"]\n",
        "RESTAURANT_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TRANSLATION_COMPONENT = \"deepl\" #@param [\"legacy\", \"deepl\"]\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~\n",
        "NLP Configuration\n",
        "~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": {\n",
        "        \"to_native\": lambda x: x,\n",
        "        \"to_source\": lambda x: x,\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"to_native\": legacy_german_to_english_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_german_to_english_translation,\n",
        "        \"to_source\": legacy_english_to_german_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_english_to_german_translation,\n",
        "    }\n",
        "}\n",
        "\n",
        "SENTIMENT = {\n",
        "    \"positive\": [\"non-toxic\", \"travel\", \"small talk\"],\n",
        "    \"negative\": [\"toxic\", \"vulgar\"],\n",
        "}\n",
        "\n",
        "PERSONAS = LEGACY_PERSONAS if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_PERSONAS\n",
        "\n",
        "SKILLS = {\n",
        "    \"travel\": {\n",
        "        \"labels\": [\"travel\", \"travel on time\", \"travel delayed\"],\n",
        "        \"pipeline\": LEGACY_TRAVEL_SKILL if TRAVEL_SKILL_VERSION == \"legacy\" else AI21_TRAVEL_SKILL\n",
        "    },\n",
        "    \"event\": {\n",
        "        \"labels\": [\"event\", \"events\"],\n",
        "        \"pipeline\": LEGACY_EVENT_SKILL if EVENT_SKILL_VERSION == \"legacy\" else AI21_EVENT_SKILL\n",
        "    },\n",
        "    \"timetable\": {\n",
        "        \"labels\": [\"lecture\", \"professor\", \"university\"],\n",
        "        \"pipeline\": LEGACY_TIMETABLE_SKILL if TIMETABLE_SKILL_VERSION == \"legacy\" else AI21_TIMETABLE_SKILL\n",
        "    },\n",
        "    \"restaurant\": {\n",
        "        \"labels\": [\"restaurant\", \"food\", \"serve food\", \"eat\"],\n",
        "        \"pipeline\": LEGACY_RESTAURANT_SKILL if RESTAURANT_SKILL_VERSION == \"legacy\" else AI21_RESTAURANT_SKILL\n",
        "\n",
        "    },\n",
        "    \"small talk\": {\n",
        "        \"labels\": [\"small talk\", \"other\"],\n",
        "        \"pipeline\": LEGACY_SMALL_TALK_SKILL if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_SMALL_TALK_SKILL\n",
        "    }\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"languages\": LANGUAGES,\n",
        "    \"sentiment\": SENTIMENT,\n",
        "    \"personas\": PERSONAS,\n",
        "    \"skills\": SKILLS,\n",
        "} \n",
        "\n",
        "\n",
        "class NLP:\n",
        "    def __init__(self,\n",
        "                 config: dict = CONFIG,\n",
        "                 verbose: bool = True,\n",
        "                 **kwargs):\n",
        "        self.config = config\n",
        "\n",
        "        language = config[\"languages\"][LANGUAGE]\n",
        "        self.to_native = language[\"to_native\"]\n",
        "        self.to_source = language[\"to_source\"]\n",
        "\n",
        "        self.sentiment_labels = []\n",
        "        for _, labels in self.config[\"sentiment\"].items():\n",
        "            self.sentiment_labels.extend(labels)\n",
        "\n",
        "        personas = config[\"personas\"]\n",
        "        self.conversation = personas[\"warm_up\"](\n",
        "            transformers.Conversation(), \n",
        "            personas=personas[\"personas\"],\n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "\n",
        "        self.skills = config[\"skills\"]\n",
        "\n",
        "        self.skill_labels = []\n",
        "        for _, skill in self.skills.items():\n",
        "            self.skill_labels.extend(skill[\"labels\"])\n",
        "        \n",
        "    def __call__(self, \n",
        "                 input: str, \n",
        "                 verbose: bool = False, \n",
        "                 **kwargs) -> str:\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP __call__ <START>|\" + \"~\"*20)\n",
        "            print(f\"[DEBUG] |NLP ATTR skills|: {self.skills}\")\n",
        "            print(f\"[DEBUG] |NLP ATTR conversation|: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP User input|: {input}\")\n",
        "        # Convert input from the source to native language.\n",
        "        input = self.to_native(input)\n",
        "\n",
        "        # Check if sentiment of the input is negative.\n",
        "        if self.is_sentiment(\"negative\", input):\n",
        "            raise Exception(\"[Warning] A negative input was captured and discarded.\")\n",
        "        self.conversation.add_user_input(input)\n",
        "\n",
        "        # Match a skill to the given input.\n",
        "        label = skill_classification(\n",
        "            input, \n",
        "            self.skill_labels,\n",
        "            verbose=verbose, \n",
        "            **kwargs)\n",
        "        \n",
        "        # Collect components to do further processing.\n",
        "        skill = self.skill_from_label(label)\n",
        "        pipeline = skill[\"pipeline\"]\n",
        "        function = pipeline[\"function\"]\n",
        "        associations = pipeline[\"associations\"]\n",
        "        \n",
        "        # Generate the skills outputs.\n",
        "        outputs = function(\n",
        "            self.conversation, \n",
        "            associations=associations, \n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "        \n",
        "        # Find the first output with a positive sentiment.\n",
        "        output = \"\"\n",
        "        for sample in outputs:\n",
        "            if self.is_sentiment(\"positive\", sample):\n",
        "                output = sample\n",
        "                break\n",
        "\n",
        "        self.conversation.mark_processed()\n",
        "        self.conversation.append_response(output)\n",
        "\n",
        "        # Issue a warning if no outputs where positive.\n",
        "        if output == \"\":\n",
        "            raise Exception(\"[Warning] All outputs where negative and discarded.\")\n",
        "        \n",
        "        # Convert input from the native to source language.\n",
        "        output = self.to_source(output)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP conversation |: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP outputs|: \\n{outputs}\")\n",
        "            print(f\"[DEBUG] |NLP output|: {output}\")\n",
        "            print(f\"[DEBUG] |NLP __call__ <END>|\" + \"~\"*20)\n",
        "        return output\n",
        "\n",
        "    def is_sentiment(self, name: str, input: str) -> bool:\n",
        "        \"\"\"Return if the input has a given sentiment.\"\"\"\n",
        "        label = sentiment_classification(\n",
        "            input, self.sentiment_labels)\n",
        "        labels = self.config[\"sentiment\"][name]\n",
        "        \n",
        "        return label in labels\n",
        "        \n",
        "    def skill_from_label(self, label: str) -> dict:\n",
        "        \"\"\"Return the first skill that has the label.\"\"\"\n",
        "        for _, skill in self.skills.items():\n",
        "            if label in skill[\"labels\"]:\n",
        "                return skill\n",
        "\n",
        "        raise Exception(\"The classified skill_label is not mapped to a skill.\")\n",
        "\n",
        "\n",
        "nlp = execute(NLP, verbose=VERBOSE, config=CONFIG)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] |Legacy Warm Up| personas: []\n",
            "[DEBUG] |Legacy Warm Up| personas: Conversation id: d03d7cf6-a6e4-4c0c-96da-652f15f4739b \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Zo09hxv31Y"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Speech Recognition (STT)*** 🎤💬\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12V9_IDkmwq-"
      },
      "source": [
        "### Set up for ***Legacy Speech Recognition***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7WGmmWMbf4o",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Installation of Legacy Dependencies ⇩\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_legacy_sst_dependencies(**kwargs):\n",
        "    !pip install transformers\n",
        "    !pip install numpy==1.20\n",
        "    !pip install numba==0.48\n",
        "    !pip install ffmpeg-python\n",
        "    !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "execute(install_legacy_sst_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjsRML5VtFXY",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Legacy Wav2Vec2 Speech Recognition\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def speech_to_text_implementation(**kwargs):\n",
        "    from transformers import Wav2Vec2Tokenizer\n",
        "    from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "    STT_MODEL = \"facebook/wav2vec2-large-960h-lv60-self\" if LANGUAGE == \"en\" else \"facebook/wav2vec2-large-xlsr-53-german\"\n",
        "\n",
        "    # load model and tokenizer\n",
        "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(STT_MODEL)\n",
        "    wav2vec2 = Wav2Vec2ForCTC.from_pretrained(STT_MODEL)\n",
        "\n",
        "    def speech_to_text(audio: np.ndarray, \n",
        "                       **kwargs) -> List[str]:   \n",
        "        input_values = tokenizer(\n",
        "            [audio], \n",
        "            return_tensors=\"pt\", \n",
        "            padding=\"longest\"\n",
        "        ).input_values\n",
        "\n",
        "        logits = wav2vec2(input_values).logits\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        text = tokenizer.batch_decode(predicted_ids)\n",
        "        text = \" \".join(text)\n",
        "        return text\n",
        "\n",
        "    return speech_to_text\n",
        "\n",
        "legacy_stt = execute(speech_to_text_implementation, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnD_dmwAm8BI"
      },
      "source": [
        "### Set up for ***Google Cloud Speech Recognition***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fnEA0Okm69x",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Installation of Google Cloud Dependencies ⇩\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "def install_gcloud_sst_dependencies(**kwargs):\n",
        "    !pip install soundfile\n",
        "    !pip install --upgrade google-auth\n",
        "    !pip install --upgrade google-cloud-speech\n",
        "    !pip install numpy==1.20\n",
        "    !pip install numba==0.48\n",
        "    !pip install ffmpeg-python\n",
        "    !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip\n",
        "\n",
        "execute(install_gcloud_sst_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hwMiTG3nsvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8bb85bb5-56fe-4a2c-90d3-1ab8aebd821b"
      },
      "source": [
        "# @title | STT | Mount Google Drive to access Google Cloud credentials\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "GCLOUD_STT_CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
        "    '/content/gdrive/MyDrive/projects/TREX/STT/key.json')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SMGSkzgn8rP",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Google Cloud Speech Recognition Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from google.cloud import speech\n",
        "\n",
        "\n",
        "def gcloud_stt(data: np.ndarray,\n",
        "               rate: int=16000,\n",
        "               language_code: str=\"en-US\",\n",
        "               speech_file: str=\"speech_file.flac\",\n",
        "               encoding=speech.RecognitionConfig.AudioEncoding.FLAC,\n",
        "               credentials=GCLOUD_STT_CREDENTIALS) -> str:\n",
        "    \"\"\"Transcribe audio data via the Google Cloud Speech-To-Text Service.\n",
        "    \n",
        "    Args:\n",
        "        data (np.ndarray): The audio data.\n",
        "    \n",
        "    Kwargs:\n",
        "        speech_file (str): A file in which the audio is stored.\n",
        "        rate (int): The sample rate of the audio.\n",
        "        encoding (enum): The encoding of the audio file.\n",
        "        language_code (str): The language of the speech.\n",
        "\n",
        "    Returns:\n",
        "        (str) The most likely transcript.\n",
        "\n",
        "    Note:\n",
        "        Transcription is limited to a 60 seconds audio file.\n",
        "        Use a GCS file for audio longer than 1 minute.\n",
        "    \"\"\"\n",
        "    sf.write(speech_file, data, rate)\n",
        "\n",
        "    client = speech.SpeechClient(credentials=credentials)\n",
        "\n",
        "    with io.open(speech_file, \"rb\") as audio_file:\n",
        "        content = audio_file.read()\n",
        "\n",
        "    audio = speech.RecognitionAudio(content=content)\n",
        "    config = speech.RecognitionConfig(\n",
        "        encoding=encoding,\n",
        "        sample_rate_hertz=rate,\n",
        "        language_code=language_code)\n",
        "\n",
        "    operation = client.long_running_recognize(\n",
        "        config=config, \n",
        "        audio=audio)\n",
        "\n",
        "    print(\"Waiting for operation to complete...\")\n",
        "    response = operation.result(timeout=90)\n",
        "\n",
        "    # Each result is for a consecutive portion of the audio. Iterate through\n",
        "    # them to get the transcripts for the entire audio file.\n",
        "    for result in response.results:\n",
        "        # The first alternative is the most likely one for this portion.\n",
        "        transcript = result.alternatives[0].transcript\n",
        "        confidence = result.alternatives[0].confidence\n",
        "\n",
        "        print(u\"Transcript: {}\".format(transcript))\n",
        "        print(\"Confidence: {}\".format(confidence))\n",
        "        return transcript\n",
        "    return None"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKsJj9mKnd1G"
      },
      "source": [
        "### Set up audio recording utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PauhmEq8chkm",
        "cellView": "form"
      },
      "source": [
        "# @title | STT | Audio Recording Utils\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\"\"\"Utils for recording audio in a Google Colaboratory notebook.\n",
        "\n",
        "This code is adapted from:\n",
        "    https://ricardodeazambuja.com/deep_learning/2019/03/09/audio_and_video_google_colab/\n",
        "    https://colab.research.google.com/gist/ricardodeazambuja/03ac98c31e87caf284f7b06286ebf7fd/microphone-to-numpy-array-from-your-browser-in-colab.ipynb\n",
        "\"\"\"\n",
        "\n",
        "SILENT = \"&> /dev/null\"\n",
        "\n",
        "import io\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import write\n",
        "from dl_colab_notebooks.audio import audio_bytes_to_np\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import HTML\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "\n",
        "STYLES_HTML = \"\"\"\n",
        "<script>\n",
        "\n",
        "var styles = `\n",
        "\n",
        "button {\n",
        "    width: 300px;\n",
        "    height: 54px;\n",
        "\n",
        "    padding: 20px;\n",
        "    margin: 5px;\n",
        "\n",
        "    display: flex;\n",
        "    justify-content: center;\n",
        "    align-items: center;\n",
        "    border-radius: 40px;\n",
        "    border: none;\n",
        "\n",
        "    text-align: center;\n",
        "    font-size: 28px;\n",
        "    \n",
        "    transition: all 0.5s;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        "button span {\n",
        "    display: inline-block;\n",
        "    position: relative;\n",
        "\n",
        "    cursor: pointer;\n",
        "    transition: 0.5s;\n",
        "}\n",
        "\n",
        "button span:after {\n",
        "    content: '🙏';\n",
        "\n",
        "    position: absolute;\n",
        "    right: -20px;\n",
        "\n",
        "    opacity: 0;\n",
        "    transition: 0.5s;\n",
        "}\n",
        "\n",
        "button:hover span {\n",
        "    padding-right: 25px;\n",
        "}\n",
        "\n",
        "button:hover span:after {\n",
        "    right: 0;\n",
        "    opacity: 1;\n",
        "}\n",
        "`\n",
        "\n",
        "var styleSheet = document.createElement(\"style\")\n",
        "styleSheet.type = \"text/css\"\n",
        "styleSheet.innerText = styles\n",
        "document.head.appendChild(styleSheet);\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "\n",
        "var container = document.createElement(\"div\");\n",
        "var button = document.createElement(\"button\");\n",
        "var span = document.createElement(\"span\");\n",
        "\n",
        "button.appendChild(span);\n",
        "container.appendChild(button);\n",
        "document.body.appendChild(container);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader, recorder, gumStream;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "    gumStream = stream;\n",
        "    var options = {\n",
        "            mimeType : 'audio/webm;codecs=opus'\n",
        "    };            \n",
        "    recorder = new MediaRecorder(stream);\n",
        "    recorder.ondataavailable = function(e) {            \n",
        "        var url = URL.createObjectURL(e.data);\n",
        "        var preview = document.createElement('audio');\n",
        "\n",
        "        preview.controls = true;\n",
        "        preview.src = url;\n",
        "        container.appendChild(preview);\n",
        "\n",
        "        reader = new FileReader();\n",
        "        reader.readAsDataURL(e.data); \n",
        "        reader.onloadend = function() {\n",
        "            base64data = reader.result;\n",
        "        }\n",
        "    };\n",
        "    recorder.start();\n",
        "};\n",
        "\n",
        "span.innerText = \"⏸︎\";\n",
        "button.style.verticalAlign = \"middle\";\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "function toggleRecording() {\n",
        "    if (recorder && recorder.state == \"recording\") {\n",
        "        recorder.stop();\n",
        "        gumStream.getAudioTracks()[0].stop();\n",
        "        span.innerText = \"✅\"\n",
        "    }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "    return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "    button.onclick = () => {\n",
        "        toggleRecording()\n",
        "\n",
        "        sleep(2000).then(() => {\n",
        "            resolve(base64data.toString())\n",
        "        });\n",
        "    }\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def record(sample_rate: int = 16000) -> str:\n",
        "    display(HTML(STYLES_HTML + AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    \n",
        "    audio_bytes = b64decode(data.split(',')[1])\n",
        "    return audio_bytes_to_np(audio_bytes, sample_rate)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXF876tBJ6I8"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Text-To-Speech (TTS)*** 💭📣\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DVfrA6NpQuo"
      },
      "source": [
        "### Set up for the ***Legacy Text-To-Speech*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UxGOjsiJ6JF",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | Installation of Legacy Dependencies ⇩\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_legacy_tts_dependencies(**kwargs):\n",
        "    !apt-get install -y espeak\n",
        "\n",
        "    if LANGUAGE == \"de\":\n",
        "        !gdown --id 1VG0EI7J6S1bk3h0q1VBc9ALExkdZdeVm -O tts_model.pth.tar\n",
        "        !gdown --id 1s1GcSihlj58KX0LeA-FPFvdMWGMkcxKI -O config.json\n",
        "        !gdown --id 1zYFHElvYW_oTeilvbZVLMLscColWRbck -O vocoder_model.pth.tar\n",
        "        !gdown --id 1ye9kVDbatAKMncRMui7watrLQ_5DaJ3e -O config_vocoder.json\n",
        "        !gdown --id 1QD40bU_M7CWrj9k0MEACNBRqwqVTSLDc -O scale_stats.npy\n",
        "        !sudo apt-get install espeak\n",
        "        !git clone https://github.com/coqui-ai/TTS\n",
        "\n",
        "        %cd TTS\n",
        "        !git checkout 540d811\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup.py install\n",
        "\n",
        "        # sometimes installation does not work\n",
        "        import os, sys\n",
        "        sys.path.append(os.getcwd())\n",
        "        %cd ..\n",
        "    else:\n",
        "        !git clone https://github.com/1ucky40nc3/TransformerTTS.git\n",
        "        %cd TransformerTTS\n",
        "        !git checkout package\n",
        "        !pip install torchaudio\n",
        "        !pip install -r /content/TransformerTTS/requirements.txt\n",
        "        !pip install -r /content/TransformerTTS/TransformerTTS/vocoding/extra_requirements.txt\n",
        "        !python setup.py develop\n",
        "\n",
        "        !wget https://public-asai-dl-models.s3.eu-central-1.amazonaws.com/hifigan.zip\n",
        "        !unzip -q hifigan.zip\n",
        "        !rsync -avq hifigan/ /content/TransformerTTS/TransformerTTS/vocoding/hifigan/\n",
        "\n",
        "execute(install_legacy_tts_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDXVw9toJ6JG",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | TTS Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown #### ❗❗❗ ***If \"de\" is selected as language an error may accure.***\n",
        "# @markdown #### ⏩ Just try to rerun this cell. 👻 \n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchaudio import functional as F\n",
        "\n",
        "def text_to_speech_implementation(**kwargs):\n",
        "    if LANGUAGE == \"de\":\n",
        "        import os\n",
        "        from TTS.utils.io import load_config\n",
        "        from TTS.utils.audio import AudioProcessor\n",
        "        from TTS.tts.utils.io import load_checkpoint\n",
        "        from TTS.tts.utils.synthesis import synthesis\n",
        "        from TTS.tts.utils.text.symbols import symbols\n",
        "        from TTS.tts.utils.generic_utils import setup_model\n",
        "        from TTS.vocoder.utils.generic_utils import setup_generator\n",
        "        from TTS.vocoder.utils.io import load_checkpoint as load_vocoder_checkpoint\n",
        "\n",
        "        TTS_MODEL = \"/content/tts_model.pth.tar\"\n",
        "        TTS_CONFIG = \"/content/config.json\"\n",
        "        VOCODER_MODEL = \"/content/vocoder_model.pth.tar\"\n",
        "        VOCODER_CONFIG = \"/content/config_vocoder.json\"\n",
        "\n",
        "        TTS_CONFIG = load_config(TTS_CONFIG)\n",
        "        TTS_CONFIG.audio[\"stats_path\"] = \"/content/scale_stats.npy\"\n",
        "\n",
        "        VOCODER_CONFIG = load_config(VOCODER_CONFIG)\n",
        "\n",
        "        audio_processor = AudioProcessor(**TTS_CONFIG.audio)\n",
        "\n",
        "        model, _ = load_checkpoint(\n",
        "            setup_model(\n",
        "                num_chars=len(symbols), \n",
        "                num_speakers=0,\n",
        "                c=TTS_CONFIG),\n",
        "            checkpoint_path=TTS_MODEL)\n",
        "\n",
        "        vocoder, _ = load_vocoder_checkpoint(\n",
        "            setup_generator(VOCODER_CONFIG), \n",
        "            checkpoint_path=VOCODER_MODEL)\n",
        "        vocoder.remove_weight_norm()\n",
        "        vocoder.inference_padding = 0\n",
        "\n",
        "        if USE_GPU_4_GERMAN_TTS:\n",
        "            model.cuda()\n",
        "            vocoder.cuda()\n",
        "\n",
        "        model.eval()\n",
        "        vocoder.eval()\n",
        "\n",
        "        def text_to_speech(text: str, \n",
        "                           **kwargs) -> np.ndarray:\n",
        "            _, _, _, mel_postnet_spec, _, _ = synthesis(\n",
        "                model, \n",
        "                text, \n",
        "                TTS_CONFIG,\n",
        "                USE_GPU_4_GERMAN_TTS, \n",
        "                audio_processor)\n",
        "            \n",
        "            speech = vocoder.inference(\n",
        "                torch.FloatTensor(\n",
        "                    mel_postnet_spec.T,\n",
        "                ).unsqueeze(0))\n",
        "            speech = speech.flatten().cpu().numpy()\n",
        "\n",
        "            return speech\n",
        "        \n",
        "        return text_to_speech\n",
        "    \n",
        "    %cd /content/TransformerTTS\n",
        "\n",
        "    from TransformerTTS.model.factory import tts_ljspeech\n",
        "    from TransformerTTS.vocoding.predictors import HiFiGANPredictor\n",
        "\n",
        "\n",
        "    folder = \"/content/TransformerTTS/TransformerTTS/vocoding/hifigan/en\"\n",
        "\n",
        "\n",
        "    model, _ = tts_ljspeech()\n",
        "    vocoder = HiFiGANPredictor.from_folder(folder)\n",
        "\n",
        "    def text_to_speech(text: str, \n",
        "                       **kwargs) -> np.ndarray:\n",
        "        speech = model.predict(text)\n",
        "        speech = speech[\"mel\"].numpy().T\n",
        "        speech = vocoder([speech])[0]\n",
        "\n",
        "        return speech\n",
        "\n",
        "    %cd ..\n",
        "    return text_to_speech\n",
        "\n",
        "legacy_tts = execute(text_to_speech_implementation, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fqGpEURp38G"
      },
      "source": [
        "### Set up for the ***Google Cloud Text-To-Speech*** Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUdzmRd9p6tl",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | Installation of Google Cloud Dependencies ⇩\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_gcloud_tts_dependencies(**kwargs):\n",
        "    !pip install soundfile\n",
        "    !pip install --upgrade google-auth\n",
        "    !pip install --upgrade google-cloud-texttospeech\n",
        "\n",
        "execute(install_gcloud_tts_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uidDtKTCqojE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cfa2c4-4121-48f2-b5af-f7ec2fe48cc3"
      },
      "source": [
        "# @title | TTS | Mount Google Drive to access Google Cloud credentials\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "GCLOUD_TTS_CREDENTIALS = service_account.Credentials.from_service_account_file(\n",
        "    '/content/gdrive/MyDrive/projects/TREX/TTS/key.json')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vddpburPqxOs",
        "cellView": "form"
      },
      "source": [
        "# @title | TTS | Google Cloud Text-To-Speech Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "import google.cloud.texttospeech as texttospeech\n",
        "import scipy\n",
        "\n",
        "\n",
        "def gcloud_tts(text: str, \n",
        "               voice_name: str=\"en-US-Wavenet-D\",\n",
        "               credentials=GCLOUD_TTS_CREDENTIALS) -> np.ndarray:\n",
        "    text_input = texttospeech.SynthesisInput(text=text)\n",
        "\n",
        "    language_code = \"-\".join(voice_name.split(\"-\")[:2])\n",
        "    voice_params = texttospeech.VoiceSelectionParams(\n",
        "        language_code=language_code, \n",
        "        name=voice_name)\n",
        "    \n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.LINEAR16)\n",
        "\n",
        "    client = texttospeech.TextToSpeechClient(\n",
        "        credentials=credentials)\n",
        "\n",
        "    response = client.synthesize_speech(\n",
        "        input=text_input, \n",
        "        voice=voice_params, \n",
        "        audio_config=audio_config)\n",
        "\n",
        "    filename = f\"{language_code}.wav\"\n",
        "    with open(filename, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "        print(f'Generated speech saved to \"{filename}\"')\n",
        "\n",
        "    rate, data = scipy.io.wavfile.read(filename)\n",
        "    return data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAOU0Mf-qRJi"
      },
      "source": [
        "### Set up for audio processing utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2uJeHgl_pjHS"
      },
      "source": [
        "# @title | TTS | Audio Processing Utils\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchaudio import functional as F\n",
        "\n",
        "def postprocessing(wav: np.ndarray) -> np.ndarray:\n",
        "    wav = torch.from_numpy(wav)\n",
        "\n",
        "    wav = wav.unsqueeze(-1).T\n",
        "    wav = F.apply_codec(\n",
        "        waveform=wav, \n",
        "        sample_rate=22050,\n",
        "        format=\"wav\", \n",
        "        encoding=\"PCM_F\")\n",
        "    wav = F.resample(\n",
        "        waveform=wav, \n",
        "        orig_freq=22050, \n",
        "        new_freq=16000)\n",
        "\n",
        "    wav = wav.squeeze()\n",
        "    wav = wav.numpy()\n",
        "    \n",
        "    return wav"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgUr4Q6TJ6JH"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "## ***Avatar (PC-AVS)*** 🤗🤖\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU2pN_5QGY-G",
        "cellView": "form"
      },
      "source": [
        "# @title | PC-AVS | Install Dependencies ⇩\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def install_avatar_dependencies(**kwargs):\n",
        "    !git clone https://github.com/1ucky40nc3/Talking-Face_PC-AVS.git\n",
        "    %cd /content/Talking-Face_PC-AVS\n",
        "\n",
        "    !pip install -r requirements.txt\n",
        "    !pip install lws\n",
        "    !pip install face-alignment\n",
        "    !pip install av\n",
        "    !pip install torchaudio\n",
        "\n",
        "    !unzip ./misc/Audio_Source.zip -d ./misc/\n",
        "    !unzip ./misc/Input.zip -d ./misc/\n",
        "    !unzip ./misc/Mouth_Source.zip -d ./misc/ \n",
        "    !unzip ./misc/Pose_Source.zip -d ./misc/\n",
        "\n",
        "    !gdown https://drive.google.com/u/0/uc?id=1Zehr3JLIpzdg2S5zZrhIbpYPKF-4gKU_&export=download\n",
        "    !mkdir checkpoints\n",
        "    !unzip demo.zip -d ./checkpoints/\n",
        "\n",
        "execute(install_avatar_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yeHLAfXGvNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e6f2bb8f-059a-4ba7-bef2-2e0143e761e2"
      },
      "source": [
        "# @title | PC-AVS | PC-AVS Implementation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "%cd /content/Talking-Face_PC-AVS\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.append('..')\n",
        "\n",
        "from data import create_dataloader\n",
        "from models import create_model\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "class Namespace:\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "\n",
        "def pc_avs_inference(opt, \n",
        "                     path_label, \n",
        "                     model, \n",
        "                     wav) -> str:\n",
        "    opt.path_label = path_label\n",
        "    dataloader = create_dataloader(opt, wav=wav)\n",
        "\n",
        "    fake_image_driven_pose_as = []\n",
        "\n",
        "    for data_i in tqdm(dataloader):\n",
        "        _, fake_image_driven_pose_a = model.forward(\n",
        "            data_i, mode='inference')\n",
        "\n",
        "        fake_image_driven_pose_as.append(\n",
        "            fake_image_driven_pose_a)\n",
        "\n",
        "    filename = os.path.join(\n",
        "        dataloader.dataset.get_processed_file_savepath(), \n",
        "        \"G_Pose_Driven_.mp4\")\n",
        "\n",
        "    video_array = torch.cat(fake_image_driven_pose_as, dim=0)\n",
        "    video_array = video_array.cpu().transpose(1, 3)\n",
        "    video_array = video_array * 125.5 + 125.5 \n",
        "    video_array = video_array.type(torch.uint8)\n",
        "    video_array = torch.rot90(video_array, -1, [1, 2])\n",
        "\n",
        "    wav = torch.from_numpy(wav)\n",
        "    wav = torch.unsqueeze(wav, dim=0)\n",
        "    \n",
        "    torchvision.io.write_video(\n",
        "        filename=filename, \n",
        "        video_array=video_array,\n",
        "        fps=25,\n",
        "        video_codec=\"libx264\",\n",
        "        audio_array=wav,\n",
        "        audio_fps=16000,\n",
        "        audio_codec=\"aac\"\n",
        "    )    \n",
        "\n",
        "    del dataloader\n",
        "    return filename\n",
        "\n",
        "\n",
        "def avatar(opt,\n",
        "           path_label,\n",
        "           wav) -> str:\n",
        "    opt.isTrain = False\n",
        "\n",
        "    model = create_model(opt).cuda()\n",
        "    model.eval()\n",
        "\n",
        "    return pc_avs_inference(\n",
        "        opt, \n",
        "        path_label, \n",
        "        model, \n",
        "        wav)\n",
        "    \n",
        "\n",
        "opt = Namespace(\n",
        "    D_input='single', \n",
        "    VGGFace_pretrain_path='', \n",
        "    aspect_ratio=1.0, \n",
        "    audio_nc=256, \n",
        "    augment_target=False, \n",
        "    batchSize=16, \n",
        "    beta1=0.5, \n",
        "    beta2=0.999, \n",
        "    checkpoints_dir='./checkpoints', \n",
        "    clip_len=1, \n",
        "    crop=False, \n",
        "    crop_len=16, \n",
        "    crop_size=224, \n",
        "    data_path='/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv', \n",
        "    dataset_mode='voxtest', \n",
        "    defined_driven=False, \n",
        "    dis_feat_rec=False, \n",
        "    display_winsize=224, \n",
        "    driven_type='face', \n",
        "    driving_pose=True, \n",
        "    feature_encoded_dim=2560, \n",
        "    feature_fusion='concat', \n",
        "    filename_tmpl='{:06}.jpg', \n",
        "    fitting_iterations=10, \n",
        "    frame_interval=1, \n",
        "    frame_rate=25, \n",
        "    gan_mode='hinge', \n",
        "    gen_video=True, \n",
        "    generate_from_audio_only=True, \n",
        "    generate_interval=1, \n",
        "    gpu_ids=[0], \n",
        "    has_mask=False, \n",
        "    heatmap_size=3, \n",
        "    hop_size=160, \n",
        "    how_many=1000000, \n",
        "    init_type='xavier', \n",
        "    init_variance=0.02, \n",
        "    input_id_feature=True, \n",
        "    input_path='./checkpoints/results/input_path', \n",
        "    isTrain=False, \n",
        "    label_mask=False, \n",
        "    lambda_D=1, \n",
        "    lambda_contrastive=100, \n",
        "    lambda_crossmodal=1, \n",
        "    lambda_feat=10.0, \n",
        "    lambda_image=1.0, \n",
        "    lambda_rotate_D=0.1, \n",
        "    lambda_softmax=1000000, \n",
        "    lambda_vgg=10.0, \n",
        "    lambda_vggface=5.0, \n",
        "    landmark_align=False, \n",
        "    landmark_type='min', \n",
        "    list_end=1000000, \n",
        "    list_num=0, \n",
        "    list_start=0, \n",
        "    load_from_opt_file=False, \n",
        "    load_landmark=False, \n",
        "    lr=0.001, \n",
        "    lrw_data_path='/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv', \n",
        "    max_dataset_size=9223372036854775807, \n",
        "    meta_path_vox='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15/avatar.csv', \n",
        "    mode='cpu', \n",
        "    model='av', \n",
        "    multi_gpu=False, \n",
        "    nThreads=4, \n",
        "    n_mel_T=4, \n",
        "    name='demo', \n",
        "    ndf=64, \n",
        "    nef=16, \n",
        "    netA='resseaudio', \n",
        "    netA_sync='ressesync', \n",
        "    netD='multiscale', \n",
        "    netE='fan', \n",
        "    netG='modulate', \n",
        "    netV='resnext', \n",
        "    ngf=64, \n",
        "    no_TTUR=False, \n",
        "    no_flip=True, \n",
        "    no_ganFeat_loss=False, \n",
        "    no_gaussian_landmark=False, \n",
        "    no_id_loss=False, \n",
        "    no_instance=False, \n",
        "    no_pairing_check=False, \n",
        "    no_spectrogram=False, \n",
        "    no_vgg_loss=False, \n",
        "    noise_pose=True, \n",
        "    norm_A='spectralinstance', \n",
        "    norm_D='spectralinstance', \n",
        "    norm_E='spectralinstance', \n",
        "    norm_G='spectralinstance', \n",
        "    num_bins_per_frame=4, \n",
        "    num_classes=5830, \n",
        "    num_clips=1, \n",
        "    num_frames_per_clip=5, \n",
        "    num_inputs=1, \n",
        "    onnx=False, \n",
        "    optimizer='adam', \n",
        "    output_nc=3, \n",
        "    phase='test', \n",
        "    pose_dim=12, \n",
        "    positional_encode=False, \n",
        "    preprocess_mode='resize_and_crop', \n",
        "    results_dir='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15', \n",
        "    save_path='./conversations/feaa8fc7-8fc7-4ecf-acef-f06ca221b493/15', \n",
        "    serial_batches=False, \n",
        "    start_ind=0, \n",
        "    style_dim=2560, \n",
        "    style_feature_loss=True, \n",
        "    target_crop_len=0, \n",
        "    train_dis_pose=False, \n",
        "    train_recognition=False, \n",
        "    train_sync=False, \n",
        "    train_word=False, \n",
        "    trainer='audio', \n",
        "    use_audio=1, \n",
        "    use_audio_id=0, \n",
        "    use_transformer=False, \n",
        "    verbose=False, \n",
        "    vgg_face=False, \n",
        "    which_epoch='latest', \n",
        "    word_loss=False\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Talking-Face_PC-AVS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG8kX8OHvA-U"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# ***T-REX*** 🦖💬\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXxUibBOvZWT",
        "cellView": "form"
      },
      "source": [
        "# @title | T-REX | Start new Conversation\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the Skill Versions 👀🔀\n",
        "SMALL_TALK_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TRAVEL_SKILL_VERSION = \"ai21\" #@param [\"legacy\", \"ai21\"]\n",
        "TIMETABLE_SKILL_VERSION = \"legacy\" #@param [\"legacy\", \"ai21\"]\n",
        "TRANSLATION_COMPONENT = \"deepl\" #@param [\"legacy\", \"deepl\"]\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~\n",
        "NLP Configuration\n",
        "~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": {\n",
        "        \"to_native\": lambda x: x,\n",
        "        \"to_source\": lambda x: x,\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"to_native\": legacy_german_to_english_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_german_to_english_translation,\n",
        "        \"to_source\": legacy_english_to_german_translation if TRANSLATION_COMPONENT == \"legacy\" else deepl_english_to_german_translation,\n",
        "    }\n",
        "}\n",
        "\n",
        "SENTIMENT = {\n",
        "    \"positive\": [\"non-toxic\", \"travel\", \"small talk\"],\n",
        "    \"negative\": [\"toxic\", \"vulgar\"],\n",
        "}\n",
        "\n",
        "LEGACY_PERSONAS = {\n",
        "    \"warm_up\": legacy_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "LEGACY_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"num_return_sequences\": 2,\n",
        "    }, \n",
        "    \"function\": legacy_small_talk_skill\n",
        "}\n",
        "\n",
        "LEGACY_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"data\": travel_table,\n",
        "            \"time\": time,\n",
        "            \"location\": location,\n",
        "            \"samples\": legacy_travel_samples,\n",
        "            \"config\": {\n",
        "                \"temperature\": 0.1,\n",
        "                \"do_sample\": False,\n",
        "                \"max_length\": length(\n",
        "                    legacy_travel_samples,\n",
        "                    FEW_SHOT_MODEL) + 100,\n",
        "            }\n",
        "        }\n",
        "    }, \n",
        "    \"function\": legacy_travel_skill\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "AI21_PERSONAS = {\n",
        "    \"warm_up\": ai21_warm_up,\n",
        "    \"personas\": []\n",
        "}\n",
        "\n",
        "AI21_SMALL_TALK_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"model\": \"j1-jumbo\",\n",
        "        \"samples\": ai21_small_talk_samples,\n",
        "        \"config\": {\n",
        "            \"num_results\": 10,\n",
        "            \"max_tokens\": 64,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.98,\n",
        "            \"stop_sequences\": [\"user >>\"],\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_small_talk_skill\n",
        "}\n",
        "\n",
        "AI21_TRAVEL_SKILL = {\n",
        "    \"associations\": {\n",
        "        \"travel\": {\n",
        "            \"model\": \"j1-jumbo\",\n",
        "            \"data\": travel_table,\n",
        "            \"time\": time,\n",
        "            \"location\": location,\n",
        "            \"samples\": ai21_travel_samples,\n",
        "            \"config\": {\n",
        "                \"max_tokens\": 100,\n",
        "                \"temperature\": 0.0,\n",
        "                \"top_p\": 1.0,\n",
        "                \"stop_sequences\": [\"\\n\\n\"],\n",
        "\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"function\": ai21_travel_skill\n",
        "}\n",
        "\n",
        "PERSONAS = LEGACY_PERSONAS if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_PERSONAS\n",
        "\n",
        "SKILLS = {\n",
        "    \"travel\": {\n",
        "        \"labels\": [\"travel\", \"travel on time\", \"travel delayed\"],\n",
        "        \"pipeline\": LEGACY_TRAVEL_SKILL if TRAVEL_SKILL_VERSION == \"legacy\" else AI21_TRAVEL_SKILL\n",
        "    },\n",
        "    \"small talk\": {\n",
        "        \"labels\": [\"small talk\", \"other\"],\n",
        "        \"pipeline\": LEGACY_SMALL_TALK_SKILL if SMALL_TALK_SKILL_VERSION == \"legacy\" else AI21_SMALL_TALK_SKILL\n",
        "    }\n",
        "}\n",
        "\n",
        "CONFIG = {\n",
        "    \"languages\": LANGUAGES,\n",
        "    \"sentiment\": SENTIMENT,\n",
        "    \"personas\": PERSONAS,\n",
        "    \"skills\": SKILLS,\n",
        "}\n",
        "\n",
        "#@markdown ---\n",
        "ACTIVATE_LEGACY_PERSONAS = False # @param {type:\"boolean\"}\n",
        "PERSONA_1 = \"I work in a travel agency\" # @param {type:\"string\"}\n",
        "PERSONA_1 = f\"your persona: {PERSONA_1}\"\n",
        "PERSONA_2 = \"My name is Mia\" # @param {type:\"string\"}\n",
        "PERSONA_2 = f\"your persona: {PERSONA_2}\"\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "import copy\n",
        "import uuid\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "def trex_setup(**kwargs):\n",
        "    personas = copy.deepcopy(LEGACY_PERSONAS)\n",
        "    personas[\"personas\"] = [PERSONA_1, PERSONA_2] if ACTIVATE_LEGACY_PERSONAS else []\n",
        "\n",
        "    config = {\n",
        "        \"languages\": LANGUAGES,\n",
        "        \"personas\": personas,\n",
        "        \"skills\": SKILLS,\n",
        "        \"sentiment\": SENTIMENT,\n",
        "    }\n",
        "\n",
        "    nlp = NLP(config=config, **kwargs)\n",
        "\n",
        "    conversation_id = uuid.uuid4()\n",
        "    conversation_dir = f\"./conversations/{conversation_id}\"\n",
        "    !mkdir ./conversations/\n",
        "    !mkdir {conversation_dir}\n",
        "\n",
        "    interaction_counter = 0\n",
        "    f\"Current Conversation is logged at: {conversation_dir}\"\n",
        "\n",
        "    !rm -r /content/Talking-Face_PC-AVS/results/id_input_pose_00473_audio_tts_output\n",
        "\n",
        "    return nlp\n",
        "\n",
        "nlp = execute(trex_setup, verbose=VERBOSE)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWlnRnDoJ_gd",
        "cellView": "form"
      },
      "source": [
        "# @title # Interact with T-REX 🦖\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Selection between the STT & TTS Module Versions 👀🔀\n",
        "STT_VERSION = \"gcloud\" #@param [\"legacy\", \"gcloud\"]\n",
        "TTS_VERSION = \"gcloud\" #@param [\"legacy\", \"gcloud\"]\n",
        "\n",
        "stt = legacy_stt if STT_VERSION == \"legacy\" else gcloud_stt\n",
        "tts = legacy_tts if TTS_VERSION == \"legacy\" else gcloud_tts\n",
        "\n",
        "LANGUAGE_CODE = \"de-DE\" if LANGUAGE == \"de\" else \"en-US\"\n",
        "\n",
        "#@markdown ### Selection Google Cloud TTS Voice 👀🔀\n",
        "EN_TTS_VOICE_NAME = \"en-US-Wavenet-B\" #@param [\"en-US-Wavenet-A\", \"en-US-Wavenet-B\", \"en-US-Wavenet-C\", \"en-US-Wavenet-D\", \"en-US-Wavenet-E\", \"en-US-Wavenet-F\", \"en-US-Wavenet-G\", \"en-US-Wavenet-H\", \"en-US-Wavenet-I\", \"en-US-Wavenet-J\"]\n",
        "DE_TTS_VOICE_NAME = \"de-DE-Wavenet-C\" #@param [\"de-DE-Wavenet-A\", \"de-DE-Wavenet-B\", \"de-DE-Wavenet-C\", \"de-DE-Wavenet-D\", \"de-DE-Wavenet-E\", \"de-DE-Wavenet-F\"]\n",
        "\n",
        "VOICE_NAME = DE_TTS_VOICE_NAME if LANGUAGE == \"de\" else EN_TTS_VOICE_NAME\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Define the  Input\n",
        "USE_STT_AS_INPUT = True # @param {type:\"boolean\"}\n",
        "TEXT_INPUT = \"Wie geht es dir heute?\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = True # @param {type:\"boolean\"}\n",
        "\n",
        "def trex(input: str=\"\", **kwargs) -> str:\n",
        "    print(f\"[DEBUG] |T-REX STT| STT Output: {input}\")\n",
        "\n",
        "    output = nlp(input, **kwargs)\n",
        "    print(f\"[DEBUG] |T-REX NLP| NLP Output: {output}\")\n",
        "\n",
        "    audio = tts(output, voice_name=VOICE_NAME)\n",
        "    audio = postprocessing(audio)\n",
        "\n",
        "    image_id = \"1\" if LANGUAGE == \"de\" else \"2\"\n",
        "    path_labels = f\"./misc/Input/input {image_id} ./misc/Pose_Source/00473 158 ./misc/Audio_Source/tts_output.mp3 None 0 None\"\n",
        "\n",
        "    video = avatar(\n",
        "        opt,\n",
        "        path_labels,\n",
        "        audio\n",
        "    )\n",
        "\n",
        "    return video\n",
        "\n",
        "input = stt(record(), language_code=LANGUAGE_CODE) if USE_STT_AS_INPUT else TEXT_INPUT\n",
        "video = execute(trex, input=input, verbose=VERBOSE)\n",
        "\n",
        "# Show the final output.\n",
        "mp4 = open(video,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + base64.b64encode(mp4).decode()\n",
        "\n",
        "HTML(\"\"\"\n",
        "<video width=700 controls autoplay>\n",
        "    <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJSj4o6TA86"
      },
      "source": [
        "---\n",
        "# ***Test*** TREX 🦖💬\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMQKe2YbHZGG"
      },
      "source": [
        "## ***Test the NLP Module*** 📰🤯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGNWpDXpStcm",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Utils for Testing\n",
        "# @markdown ✋ Rerun Cell if Runtime was restarted 🔄\n",
        "\n",
        "\n",
        "from typing import Any\n",
        "from typing import Tuple\n",
        "from typing import List\n",
        "\n",
        "import io\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import transformers\n",
        "\n",
        "\n",
        "def get_nlp_models(\n",
        "    order: List[str] = [\n",
        "        \"SMALL_TALK\", \n",
        "        \"FEW_SHOT\", \n",
        "        \"TABLE_QA\", \n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\", \n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\"],\n",
        "    delimiter: str = \",\") -> str:\n",
        "    models = {\n",
        "        \"ZERO_SHOT\": ZERO_SHOT_MODEL,\n",
        "        \"SMALL_TALK\": SMALL_TALK_MODEL,\n",
        "        \"FEW_SHOT\": FEW_SHOT_MODEL,\n",
        "        \"TABLE_QA\": TABLE_QA_MODEL,\n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\": GERMAN_TO_ENGLISH_MODEL,\n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\": ENGLISH_TO_GERMAN_MODEL,\n",
        "    }\n",
        "    return delimiter.join([models[i] for i in order])\n",
        "\n",
        "def test(component: Any,\n",
        "         dataset: List[Tuple[Any]],\n",
        "         config: dict = {}) -> dict:\n",
        "    results = {**locals()}\n",
        "\n",
        "    predictions = []\n",
        "    for x, y in dataset:\n",
        "        prediction = \"\"\n",
        "        try:\n",
        "            prediction = component(x, **config)\n",
        "        except: pass\n",
        "        \n",
        "        predictions.append(prediction)\n",
        "    \n",
        "    results[\"predictions\"] = predictions\n",
        "    results[\"models\"] = get_nlp_models()\n",
        "    return results\n",
        "\n",
        "def upload_file(extension: str) -> bytes:\n",
        "    \"\"\"Upload files and return the content of the file with the extension.\"\"\"\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        if extension in filename:\n",
        "            return uploaded[filename]\n",
        "    \n",
        "    raise Exception(\"No file with specified extension was found in the uploaded files!\\n\"\\\n",
        "                    \"Check the uploaded files and please retry the procedure!\")\n",
        "\n",
        "def dataframe_from_csv(content: bytes,\n",
        "                       **kwargs) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a csv file into a DataFrame.\"\"\"\n",
        "    return pd.read_csv(io.BytesIO(content))\n",
        "\n",
        "def dataframe_from_excel(content: bytes,\n",
        "                         sheet: str) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a excel sheet into a DataFrame.\"\"\"\n",
        "    return pd.read_excel(\n",
        "        io.BytesIO(content),\n",
        "        sheet_name=sheet)\n",
        "    \n",
        "def dataframe_from_type(type: str,\n",
        "                        content: bytes,\n",
        "                        sheet: str=None) -> pd.DataFrame:\n",
        "    \"\"\"Load the content of a file of the given type into a DataFrame.\"\"\"\n",
        "    function = {\n",
        "        \".xlsx\": dataframe_from_excel,\n",
        "        \".csv\": dataframe_from_csv,\n",
        "    }\n",
        "\n",
        "    return function[type](content, sheet=sheet)\n",
        "\n",
        "def preprocess_dataframe(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Convert a given DataFrame into testing format.\"\"\"\n",
        "    dataframe = dataframe.astype(\n",
        "        {column: str for column in dataframe.columns.values})\n",
        "    \n",
        "    return dataframe\n",
        "\n",
        "def parse_table_from_dataframe(dataframe: pd.DataFrame,\n",
        "                               excluded_headers: List[str],\n",
        "                               delimiter: str=\",\") -> str:\n",
        "    \"\"\"Convert the dataframe into a Table-QA table, excluding specified headers.\"\"\"\n",
        "    dataframe = dataframe.loc[:, ~dataframe.columns.isin(excluded_headers)]\n",
        "    \n",
        "    table = df_to_csv(dataframe)\n",
        "    table = table.replace(\",\", delimiter)\n",
        "    return table\n",
        "\n",
        "def parse_dict_from_dataframe(dataframe: pd.DataFrame,\n",
        "                              headers: list) -> dict:\n",
        "    \"\"\"Load a dataset as dict from a DataFrame restricting to the headers.\"\"\"\n",
        "    dataframe = dataframe.to_dict()\n",
        "    datafame = {key: value for key, value in dataframe.items()\n",
        "                    if key in headers}\n",
        "    return dataframe\n",
        "\n",
        "def dataset_from_dict(test: dict,\n",
        "                      header_x: str=\"x\",\n",
        "                      header_y: str=\"y\") -> List[Tuple[str]]:\n",
        "    \"\"\"Create a list of (x, y) tuples to execute a given test.\"\"\"\n",
        "    x, y = test[header_x], test[header_y]\n",
        "    \n",
        "    x = [x[i] for i in x.keys()]\n",
        "    y = [y[i] for i in y.keys()]\n",
        "\n",
        "    dataset = [(i, j) for i, j in zip(x, y)]\n",
        "    return dataset\n",
        "\n",
        "def preprocess_dataset(dataset: List[Tuple[str]]) -> List[Tuple[transformers.Conversation, str]]:\n",
        "    \"\"\"Prepare the dataset for testing.\"\"\"\n",
        "    def input_as_conversation(sample):\n",
        "        x, y = sample\n",
        "        return transformers.Conversation(x), y\n",
        "\n",
        "    dataset = list(map(input_as_conversation, dataset))\n",
        "    return dataset\n",
        "\n",
        "def save_test_results(results: dict, \n",
        "                      dictionary: dict,\n",
        "                      filename: str=\"test.xlsx\") -> str:\n",
        "    \"\"\"Save the results of the test as excel file and return the filename.\"\"\"\n",
        "    dictionary[\"Output\"] = {}\n",
        "\n",
        "    for i, prediction in enumerate(results[\"predictions\"]):\n",
        "        dictionary[\"Output\"][i] = prediction\n",
        "\n",
        "    dataframe = pd.DataFrame.from_dict(dictionary)\n",
        "    dataframe.to_excel(filename)\n",
        "\n",
        "    return filename"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCk74Lnm7TXK",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "outputId": "adad05e7-348d-4444-830e-22ead67b69e5"
      },
      "source": [
        "# @title | NLP | Prepare Testing Data 📋 🆒\n",
        "# @markdown ---\n",
        "\n",
        "# @markdown Select a file type. The first file with the given extension will be loaded. 📗\n",
        "EXTENSION = \".xlsx\" #@param [\".xlsx\", \".csv\"]\n",
        "\n",
        "# @markdown Select a sheet if the file is an excel file. 📜\t\n",
        "SHEET = \"Test1\" #@param {type: \"string\"}\n",
        "\n",
        "# @markdown Specify headers in the sheet that shall be included in the dataset. 📋\n",
        "DATASET_HEADERS = \"Question, Answer\" #@param {type: \"string\"}\n",
        "DATASET_HEADERS = DATASET_HEADERS.split(\", \")\n",
        "\n",
        "assert len(DATASET_HEADERS) == 2, \"Warning! There can only be two dataset headers! Please refactor and retry!\"\n",
        "DATASET_HEADER_X, DATASET_HEADER_Y = DATASET_HEADERS\n",
        "\n",
        "# @markdown ✨ Note: The headers must be concatenated via the string \", \".\n",
        "\n",
        "\n",
        "uploaded_content = upload_file(EXTENSION)\n",
        "dataframe = dataframe_from_type(\n",
        "    EXTENSION, \n",
        "    uploaded_content, \n",
        "    SHEET)\n",
        "dataframe = preprocess_dataframe(dataframe)\n",
        "\n",
        "dictionary = parse_dict_from_dataframe(\n",
        "    dataframe,\n",
        "    DATASET_HEADERS)\n",
        "dataset = dataset_from_dict(\n",
        "    dictionary,\n",
        "    DATASET_HEADER_X,\n",
        "    DATASET_HEADER_Y)\n",
        "dataset = preprocess_dataset(dataset)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-064ffb8e-9dff-4d44-9235-3e5749c07a32\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-064ffb8e-9dff-4d44-9235-3e5749c07a32\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test_NLP_TravelSkill.xlsx to Test_NLP_TravelSkill (2).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "u4c0bUZm1DGT",
        "cellView": "form",
        "outputId": "792672ea-0bbd-436b-9148-a9c6babaf794"
      },
      "source": [
        "# @title | NLP | Display the Dataset 📋🎉\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.DataTable(\n",
        "    pd.DataFrame(\n",
        "        dataset_from_dict(\n",
        "            dictionary,\n",
        "            DATASET_HEADER_X,\n",
        "            DATASET_HEADER_Y)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"It is 12:30. Wich is the next train from Frankfurt to Leipzig?\",\n\"The next train to Leipzig is ICE 1655 at 17:21 from track 9.\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"It is 17:22. Wich is the next train from Frankfurt to Leipzig?\",\n\"The next train to Leipzig is ICE 594 at 18:14 from track 9.\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"When will the ICE 594 from Frankfurt arrive in Leipzig.\",\n\"The ICE 594 will arrive at 21:10 on the track 13.\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"How long will the ICE 1655 need to get from Frankfurt to Leipzig?\",\n\"The  ICE 1655 will need 3 hours and 3 minutes.\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"At wich track will the FLX 1354 from Berlin arrive?\",\n\"The FLX 1354 from Berlin will arrive at the track 5 at 10:07.\"],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"Which train is the fastest option from Berlin to Hamburg?\",\n\"The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\"],\n [{\n            'v': 6,\n            'f': \"6\",\n        },\n\"Which is the fastest option from Berlin to Hamburg?\",\n\"The ICE 806 is the fastest option. It's travel duration is only 1 hour and 43 minutes.\"],\n [{\n            'v': 7,\n            'f': \"7\",\n        },\n\"Can I take a Flixtrain from Berlin to Hamburg?\",\n\"The Flixtrain FLX 1354 will travel to Hamburg starting at 08:07 from track 8.\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"0\"], [\"string\", \"1\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It is 12:30. Wich is the next train from Frank...</td>\n",
              "      <td>The next train to Leipzig is ICE 1655 at 17:21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It is 17:22. Wich is the next train from Frank...</td>\n",
              "      <td>The next train to Leipzig is ICE 594 at 18:14 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When will the ICE 594 from Frankfurt arrive in...</td>\n",
              "      <td>The ICE 594 will arrive at 21:10 on the track 13.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How long will the ICE 1655 need to get from Fr...</td>\n",
              "      <td>The  ICE 1655 will need 3 hours and 3 minutes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>At wich track will the FLX 1354 from Berlin ar...</td>\n",
              "      <td>The FLX 1354 from Berlin will arrive at the tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Which train is the fastest option from Berlin ...</td>\n",
              "      <td>The ICE 806 is the fastest option. It's travel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Which is the fastest option from Berlin to Ham...</td>\n",
              "      <td>The ICE 806 is the fastest option. It's travel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Can I take a Flixtrain from Berlin to Hamburg?</td>\n",
              "      <td>The Flixtrain FLX 1354 will travel to Hamburg ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nztBbD3cJN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "cellView": "form",
        "outputId": "c5918e77-e010-4e3d-9b8d-14f67324216b"
      },
      "source": [
        "# @title | NLP | Test Component 👻\n",
        "# @markdown ---\n",
        "\n",
        "import uuid\n",
        "\n",
        "from datetime import datetime as dt\n",
        "from datetime import timedelta as td\n",
        "from datetime import timezone as tz\n",
        "\n",
        "\n",
        "FILENAME = f\"Test_NLP_%u_%t.xlsx\" #@param {type: \"string\"}\n",
        "# @markdown ⚡ Select if a UUID shall be substituted for the **%u** string.\n",
        "UUID = True # @param {type:\"boolean\"}\n",
        "# @markdown ✨ Note: **%t** in the filename will the replaced with the current timestamp.\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "uuid_ = f\"_{str(uuid.uuid4())}_\" if UUID else \"\"\n",
        "filename = FILENAME.replace(\"_%u_\", uuid_)\n",
        "\n",
        "timestamp = dt.now() + td(hours=2)\n",
        "timestamp = f\"{timestamp:%Y%m%d%H%M}\"\n",
        "filename = filename.replace(\"%t\", timestamp)\n",
        "\n",
        "nlp = NLP(config=CONFIG)\n",
        "\n",
        "results = test(\n",
        "    nlp,\n",
        "    dataset,\n",
        "    {\"verbose\": VERBOSE})\n",
        "\n",
        "save_test_results(\n",
        "    results,\n",
        "    dictionary,\n",
        "    filename)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG] |AI21 Warm Up| personas: Conversation id: f2649e51-5b2c-4de6-adbc-bec92cc5769b \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Test_NLP_4f8f346d-5b51-41bc-a140-aa930b468c77_202109021033.xlsx'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fUttuknrpOt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
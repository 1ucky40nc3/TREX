{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "testing_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNtQk81E2I7d6O4i52fcCG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1ucky40nc3/TREX/blob/testing/testing_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCNgpK3tZbZ",
        "outputId": "fa35e6d0-c793-4ea3-f7fd-0f906f705494"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 19 21:30:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78i3mCfXdyK1",
        "cellView": "form"
      },
      "source": [
        "# @title Utils for the entire Notebook\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "from IPython.utils.io import capture_output\n",
        "\n",
        "\n",
        "def execute(func, *args, verbose: bool = False, **kwargs):\n",
        "    if verbose:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})\n",
        "    \n",
        "    with capture_output() as captured:\n",
        "        return func(*args, **{\"verbose\": verbose, **kwargs})"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0AFeWgzwFgr"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "# ***Natural Language Processing (NLP)*** ðŸ“°ðŸ¤¯\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mC4zn53LYTw9"
      },
      "source": [
        "# @title | NLP | Install Dependencies â‡©\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "    \n",
        "\n",
        "def install_nlp_dependencies(**kwargs):\n",
        "    !pip install sentencepiece\n",
        "    !pip install transformers\n",
        "    !pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "    !pip install torch-geometric\n",
        "    !pip install torch-scatter==2.0.8 -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "\n",
        "execute(install_nlp_dependencies, verbose=VERBOSE)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1U9U9gdwKig",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | Initialize the NLP Pipelines\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "def TABLE_QA(*args, **kwargs):\n",
        "    return {\"answer\": \"WOW\"}\n",
        "\n",
        "def device(boolean: bool) -> int:\n",
        "    return 0 if boolean else -1\n",
        "\n",
        "#@markdown ---\n",
        "TABLE_QA_MODEL = \"google/tapas-base-finetuned-wikisql-supervised\" #@param [\"lysandre/tiny-tapas-random-wtq\", \"lysandre/tiny-tapas-random-sqa\", \"google/tapas-base-finetuned-wtq\", \"google/tapas-base-finetuned-sqa\", \"google/tapas-base-finetuned-wikisql-supervised\", \"google/tapas-large-finetuned-wtq\", \"google/tapas-large-finetuned-sqa\", \"google/tapas-large-finetuned-wikisql-supervised\"]\n",
        "USE_GPU_4_TABLE_QA = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "SMALL_TALK_MODEL = \"facebook/blenderbot-90M\" #@param [\"facebook/blenderbot-90M\", \"facebook/blenderbot-400M-distill\", \"facebook/blenderbot-1B-distill\", \"facebook/blenderbot-3B\"]\n",
        "USE_GPU_4_SMALL_TALK = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "FEW_SHOT_MODEL = \"EleutherAI/gpt-neo-125M\" #@param [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"EleutherAI/gpt-neo-125M\", \"EleutherAI/gpt-neo-1.3B\", \"EleutherAI/gpt-neo-2.7B\"]\n",
        "USE_GPU_4_FEW_SHOT = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "DEACTIVATE_TABLE_QA = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "LANGUAGE = \"en\" #@param [\"en\", \"de\"]\n",
        "\n",
        "#@markdown ---\n",
        "GERMAN_TO_ENGLISH_MODEL = \"Helsinki-NLP/opus-mt-de-en\" #@param [\"Helsinki-NLP/opus-mt-de-en\"]\n",
        "USE_GPU_4_GERMAN_TO_ENGLISH = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "ENGLISH_TO_GERMAN_MODEL = \"Helsinki-NLP/opus-mt-en-de\" #@param [\"Helsinki-NLP/opus-mt-en-de\"]\n",
        "USE_GPU_4_ENGLISH_TO_GERMAN = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "def initialize_nlp_pipelines(**kwargs):\n",
        "    print(\"[DEBUG] Downloading Zero-Shot-Classification Components\")\n",
        "    ZERO_SHOT = transformers.pipeline(\n",
        "        \"zero-shot-classification\")\n",
        "\n",
        "    print(\"[DEBUG] Downloading Small-Talk Components\")\n",
        "    SMALL_TALK = transformers.pipeline(\n",
        "        \"conversational\", \n",
        "        model=SMALL_TALK_MODEL, \n",
        "        device=device(USE_GPU_4_SMALL_TALK))\n",
        "\n",
        "    print(\"[DEBUG] Downloading Text-To-Text Components\")\n",
        "    FEW_SHOT = transformers.pipeline(\n",
        "        \"text-generation\", \n",
        "        model=FEW_SHOT_MODEL, \n",
        "        device=device(USE_GPU_4_FEW_SHOT))\n",
        "\n",
        "\n",
        "    if not DEACTIVATE_TABLE_QA:\n",
        "        print(\"[DEBUG] Downloading Table QA Components\")\n",
        "        TABLE_QA = transformers.pipeline(\n",
        "            \"table-question-answering\", \n",
        "            model=TABLE_QA_MODEL, \n",
        "            device=device(USE_GPU_4_TABLE_QA))\n",
        "        \n",
        "    if LANGUAGE == \"de\":\n",
        "        print(\"[DEBUG] Downloading German-To-English Translation Components\")\n",
        "        GERMAN_TO_ENGLISH_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_de_to_en\", \n",
        "            model=GERMAN_TO_ENGLISH_MODEL)\n",
        "        print(\"[DEBUG] Downloading English-To-German Translation Components\")\n",
        "        ENGLISH_TO_GERMAN_TRANSLATOR = transformers.pipeline(\n",
        "            \"translation_en_to_de\", \n",
        "            model=ENGLISH_TO_GERMAN_MODEL)\n",
        "    \n",
        "    return locals()\n",
        "\n",
        "PIPELINES = execute(initialize_nlp_pipelines, verbose=VERBOSE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "N4aTN97_w5sH",
        "cellView": "form",
        "outputId": "44915ada-951c-4c0a-84cf-25e2ea1b030d"
      },
      "source": [
        "# @title | NLP | Set up Services for Data\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "import transformers\n",
        "\n",
        "\n",
        "TRAIN_TABLE = \"\"\"Location,Train,Start,Destination,Departure,Arrival,Delay\n",
        "Munich,ICE 77,Munich,Berlin,12:30,13:33,2\n",
        "Munich,ICE 56,Munich,Leipzig,12:30,13:30,4\n",
        "Munich,ICE 33,Leipzig,Berlin,13:30,14:00,45\"\"\"\n",
        "\n",
        "PLANE_TABLE = \"\"\"Location,Plane,Start,Destination,Departure,Arrival,Delay\n",
        "Munich,Eurowings (EW8003),Munich,Berlin,12:30,13:33,0\n",
        "Munich,Lufthansa (LH1940),Munich,Leipzig,12:30,13:30,10\n",
        "Munich,Lufthansa (LH2040),Leipzig,Berlin,13:30,14:00,7\"\"\"\n",
        "\n",
        "\n",
        "def train_table() -> pd.DataFrame:\n",
        "    return pd.read_csv(io.StringIO(TRAIN_TABLE))\n",
        "\n",
        "def plane_table() -> pd.DataFrame:\n",
        "    return pd.read_csv(io.StringIO(PLANE_TABLE))\n",
        "\n",
        "def df_to_csv(df) -> str:\n",
        "    csv = io.StringIO()\n",
        "    df.to_csv(csv, index=False)\n",
        "    return csv.getvalue()\n",
        "\n",
        "def csv_to_df(csv) -> pd.DataFrame:\n",
        "    return pd.read_csv(io.StringIO(csv))\n",
        "\n",
        "def travel_tables(tables=[train_table(), plane_table()]) -> pd.DataFrame:\n",
        "    travel = pd.concat(tables)\n",
        "    travel = travel.fillna(\"NONE\")\n",
        "\n",
        "    csv = df_to_csv(travel)\n",
        "    travel = csv_to_df(csv)\n",
        "    travel = travel.astype(\n",
        "        {column: str for column in travel.columns.values})\n",
        "    return travel\n",
        "\n",
        "travel_samples = \"\"\"Question: \"I am in Hannover. It is 17:48. Which train can I take from Munich to Berlin?\" Context: \"ICE 33\" Answer: \"The train ICE 33 will travel from Munich to Berlin.\"\n",
        "Question: \"I am in Frankfurt. It is 09:32. When will the next flight to Madrid leave?\" Context: \"07:59\" Answer: \"The next to Madrid will leave 07:59.\"\n",
        "Question: \"I am in Hannover. It is 17:48. What is the best train to get to Berlin from London?\" Context: \"ICE 33\" Answer: \"The train ICE 33 is the fastest.\"\n",
        "Question: \"I am in Munich. It is 05:51. From which platform does the RB 61 exit to Zurich?\" Context: \"8\" Answer: \"The RB 61 will departs from the platform 8.\"\n",
        "Question: \"I am in Berlin. It is 12:20. How can I get to London by aircraft?\" Context: \"Eurowings (EW8003)\" Answer: \"The flight Eurowings (EW8003) will leave for London.\"\n",
        "Question: \"I am in London. It is 12:20. I am at a train station. How can I get to Frankfurt?\" Context: \"ICE 923\" Answer: \"The train ICE 77 is available for your trip.\"\n",
        "Question: \"I am in Hamburg. It is 23:43. From which gate does the Lufthansa aircraft (LH1940) take off?\" Context: \"23\" Answer: \"The Lufthansa airliner (LH1940) will take off from gate 23.\"\n",
        "Question: \"I am in Stuttgart. It is 08:24. When will the next ICE to Bremen leave?\" Context: \"07:59\" Answer: \"The next to Bremen will leave 07:59.\"\n",
        "Question: \"I am in Bremen. It is 20:15. Is the ICE 1556 delayed?\" Context: \"9\" Answer: \"The ICE 1556 will be delayed by 9 minutes.\"\n",
        "Question: \"I am in Dresden. It is 10:17. How much is the flight LH1239 delayed?\" Context: \"59\" Answer: \"The flight LH1239 will be delayed by 59 minutes.\"\n",
        "\"\"\"\n",
        "\n",
        "def samples_length(samples: str, model: str) -> int:\n",
        "    if not \"EleutherAI/gpt-neo\" in model:\n",
        "        raise Exception(\n",
        "            \"\"\"The tokenizer of the FEW-SHOT model is not accessible!\n",
        "            Therefore the sample length can not be computed.\"\"\")\n",
        "        \n",
        "    tokenizer = transformers.GPT2Tokenizer.from_pretrained(FEW_SHOT_MODEL)\n",
        "    input_ids = tokenizer(travel_samples, return_tensors=\"pt\").input_ids\n",
        "    return input_ids.shape[-1]\n",
        "\n",
        "\n",
        "TRAVEL_TIME = \"7:00\" #@param {type: \"string\"}\n",
        "TRAVEL_LOCATION = \"Munich\" #@param {type: \"string\"}\n",
        "\n",
        "def travel_time() -> str:\n",
        "    return TRAVEL_TIME\n",
        "\n",
        "def travel_location() -> str:\n",
        "    return TRAVEL_LOCATION\n",
        "\n",
        "travel_tables()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Location</th>\n",
              "      <th>Train</th>\n",
              "      <th>Start</th>\n",
              "      <th>Destination</th>\n",
              "      <th>Departure</th>\n",
              "      <th>Arrival</th>\n",
              "      <th>Delay</th>\n",
              "      <th>Plane</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Munich</td>\n",
              "      <td>ICE 77</td>\n",
              "      <td>Munich</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>12:30</td>\n",
              "      <td>13:33</td>\n",
              "      <td>2</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Munich</td>\n",
              "      <td>ICE 56</td>\n",
              "      <td>Munich</td>\n",
              "      <td>Leipzig</td>\n",
              "      <td>12:30</td>\n",
              "      <td>13:30</td>\n",
              "      <td>4</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Munich</td>\n",
              "      <td>ICE 33</td>\n",
              "      <td>Leipzig</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>13:30</td>\n",
              "      <td>14:00</td>\n",
              "      <td>45</td>\n",
              "      <td>NONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Munich</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Munich</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>12:30</td>\n",
              "      <td>13:33</td>\n",
              "      <td>0</td>\n",
              "      <td>Eurowings (EW8003)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Munich</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Munich</td>\n",
              "      <td>Leipzig</td>\n",
              "      <td>12:30</td>\n",
              "      <td>13:30</td>\n",
              "      <td>10</td>\n",
              "      <td>Lufthansa (LH1940)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Munich</td>\n",
              "      <td>NONE</td>\n",
              "      <td>Leipzig</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>13:30</td>\n",
              "      <td>14:00</td>\n",
              "      <td>7</td>\n",
              "      <td>Lufthansa (LH2040)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Location   Train    Start  ... Arrival Delay               Plane\n",
              "0   Munich  ICE 77   Munich  ...   13:33     2                NONE\n",
              "1   Munich  ICE 56   Munich  ...   13:30     4                NONE\n",
              "2   Munich  ICE 33  Leipzig  ...   14:00    45                NONE\n",
              "3   Munich    NONE   Munich  ...   13:33     0  Eurowings (EW8003)\n",
              "4   Munich    NONE   Munich  ...   13:30    10  Lufthansa (LH1940)\n",
              "5   Munich    NONE  Leipzig  ...   14:00     7  Lufthansa (LH2040)\n",
              "\n",
              "[6 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDT5V9m2w3sQ",
        "cellView": "form"
      },
      "source": [
        "# @title | NLP | NLP Implementation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from typing import Callable\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "class Associations(Dict):\n",
        "    data: Callable[[], pd.DataFrame]\n",
        "    samples: str\n",
        "\n",
        "Response = Tuple[str, Optional[transformers.Conversation]]\n",
        "\n",
        "Function = Callable[\n",
        "    [transformers.Conversation], \n",
        "    Response\n",
        "]\n",
        "\n",
        "class Skill(Dict):\n",
        "    associations: Associations\n",
        "    function: Function\n",
        "\n",
        "class Skills(Dict):\n",
        "    name: str\n",
        "    skill: Skill\n",
        "\n",
        "WarmUp = Callable[\n",
        "    [transformers.Conversation], \n",
        "    transformers.Conversation\n",
        "]\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Classification on a Zero-Shot basis.\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def zero_shot_classification(input: str, \n",
        "                             labels: List[str], \n",
        "                             top_k: Optional[int] = 1,\n",
        "                             verbose: Optional[bool] = False,\n",
        "                             **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Zero-Shot Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Zero-Shot Classification| labels: {labels}\")\n",
        "        print(f\"[DEBUG] |Zero-Shot Classification| top_k: {top_k}\")\n",
        "    \n",
        "    top_k_labels = PIPELINES[\"ZERO_SHOT\"](\n",
        "        input, labels)[\"labels\"][:top_k]\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Zero-Shot Classification| top_k_labels: {top_k_labels}\")\n",
        "    return top_k_labels\n",
        "\n",
        "def skill_classification(input: str, \n",
        "                         skills: List[str], \n",
        "                         verbose: Optional[bool] = False,\n",
        "                         **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Skill Classification| skills: {skills}\")\n",
        "\n",
        "    skill = zero_shot_classification(input, skills, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Skill Classification| skill: {skill}\")\n",
        "    return skill\n",
        "\n",
        "def toxicity_classification(input: str,\n",
        "                            verbose: Optional[bool] = False,\n",
        "                            labels: List[str] = [\"toxic\", \"non-toxic\"],\n",
        "                            **kwargs) -> List[str]:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Toxicity Classification| input: {input}\")\n",
        "        print(f\"[DEBUG] |Toxicity Classification| labels: {labels}\")\n",
        "\n",
        "    label = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Toxicity Classification| label: {label}\")\n",
        "    return label\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~\n",
        "Section for Table QA.\n",
        "~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def table_question_answering(input: str, \n",
        "                             table: pd.DataFrame, \n",
        "                             verbose: Optional[bool] = False, \n",
        "                             **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| input: {input}\")\n",
        "        print(f\"[DEBUG] |Table Question Answering| table: \\n{table}\")\n",
        "    \n",
        "    output = PIPELINES[\"TABLE_QA\"](table=table, query=input)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Table Question Answering| output: \\n{output}\")\n",
        "    return output[\"answer\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Few-Shot Text Generation\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def few_shot(query: str, \n",
        "             samples: str, \n",
        "             verbose: Optional[bool] = False, \n",
        "             **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "    \n",
        "    output = PIPELINES[\"FEW_SHOT\"](samples + query, **kwargs)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Few-Shot Text Generation| output: \\n{output}\")\n",
        "    return output[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "def travel_few_shot(query: str, \n",
        "                    samples: str, \n",
        "                    verbose: Optional[bool] = False, \n",
        "                    **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| query: \\n{query}\")\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| samples: \\n{samples}\")\n",
        "\n",
        "    output = few_shot(query, \n",
        "                      samples, \n",
        "                      verbose, \n",
        "                      **kwargs)\n",
        "    output = output[len(samples + query):]\n",
        "    output = output.split('\"')[0]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Few-Shot Text Generation| output: \\n{output}\")\n",
        "    return output\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Skill Functions\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def travel_skill(conversation: transformers.Conversation, \n",
        "                 associations: Associations, \n",
        "                 verbose: Optional[bool] = False, \n",
        "                 **kwargs) -> Response:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Skill| input conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |Travel Skill| associations: \\n{associations}\")\n",
        "\n",
        "    input = conversation.new_user_input\n",
        "    labels = list(associations.keys())\n",
        "\n",
        "    variant = zero_shot_classification(input, labels, **kwargs)[0]\n",
        "\n",
        "    data = associations[variant][\"data\"]()\n",
        "    time = associations[variant][\"time\"]()\n",
        "    location = associations[variant][\"location\"]()\n",
        "    samples = associations[variant][\"samples\"]\n",
        "    config = associations[variant][\"config\"]\n",
        "\n",
        "    cell = table_question_answering(input, data, verbose)\n",
        "\n",
        "    input = f\"I am in {location}. It is {time}. {input}\"\n",
        "    query = f'Question: \"{input}\" Context: \"{cell}\" Answer: \"'\n",
        "\n",
        "    output = travel_few_shot(\n",
        "        query, \n",
        "        samples, \n",
        "        verbose, \n",
        "        **{**config, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Travel Skill| variant: {variant}\")\n",
        "        print(f\"[DEBUG] |Travel Skill| cell: {cell}\")\n",
        "        print(f\"[DEBUG] |Travel Skill| output: {output}\")\n",
        "    return output, None\n",
        "\n",
        "def small_talk_skill(conversation: transformers.Conversation, \n",
        "                     verbose: Optional[bool] = False, \n",
        "                     **kwargs) -> Response:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Small Talk Skill| input conversation: \\n{conversation}\")\n",
        "\n",
        "    conversation = PIPELINES[\"SMALL_TALK\"](conversation)\n",
        "    output = conversation.generated_responses[-1]\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Small Talk Skill| output conversation: \\n{conversation}\")\n",
        "        print(f\"[DEBUG] |Small Talk Skill| output: {output}\")\n",
        "    return output, conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Section for Personas and Warm Up\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "\n",
        "def warm_up(conversation: transformers.Conversation, \n",
        "            personas: List[str],\n",
        "            verbose: Optional[bool] = False,\n",
        "            **kwargs) -> transformers.Conversation:\n",
        "    for persona in personas:\n",
        "        conversation.add_user_input(persona)\n",
        "        conversation = PIPELINES[\"SMALL_TALK\"](conversation)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |Warm Up| personas: {personas}\")\n",
        "        print(f\"[DEBUG] |Warm Up| personas: {conversation}\")\n",
        "    return conversation\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~~~\n",
        "Language Processors\n",
        "~~~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "def german_to_english_translation(input: str,\n",
        "                                  verbose: Optional[bool] = False, \n",
        "                                  **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |German-To-English Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"GERMAN_TO_ENGLISH_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |German-To-English Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "def english_to_german_translation(input: str,\n",
        "                                  verbose: Optional[bool] = False, \n",
        "                                  **kwargs) -> str:\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |English-To-German Translation| input: {input}\")\n",
        "\n",
        "    translation = PIPELINES[\"ENGLISH_TO_GERMAN_TRANSLATOR\"](input, **{\"num_beams\": 40, **kwargs})\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"[DEBUG] |English-To-German Translation| translation: {translation}\")\n",
        "    return translation[0][\"translation_text\"]\n",
        "\n",
        "\n",
        "\"\"\"~~~~~~~~~~~~~~~\n",
        "NLP Configuration\n",
        "~~~~~~~~~~~~~~~\"\"\"\n",
        "\n",
        "LANGUAGES = {\n",
        "    \"en\": {\n",
        "        \"preprocessor\": lambda x: x,\n",
        "        \"postprocessor\": lambda x: x,\n",
        "    },\n",
        "    \"de\": {\n",
        "        \"preprocessor\": german_to_english_translation,\n",
        "        \"postprocessor\": english_to_german_translation,\n",
        "    }\n",
        "}\n",
        "\n",
        "TRAVEL_ASSOCIATIONS = {\n",
        "    \"travel\": {\n",
        "        \"data\": travel_tables,\n",
        "        \"time\": travel_time,\n",
        "        \"location\": travel_location,\n",
        "        \"samples\": travel_samples,\n",
        "        \"config\": {\n",
        "            \"temperature\": 0.6,\n",
        "            \"do_sample\": True,\n",
        "            \"max_length\": samples_length(\n",
        "                travel_samples, \n",
        "                FEW_SHOT_MODEL) + 50,\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "TRAVEL_SKILL = {\n",
        "    \"associations\": TRAVEL_ASSOCIATIONS, \n",
        "    \"function\": travel_skill\n",
        "}\n",
        "\n",
        "SKILLS: Skills = {\n",
        "    \"small talk\": {\n",
        "        \"associations\": {}, \n",
        "        \"function\": small_talk_skill\n",
        "    },\n",
        "    \"travel\": TRAVEL_SKILL,\n",
        "    \"travel on time\": TRAVEL_SKILL,\n",
        "    \"travel delayed\": TRAVEL_SKILL,\n",
        "    \"other\": {\n",
        "        \"associations\": {}, \n",
        "        \"function\": small_talk_skill\n",
        "    },\n",
        "}\n",
        "\n",
        "PERSONAS = []\n",
        "\n",
        "\n",
        "CONFIG = {\n",
        "    \"languages\": LANGUAGES,\n",
        "    \"personas\": PERSONAS,\n",
        "    \"skills\": SKILLS,\n",
        "} \n",
        "\n",
        "\n",
        "class NLP:\n",
        "    def __init__(self,\n",
        "                 config: dict = CONFIG,\n",
        "                 verbose: bool = True,\n",
        "                 **kwargs):\n",
        "        self.config = config\n",
        "\n",
        "        language_processors = config[\"languages\"][LANGUAGE]\n",
        "        self.language_preprocessor = language_processors[\"preprocessor\"]\n",
        "        self.language_postprocessor = language_processors[\"postprocessor\"]\n",
        "\n",
        "        self.conversation = transformers.Conversation()\n",
        "        self.conversation = warm_up(\n",
        "            self.conversation, \n",
        "            personas=config[\"personas\"],\n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "\n",
        "        self.skills = config[\"skills\"]\n",
        "        \n",
        "    def __call__(self, \n",
        "                 input: str, \n",
        "                 verbose: bool = False, \n",
        "                 **kwargs) -> str:\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP __call__ START|\" + \"~\"*20)\n",
        "            print(f\"[DEBUG] |NLP ATTR skills|: {self.skills}\")\n",
        "            print(f\"[DEBUG] |NLP ATTR conversation|: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP User input|: {input}\")\n",
        "        \n",
        "        input = self.language_preprocessor(input)\n",
        "        self.conversation.add_user_input(input)\n",
        "\n",
        "        skill = skill_classification(\n",
        "            input, \n",
        "            list(self.skills.keys()), \n",
        "            verbose=verbose, \n",
        "            **kwargs)\n",
        "        \n",
        "        pipeline = self.skills[skill]\n",
        "        function = pipeline[\"function\"]\n",
        "        associations = pipeline[\"associations\"]\n",
        "        \n",
        "        output, conversation = function(\n",
        "            self.conversation, \n",
        "            associations=associations, \n",
        "            verbose=verbose,\n",
        "            **kwargs)\n",
        "\n",
        "        if conversation:\n",
        "            self.conversation = conversation\n",
        "        output = self.language_postprocessor(output)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"[DEBUG] |NLP conversation |: \\n{self.conversation}\")\n",
        "            print(f\"[DEBUG] |NLP User output|: {output}\")\n",
        "            print(f\"[DEBUG] |NLP __call__ END|\" + \"~\"*20)\n",
        "        return output\n",
        "\n",
        "nlp = execute(NLP, verbose=VERBOSE, config=CONFIG)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG8kX8OHvA-U"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# ***T-REX*** ðŸ¦–\n",
        "\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXxUibBOvZWT",
        "cellView": "form"
      },
      "source": [
        "# @title | T-REX | Start new Conversation\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "#@markdown ---\n",
        "ACTIVATE_PERSONAS = False # @param {type:\"boolean\"}\n",
        "PERSONA_1 = \"I work in a travel agency\" # @param {type:\"string\"}\n",
        "PERSONA_1 = f\"your persona: {PERSONA_1}\"\n",
        "PERSONA_2 = \"My name is Mia\" # @param {type:\"string\"}\n",
        "PERSONA_2 = f\"your persona: {PERSONA_2}\"\n",
        "\n",
        "#@markdown ---\n",
        "VERBOSE = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "def trex_setup(**kwargs):\n",
        "    config = {\n",
        "        \"languages\": LANGUAGES,\n",
        "        \"personas\": [PERSONA_1, PERSONA_2] if ACTIVATE_PERSONAS else [],\n",
        "        \"skills\": SKILLS,\n",
        "    }\n",
        "\n",
        "    nlp = NLP(config=config, **kwargs)\n",
        "    return nlp\n",
        "\n",
        "nlp = execute(trex_setup, verbose=VERBOSE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJSj4o6TA86"
      },
      "source": [
        "# Test the Toolkit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yGNWpDXpStcm"
      },
      "source": [
        "# @title Utils for Testing\n",
        "# @markdown âœ‹ Rerun Cell if Runtime was restarted ðŸ”„\n",
        "\n",
        "\n",
        "from typing import Any\n",
        "from typing import Tuple\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def test_toolkit_component(\n",
        "    component: Any, \n",
        "    dataset: List[Tuple[Any]], \n",
        "    config: dict = {}) -> dict:\n",
        "    results = {**locals()}\n",
        "\n",
        "    predictions = []\n",
        "    for x, y in dataset:\n",
        "        predictions.append(\n",
        "            component(x, **config))\n",
        "    \n",
        "    results[\"predictions\"] = predictions\n",
        "    return results\n",
        "\n",
        "def get_nlp_models(\n",
        "    order: List[str] = [\n",
        "        \"SMALL_TALK\", \n",
        "        \"FEW_SHOT\", \n",
        "        \"TABLE_QA\", \n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\", \n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\"],\n",
        "    delimiter: str = \",\") -> str:\n",
        "    models = {\n",
        "        \"SMALL_TALK\": SMALL_TALK_MODEL,\n",
        "        \"FEW_SHOT\": FEW_SHOT_MODEL,\n",
        "        \"TABLE_QA\": TABLE_QA_MODEL,\n",
        "        \"SOURCE_TO_NATIVE_TRANSLATOR\": GERMAN_TO_ENGLISH_MODEL,\n",
        "        \"NATIVE_TO_SOURCE_TRANSLATOR\": ENGLISH_TO_GERMAN_MODEL,\n",
        "    }\n",
        "    return delimiter.join([models[i] for i in order])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nsnv06Y_Ul0w"
      },
      "source": [
        "# @title Test the **Zero-Shot Classification** Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    zero_shot_classification, \n",
        "    [\n",
        "        (\"Hello, how are you?\", \"small-talk\")\n",
        "    ], \n",
        "    {\n",
        "        \"labels\": [\"travel\", \"small-talk\"]\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkQmakDVWZRW"
      },
      "source": [
        "# @title Test the **Skill Classification** capability of the *Zero-Shot Classification* Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    skill_classification,\n",
        "    [\n",
        "        (\"Hello, how are you?\", \"small talk\"),\n",
        "        (\"When will the ICE 77 arrive?\",\n",
        "            [\"travel\", \"travel on time\", \"travel delayed\"]),\n",
        "    ],\n",
        "    {\n",
        "        \"skills\": list(SKILLS.keys()),\n",
        "        \"verbose\": False\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASJyCLEpYmST"
      },
      "source": [
        "# @title Test the **Toxicity Classification** capability of the *Zero-Shot Classification* Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    toxicity_classification,\n",
        "    [\n",
        "        (\"Hello, how are you?\", \"non-toxic\"),\n",
        "        (\"You bastard!\", \"toxic\"),\n",
        "    ],\n",
        "    {\n",
        "        \"verbose\": False,\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do_PDtFkXLF0"
      },
      "source": [
        "# @title Test the **Table-QA** Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    table_question_answering,\n",
        "    [\n",
        "        (\"When will the ICE 77 departure?\", \"12:30\"),\n",
        "        (\"How much will the ICE 77 be delayed?\", \"2\"),\n",
        "    ],\n",
        "    {\n",
        "        \"table\": travel_tables()\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxxd9NuvaUWV"
      },
      "source": [
        "# @title Test the **Few-Shot** Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    few_shot,\n",
        "    [\n",
        "        (\"Hello, how are you?\", None),\n",
        "    ],\n",
        "    {\n",
        "        \"samples\": \"\",\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly869xXnavgf"
      },
      "source": [
        "# @title Test the **Travel Few-Shot** capability of the *Few-Shot* Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    travel_few_shot,\n",
        "    [\n",
        "        ('Question: \"I am in Munich. It is 7:00. When will the ICE 77 departure?\" Context: \"12:30\" Answer: \"', 'The ICE 77 will departure 12:30.\"')\n",
        "    ],\n",
        "    {\n",
        "        \"samples\": travel_samples,\n",
        "        **TRAVEL_ASSOCIATIONS[\"travel\"][\"config\"]\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nztBbD3cJN2"
      },
      "source": [
        "# @title Test the **Travel-Skill**\n",
        "\n",
        "test_toolkit_component(\n",
        "    travel_skill,\n",
        "    [\n",
        "        (transformers.Conversation(\"When will the ICE 77 departure?\"),\n",
        "            \"The ICE 77 will departure 12:30.\"),\n",
        "    ],\n",
        "    {\n",
        "        \"associations\": TRAVEL_ASSOCIATIONS\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5DzuFw8XI4w"
      },
      "source": [
        "# @title Test the **Small-Talk-Skill**\n",
        "\n",
        "test_toolkit_component(\n",
        "    small_talk_skill,\n",
        "    [\n",
        "        (transformers.Conversation(\"Hello, how are you?\"), None),\n",
        "    ],\n",
        "    {}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVKDnYtGfYaW"
      },
      "source": [
        "# @title Test the **Personas** of the *Small-Talk-Skill*\n",
        "\n",
        "test_toolkit_component(\n",
        "    warm_up,\n",
        "    [\n",
        "        (transformers.Conversation(), None),\n",
        "    ],\n",
        "    {\n",
        "        \"personas\": [PERSONA_1, PERSONA_2],\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDFUy2YZjOcA"
      },
      "source": [
        "# @title Test the **Soure-To-Native Translation** Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    german_to_english_translation,\n",
        "    [\n",
        "        (\"Wie geht es dir?\", \"How are you?\"),\n",
        "    ],\n",
        "    {}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPGurUYAjxwm"
      },
      "source": [
        "# @title Test the **Native-To-Source Translation** Component\n",
        "\n",
        "test_toolkit_component(\n",
        "    english_to_german_translation,\n",
        "    [\n",
        "        (\"How are you?\", \"Wie geht es dir?\"),\n",
        "    ],\n",
        "    {}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}